{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "_wmjdc9Wc73k",
    "outputId": "acb92645-7a7a-4e42-d91e-a7fad63753f4"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install numpy==1.19.5\n",
    "!pip install --upgrade tqdm\n",
    "!pip install --upgrade pip requests\n",
    "!pip install --upgrade pip Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T17:31:55.616126Z",
     "iopub.status.busy": "2022-07-01T17:31:55.615647Z",
     "iopub.status.idle": "2022-07-01T17:32:16.962399Z",
     "shell.execute_reply": "2022-07-01T17:32:16.961448Z",
     "shell.execute_reply.started": "2022-07-01T17:31:55.616048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy==1.3.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/18/d7c101d5e93b6c78dc206fcdf7bd04c1f8138a7b1a93578158fa3b132b08/scipy-1.3.3-cp36-cp36m-manylinux1_x86_64.whl (25.2MB)\n",
      "\u001b[K     |████████████████████████████████| 25.2MB 23.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy==1.3.3) (1.17.0)\n",
      "Installing collected packages: scipy\n",
      "  Found existing installation: scipy 1.3.0\n",
      "    Uninstalling scipy-1.3.0:\n",
      "      Successfully uninstalled scipy-1.3.0\n",
      "Successfully installed scipy-1.3.3\n",
      "\u001b[33mWARNING: You are using pip version 19.2.1, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting requests==2.22.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 6.6MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting idna<2.9,>=2.5 (from requests==2.22.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 24.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17 (from requests==2.22.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/06/d3d367b7af6305b16f0d28ae2aaeb86154fa91f144f036c2d5002a5a202b/certifi-2022.6.15-py3-none-any.whl (160kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 40.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting chardet<3.1.0,>=3.0.2 (from requests==2.22.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 29.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests==2.22.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/aa/4ef5aa67a9a62505db124a5cb5262332d1d4153462eb8fd89c9fa41e5d92/urllib3-1.25.11-py2.py3-none-any.whl (127kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 40.9MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: idna, certifi, chardet, urllib3, requests\n",
      "Successfully installed certifi-2022.6.15 chardet-3.0.4 idna-2.8 requests-2.22.0 urllib3-1.25.11\n",
      "\u001b[33mWARNING: You are using pip version 19.2.1, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting Pillow==6.2.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/5c/0e94e689de2476c4c5e644a3bd223a1c1b9e2bdb7c510191750be74fa786/Pillow-6.2.1-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1MB 13.4MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: Pillow\n",
      "Successfully installed Pillow-6.2.1\n",
      "\u001b[33mWARNING: You are using pip version 19.2.1, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: h5py==2.9.0 in /usr/local/lib/python3.6/dist-packages (2.9.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py==2.9.0) (1.17.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py==2.9.0) (1.12.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.1, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting imageio==2.9.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/57/5d899fae74c1752f52869b613a8210a2480e1a69688e65df6cb26117d45d/imageio-2.9.0-py3-none-any.whl (3.3MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3MB 15.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio==2.9.0) (1.17.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio==2.9.0) (6.2.1)\n",
      "Installing collected packages: imageio\n",
      "Successfully installed imageio-2.9.0\n",
      "\u001b[33mWARNING: You are using pip version 19.2.1, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting imageio-ffmpeg==0.4.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/c8/04c6b4a001b8ae7326fb83d6665af1ee58d6cc1acb421f8ea40d2678fe3c/imageio_ffmpeg-0.4.2-py3-none-manylinux2010_x86_64.whl (26.9MB)\n",
      "\u001b[K     |████████████████████████████████| 26.9MB 22.1MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: imageio-ffmpeg\n",
      "Successfully installed imageio-ffmpeg-0.4.2\n",
      "\u001b[33mWARNING: You are using pip version 19.2.1, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting tqdm==4.49.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/d5/f220e0c69b2f346b5649b66abebb391df1a00a59997a7ccf823325bd7a3e/tqdm-4.49.0-py2.py3-none-any.whl (69kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 14.9MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.49.0\n",
      "\u001b[33mWARNING: You are using pip version 19.2.1, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy==1.3.3\n",
    "!pip install requests==2.22.0\n",
    "!pip install Pillow==6.2.1\n",
    "!pip install h5py==2.9.0\n",
    "!pip install imageio==2.9.0\n",
    "!pip install imageio-ffmpeg==0.4.2\n",
    "!pip install tqdm==4.49.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T17:32:16.966678Z",
     "iopub.status.busy": "2022-07-01T17:32:16.966486Z",
     "iopub.status.idle": "2022-07-01T17:32:18.693444Z",
     "shell.execute_reply": "2022-07-01T17:32:18.692615Z",
     "shell.execute_reply.started": "2022-07-01T17:32:16.966646Z"
    },
    "id": "scbAtP_LVgpK"
   },
   "outputs": [],
   "source": [
    "import os, glob, pickle\n",
    "#from bs4 import BeautifulSoup\n",
    "from csv import writer\n",
    "#from imageio import imread, imwrite\n",
    "from io import StringIO, BytesIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-07-01T17:32:32.327150Z",
     "iopub.status.busy": "2022-07-01T17:32:32.326691Z",
     "iopub.status.idle": "2022-07-01T17:32:32.332105Z",
     "shell.execute_reply": "2022-07-01T17:32:32.331282Z",
     "shell.execute_reply.started": "2022-07-01T17:32:32.327086Z"
    },
    "id": "Ll4QTUIaQ83p",
    "outputId": "d1db400b-6f5f-4c9b-f03c-211643e6e94d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import tensorflow\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-06-13T13:53:10.491858Z",
     "iopub.status.busy": "2022-06-13T13:53:10.491264Z"
    },
    "id": "fgrPamuPStgb",
    "outputId": "b93876e5-2b3c-4b25-c462-a8f9fd38969d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'stylegan2-ada'...\n",
      "remote: Enumerating objects: 74, done.\u001b[K\n",
      "remote: Total 74 (delta 0), reused 0 (delta 0), pack-reused 74\u001b[K\n",
      "Unpacking objects: 100% (74/74), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/NVlabs/stylegan2-ada.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-06-13T12:30:27.271010Z",
     "iopub.status.busy": "2022-06-13T12:30:27.270661Z",
     "iopub.status.idle": "2022-06-13T12:31:34.150410Z",
     "shell.execute_reply": "2022-06-13T12:31:34.149160Z",
     "shell.execute_reply.started": "2022-06-13T12:30:27.270958Z"
    },
    "id": "quPD1PzSFqde",
    "outputId": "a0a4b5c2-0d09-443f-fedf-0b4fada3bf6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'logoGAN'...\n",
      "remote: Enumerating objects: 28172, done.\u001b[K\n",
      "remote: Total 28172 (delta 0), reused 0 (delta 0), pack-reused 28172\u001b[K\n",
      "Receiving objects: 100% (28172/28172), 306.75 MiB | 14.60 MiB/s, done.\n",
      "Resolving deltas: 100% (10955/10955), done.\n",
      "Checking out files: 100% (22514/22514), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/gracjans/logoGAN.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T10:00:19.491246Z",
     "iopub.status.busy": "2022-06-16T10:00:19.490915Z",
     "iopub.status.idle": "2022-06-16T10:01:04.464529Z",
     "shell.execute_reply": "2022-06-16T10:01:04.463783Z",
     "shell.execute_reply.started": "2022-06-16T10:00:19.491196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'logoGAN-full'...\n",
      "remote: Enumerating objects: 28175, done.\u001b[K\n",
      "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
      "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
      "remote: Total 28175 (delta 0), reused 3 (delta 0), pack-reused 28172\u001b[K\n",
      "Receiving objects: 100% (28175/28175), 306.76 MiB | 22.46 MiB/s, done.\n",
      "Resolving deltas: 100% (10955/10955), done.\n",
      "Checking out files: 100% (22515/22515), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/gracjans/logoGAN.git logoGAN-full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-13T13:54:39.203023Z",
     "iopub.status.busy": "2022-06-13T13:54:39.202708Z",
     "iopub.status.idle": "2022-06-13T13:54:51.030254Z",
     "shell.execute_reply": "2022-06-13T13:54:51.029738Z",
     "shell.execute_reply.started": "2022-06-13T13:54:39.202986Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5515\n",
      "3515\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "REDUCE DATASET (delete random images)\n",
    "\"\"\"\n",
    "# import os\n",
    "# from random import sample\n",
    "\n",
    "# files = os.listdir('logoGAN/data/img_128x128')\n",
    "# number_files = len(files)\n",
    "# print(number_files)\n",
    "\n",
    "# # delete number of random files\n",
    "# files_to_delete = 2000\n",
    "\n",
    "# for file in sample(files, files_to_delete):\n",
    "#     os.remove('logoGAN/data/img_128x128/'+file)\n",
    "\n",
    "# files = os.listdir('logoGAN/data/img_128x128')\n",
    "# number_files = len(files)\n",
    "# print(number_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-06-16T10:01:07.569097Z",
     "iopub.status.busy": "2022-06-16T10:01:07.568716Z",
     "iopub.status.idle": "2022-06-16T10:02:06.046009Z",
     "shell.execute_reply": "2022-06-16T10:02:06.044844Z",
     "shell.execute_reply.started": "2022-06-16T10:01:07.569046Z"
    },
    "id": "qCCCsYnK--25",
    "outputId": "559c65bb-9370-4464-b288-3d57190595ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Loading images from \"logoGAN-full/data/img_128x128\"\n",
      "Creating dataset \"./datasets/logo-full\"\n",
      "Added 5515 images.                      \n"
     ]
    }
   ],
   "source": [
    "!python stylegan2-ada/dataset_tool.py create_from_images ./datasets/logo-full logoGAN-full/data/img_128x128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mirror=False, batch=16\n",
    "## Traning stage 1: With \"--freezed=2\" (around 1300kimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-06-13T14:26:29.710465Z",
     "iopub.status.busy": "2022-06-13T14:26:29.710147Z"
    },
    "id": "uhkdvy76L2R8",
    "outputId": "2d94800d-4fb6-4be8-fcbe-fc76db900fa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256,\n",
      "    \"freeze_layers\": 2\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 16.0\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.6,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1,\n",
      "      \"imgfilter\": 1,\n",
      "      \"noise\": 1,\n",
      "      \"cutout\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 20,\n",
      "  \"network_snapshot_ticks\": 20,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 1000,\n",
      "  \"minibatch_size\": 16,\n",
      "  \"minibatch_gpu\": 16,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/transfer-learning-source-nets/ffhq-res256-mirror-paper256-noaug.pkl\",\n",
      "  \"run_dir\": \"./training-runs/00000-logo-res128-auto1-gamma16-kimg1000-bgcfnc-resumeffhq256-freezed2\"\n",
      "}\n",
      "\n",
      "Output directory:  ./training-runs/00000-logo-res128-auto1-gamma16-kimg1000-bgcfnc-resumeffhq256-freezed2\n",
      "Training data:     ./datasets/logo\n",
      "Training length:   1000 kimg\n",
      "Resolution:        128\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "Image shape: [3, 128, 128]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Loading... Done.\n",
      "Resuming from \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/transfer-learning-source-nets/ffhq-res256-mirror-paper256-noaug.pkl\"\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 12, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 12, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "---                           ---       ---                 ---             \n",
      "Total                         22949277                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 128, 128)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "128x128/FromRGB      -         (?, 128, 128, 128)  -               \n",
      "128x128/Conv0        -         (?, 128, 128, 128)  -               \n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                23734273                                      \n",
      "\n",
      "Exporting sample images...\n",
      "2022-06-13 14:26:41.324292: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "2022-06-13 14:26:49.183778: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 3.31G (3557815040 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 1000 kimg...\n",
      "\n",
      "tick 0     kimg 0.1      time 1m 16s       sec/tick 17.0    sec/kimg 264.96  maintenance 58.9   gpumem 6.0   augment 0.000\n",
      "Evaluating metrics...\n",
      "network-snapshot-000000        time 6m 58s       fid50k_full 253.0458\n",
      "tick 1     kimg 4.1      time 11m 01s      sec/tick 137.7   sec/kimg 34.15   maintenance 447.7  gpumem 6.0   augment 0.016\n",
      "tick 2     kimg 8.1      time 13m 19s      sec/tick 137.4   sec/kimg 34.08   maintenance 0.0    gpumem 6.0   augment 0.038\n",
      "tick 3     kimg 12.2     time 15m 36s      sec/tick 137.5   sec/kimg 34.11   maintenance 0.0    gpumem 6.0   augment 0.065\n",
      "tick 4     kimg 16.2     time 17m 54s      sec/tick 137.5   sec/kimg 34.10   maintenance 0.0    gpumem 6.0   augment 0.090\n",
      "tick 5     kimg 20.2     time 20m 12s      sec/tick 137.8   sec/kimg 34.18   maintenance 0.0    gpumem 6.0   augment 0.108\n",
      "tick 6     kimg 24.3     time 22m 29s      sec/tick 137.9   sec/kimg 34.21   maintenance 0.0    gpumem 6.0   augment 0.128\n",
      "tick 7     kimg 28.3     time 24m 47s      sec/tick 137.9   sec/kimg 34.20   maintenance 0.0    gpumem 6.0   augment 0.145\n",
      "tick 8     kimg 32.3     time 27m 05s      sec/tick 137.9   sec/kimg 34.20   maintenance 0.0    gpumem 6.0   augment 0.156\n",
      "tick 9     kimg 36.4     time 29m 23s      sec/tick 137.7   sec/kimg 34.16   maintenance 0.0    gpumem 6.0   augment 0.166\n",
      "tick 10    kimg 40.4     time 31m 41s      sec/tick 138.2   sec/kimg 34.28   maintenance 0.0    gpumem 6.0   augment 0.178\n",
      "tick 11    kimg 44.4     time 33m 59s      sec/tick 138.3   sec/kimg 34.29   maintenance 0.0    gpumem 6.0   augment 0.182\n",
      "tick 12    kimg 48.4     time 36m 18s      sec/tick 138.1   sec/kimg 34.25   maintenance 0.0    gpumem 6.0   augment 0.196\n",
      "tick 13    kimg 52.5     time 38m 36s      sec/tick 138.0   sec/kimg 34.23   maintenance 0.0    gpumem 6.0   augment 0.203\n",
      "tick 14    kimg 56.5     time 40m 54s      sec/tick 138.1   sec/kimg 34.25   maintenance 0.0    gpumem 6.0   augment 0.202\n",
      "tick 15    kimg 60.5     time 43m 12s      sec/tick 138.1   sec/kimg 34.25   maintenance 0.0    gpumem 6.0   augment 0.209\n",
      "tick 16    kimg 64.6     time 45m 30s      sec/tick 138.0   sec/kimg 34.22   maintenance 0.0    gpumem 6.0   augment 0.219\n",
      "tick 17    kimg 68.6     time 47m 48s      sec/tick 138.0   sec/kimg 34.22   maintenance 0.0    gpumem 6.0   augment 0.228\n",
      "tick 18    kimg 72.6     time 50m 06s      sec/tick 138.2   sec/kimg 34.27   maintenance 0.0    gpumem 6.0   augment 0.230\n",
      "tick 19    kimg 76.7     time 52m 24s      sec/tick 138.4   sec/kimg 34.33   maintenance 0.0    gpumem 6.0   augment 0.227\n",
      "tick 20    kimg 80.7     time 54m 43s      sec/tick 138.2   sec/kimg 34.27   maintenance 0.0    gpumem 6.0   augment 0.236\n",
      "Evaluating metrics...\n",
      "network-snapshot-000080        time 6m 58s       fid50k_full 69.8501\n",
      "tick 21    kimg 84.7     time 1h 04m 09s   sec/tick 138.0   sec/kimg 34.24   maintenance 428.0  gpumem 6.0   augment 0.240\n",
      "tick 22    kimg 88.8     time 1h 06m 27s   sec/tick 138.3   sec/kimg 34.31   maintenance 0.0    gpumem 6.0   augment 0.242\n",
      "tick 23    kimg 92.8     time 1h 08m 45s   sec/tick 138.2   sec/kimg 34.28   maintenance 0.0    gpumem 6.0   augment 0.244\n",
      "tick 24    kimg 96.8     time 1h 11m 03s   sec/tick 138.1   sec/kimg 34.25   maintenance 0.0    gpumem 6.0   augment 0.248\n",
      "tick 25    kimg 100.9    time 1h 13m 22s   sec/tick 138.2   sec/kimg 34.28   maintenance 0.0    gpumem 6.0   augment 0.253\n",
      "tick 26    kimg 104.9    time 1h 15m 40s   sec/tick 138.3   sec/kimg 34.29   maintenance 0.0    gpumem 6.0   augment 0.253\n",
      "tick 27    kimg 108.9    time 1h 17m 58s   sec/tick 138.3   sec/kimg 34.29   maintenance 0.0    gpumem 6.0   augment 0.248\n",
      "tick 28    kimg 113.0    time 1h 20m 16s   sec/tick 138.1   sec/kimg 34.25   maintenance 0.0    gpumem 6.0   augment 0.244\n",
      "tick 29    kimg 117.0    time 1h 22m 34s   sec/tick 138.1   sec/kimg 34.24   maintenance 0.0    gpumem 6.0   augment 0.249\n",
      "tick 30    kimg 121.0    time 1h 24m 53s   sec/tick 138.2   sec/kimg 34.28   maintenance 0.0    gpumem 6.0   augment 0.260\n",
      "tick 31    kimg 125.1    time 1h 27m 11s   sec/tick 138.2   sec/kimg 34.28   maintenance 0.0    gpumem 6.0   augment 0.260\n",
      "tick 32    kimg 129.1    time 1h 29m 29s   sec/tick 137.9   sec/kimg 34.19   maintenance 0.0    gpumem 6.0   augment 0.265\n",
      "tick 33    kimg 133.1    time 1h 31m 47s   sec/tick 138.0   sec/kimg 34.24   maintenance 0.0    gpumem 6.0   augment 0.267\n",
      "tick 34    kimg 137.2    time 1h 34m 05s   sec/tick 138.0   sec/kimg 34.23   maintenance 0.0    gpumem 6.0   augment 0.262\n",
      "tick 35    kimg 141.2    time 1h 36m 23s   sec/tick 138.2   sec/kimg 34.27   maintenance 0.0    gpumem 6.0   augment 0.268\n",
      "tick 36    kimg 145.2    time 1h 38m 41s   sec/tick 138.4   sec/kimg 34.32   maintenance 0.0    gpumem 6.0   augment 0.271\n",
      "tick 37    kimg 149.2    time 1h 40m 59s   sec/tick 138.0   sec/kimg 34.24   maintenance 0.0    gpumem 6.0   augment 0.278\n",
      "tick 38    kimg 153.3    time 1h 43m 18s   sec/tick 138.4   sec/kimg 34.34   maintenance 0.0    gpumem 6.0   augment 0.279\n",
      "tick 39    kimg 157.3    time 1h 45m 36s   sec/tick 138.0   sec/kimg 34.23   maintenance 0.0    gpumem 6.0   augment 0.272\n",
      "tick 40    kimg 161.3    time 1h 47m 54s   sec/tick 138.2   sec/kimg 34.28   maintenance 0.0    gpumem 6.0   augment 0.270\n",
      "Evaluating metrics...\n",
      "network-snapshot-000161        time 6m 58s       fid50k_full 53.2327\n",
      "tick 41    kimg 165.4    time 1h 57m 20s   sec/tick 138.1   sec/kimg 34.25   maintenance 427.7  gpumem 6.0   augment 0.271\n",
      "tick 42    kimg 169.4    time 1h 59m 38s   sec/tick 138.3   sec/kimg 34.29   maintenance 0.0    gpumem 6.0   augment 0.270\n",
      "tick 43    kimg 173.4    time 2h 01m 57s   sec/tick 138.4   sec/kimg 34.33   maintenance 0.0    gpumem 6.0   augment 0.275\n",
      "tick 44    kimg 177.5    time 2h 04m 15s   sec/tick 138.4   sec/kimg 34.32   maintenance 0.0    gpumem 6.0   augment 0.270\n",
      "tick 45    kimg 181.5    time 2h 06m 33s   sec/tick 138.2   sec/kimg 34.27   maintenance 0.0    gpumem 6.0   augment 0.269\n",
      "tick 46    kimg 185.5    time 2h 08m 51s   sec/tick 138.2   sec/kimg 34.27   maintenance 0.0    gpumem 6.0   augment 0.270\n",
      "tick 47    kimg 189.6    time 2h 11m 10s   sec/tick 138.3   sec/kimg 34.30   maintenance 0.0    gpumem 6.0   augment 0.268\n",
      "tick 48    kimg 193.6    time 2h 13m 28s   sec/tick 138.1   sec/kimg 34.24   maintenance 0.0    gpumem 6.0   augment 0.269\n",
      "tick 49    kimg 197.6    time 2h 15m 46s   sec/tick 138.1   sec/kimg 34.25   maintenance 0.0    gpumem 6.0   augment 0.260\n",
      "tick 50    kimg 201.7    time 2h 18m 04s   sec/tick 138.2   sec/kimg 34.28   maintenance 0.0    gpumem 6.0   augment 0.262\n",
      "tick 51    kimg 205.7    time 2h 20m 22s   sec/tick 138.2   sec/kimg 34.28   maintenance 0.0    gpumem 6.0   augment 0.267\n",
      "tick 52    kimg 209.7    time 2h 22m 41s   sec/tick 138.3   sec/kimg 34.30   maintenance 0.0    gpumem 6.0   augment 0.278\n",
      "tick 53    kimg 213.8    time 2h 24m 59s   sec/tick 138.2   sec/kimg 34.27   maintenance 0.0    gpumem 6.0   augment 0.276\n",
      "tick 54    kimg 217.8    time 2h 27m 17s   sec/tick 138.0   sec/kimg 34.22   maintenance 0.0    gpumem 6.0   augment 0.276\n",
      "tick 55    kimg 221.8    time 2h 29m 35s   sec/tick 138.2   sec/kimg 34.28   maintenance 0.0    gpumem 6.0   augment 0.276\n",
      "tick 56    kimg 225.9    time 2h 31m 53s   sec/tick 138.4   sec/kimg 34.33   maintenance 0.0    gpumem 6.0   augment 0.282\n",
      "tick 57    kimg 229.9    time 2h 34m 12s   sec/tick 138.2   sec/kimg 34.27   maintenance 0.0    gpumem 6.0   augment 0.282\n",
      "tick 58    kimg 233.9    time 2h 36m 30s   sec/tick 138.3   sec/kimg 34.30   maintenance 0.0    gpumem 6.0   augment 0.278\n",
      "tick 59    kimg 238.0    time 2h 38m 48s   sec/tick 138.3   sec/kimg 34.31   maintenance 0.0    gpumem 6.0   augment 0.272\n",
      "tick 60    kimg 242.0    time 2h 41m 07s   sec/tick 138.4   sec/kimg 34.33   maintenance 0.0    gpumem 6.0   augment 0.270\n",
      "Evaluating metrics...\n",
      "network-snapshot-000241        time 7m 00s       fid50k_full 47.7056\n",
      "tick 61    kimg 246.0    time 2h 50m 34s   sec/tick 138.1   sec/kimg 34.24   maintenance 429.2  gpumem 6.0   augment 0.271\n",
      "tick 62    kimg 250.0    time 2h 52m 52s   sec/tick 138.6   sec/kimg 34.36   maintenance 0.0    gpumem 6.0   augment 0.271\n",
      "tick 63    kimg 254.1    time 2h 55m 11s   sec/tick 138.5   sec/kimg 34.35   maintenance 0.0    gpumem 6.0   augment 0.278\n",
      "tick 64    kimg 258.1    time 2h 57m 30s   sec/tick 138.6   sec/kimg 34.37   maintenance 0.0    gpumem 6.0   augment 0.274\n",
      "tick 65    kimg 262.1    time 2h 59m 48s   sec/tick 138.1   sec/kimg 34.25   maintenance 0.0    gpumem 6.0   augment 0.280\n",
      "tick 66    kimg 266.2    time 3h 02m 06s   sec/tick 138.3   sec/kimg 34.31   maintenance 0.0    gpumem 6.0   augment 0.278\n",
      "tick 67    kimg 270.2    time 3h 04m 24s   sec/tick 138.4   sec/kimg 34.33   maintenance 0.0    gpumem 6.0   augment 0.273\n",
      "tick 68    kimg 274.2    time 3h 06m 43s   sec/tick 138.5   sec/kimg 34.36   maintenance 0.0    gpumem 6.0   augment 0.274\n",
      "tick 69    kimg 278.3    time 3h 09m 01s   sec/tick 138.3   sec/kimg 34.31   maintenance 0.0    gpumem 6.0   augment 0.269\n",
      "tick 70    kimg 282.3    time 3h 11m 20s   sec/tick 138.2   sec/kimg 34.28   maintenance 0.0    gpumem 6.0   augment 0.269\n",
      "tick 71    kimg 286.3    time 3h 13m 38s   sec/tick 138.1   sec/kimg 34.26   maintenance 0.0    gpumem 6.0   augment 0.271\n",
      "tick 72    kimg 290.4    time 3h 15m 56s   sec/tick 138.2   sec/kimg 34.27   maintenance 0.0    gpumem 6.0   augment 0.276\n",
      "tick 73    kimg 294.4    time 3h 18m 14s   sec/tick 138.0   sec/kimg 34.24   maintenance 0.0    gpumem 6.0   augment 0.276\n",
      "tick 74    kimg 298.4    time 3h 20m 32s   sec/tick 138.3   sec/kimg 34.30   maintenance 0.0    gpumem 6.0   augment 0.275\n",
      "tick 75    kimg 302.5    time 3h 22m 51s   sec/tick 138.6   sec/kimg 34.38   maintenance 0.0    gpumem 6.0   augment 0.280\n",
      "tick 76    kimg 306.5    time 3h 25m 09s   sec/tick 138.5   sec/kimg 34.35   maintenance 0.0    gpumem 6.0   augment 0.284\n",
      "tick 77    kimg 310.5    time 3h 27m 27s   sec/tick 138.0   sec/kimg 34.24   maintenance 0.0    gpumem 6.0   augment 0.282\n",
      "tick 78    kimg 314.6    time 3h 29m 46s   sec/tick 138.5   sec/kimg 34.34   maintenance 0.0    gpumem 6.0   augment 0.282\n",
      "tick 79    kimg 318.6    time 3h 32m 04s   sec/tick 138.2   sec/kimg 34.28   maintenance 0.0    gpumem 6.0   augment 0.286\n",
      "tick 80    kimg 322.6    time 3h 34m 23s   sec/tick 138.4   sec/kimg 34.32   maintenance 0.0    gpumem 6.0   augment 0.291\n",
      "Evaluating metrics...\n",
      "network-snapshot-000322        time 6m 58s       fid50k_full 42.7035\n",
      "tick 81    kimg 326.7    time 3h 43m 48s   sec/tick 138.0   sec/kimg 34.23   maintenance 427.6  gpumem 6.0   augment 0.287\n",
      "tick 82    kimg 330.7    time 3h 46m 07s   sec/tick 138.3   sec/kimg 34.31   maintenance 0.0    gpumem 6.0   augment 0.289\n",
      "tick 83    kimg 334.7    time 3h 48m 25s   sec/tick 138.3   sec/kimg 34.30   maintenance 0.0    gpumem 6.0   augment 0.281\n",
      "tick 84    kimg 338.8    time 3h 50m 43s   sec/tick 138.3   sec/kimg 34.29   maintenance 0.0    gpumem 6.0   augment 0.282\n",
      "tick 85    kimg 342.8    time 3h 53m 01s   sec/tick 138.3   sec/kimg 34.30   maintenance 0.0    gpumem 6.0   augment 0.289\n",
      "tick 86    kimg 346.8    time 3h 55m 20s   sec/tick 138.5   sec/kimg 34.35   maintenance 0.0    gpumem 6.0   augment 0.291\n",
      "tick 87    kimg 350.8    time 3h 57m 38s   sec/tick 138.5   sec/kimg 34.34   maintenance 0.0    gpumem 6.0   augment 0.292\n",
      "tick 88    kimg 354.9    time 3h 59m 57s   sec/tick 138.6   sec/kimg 34.37   maintenance 0.0    gpumem 6.0   augment 0.283\n",
      "tick 89    kimg 358.9    time 4h 02m 15s   sec/tick 138.4   sec/kimg 34.32   maintenance 0.0    gpumem 6.0   augment 0.280\n",
      "tick 90    kimg 362.9    time 4h 04m 34s   sec/tick 138.7   sec/kimg 34.41   maintenance 0.0    gpumem 6.0   augment 0.289\n",
      "tick 91    kimg 367.0    time 4h 06m 53s   sec/tick 138.6   sec/kimg 34.38   maintenance 0.0    gpumem 6.0   augment 0.289\n",
      "tick 92    kimg 371.0    time 4h 09m 12s   sec/tick 138.7   sec/kimg 34.39   maintenance 0.0    gpumem 6.0   augment 0.296\n",
      "tick 93    kimg 375.0    time 4h 11m 30s   sec/tick 138.5   sec/kimg 34.34   maintenance 0.0    gpumem 6.0   augment 0.295\n",
      "tick 94    kimg 379.1    time 4h 13m 49s   sec/tick 138.8   sec/kimg 34.42   maintenance 0.0    gpumem 6.0   augment 0.289\n",
      "tick 95    kimg 383.1    time 4h 16m 07s   sec/tick 138.7   sec/kimg 34.39   maintenance 0.0    gpumem 6.0   augment 0.292\n",
      "tick 96    kimg 387.1    time 4h 18m 26s   sec/tick 138.5   sec/kimg 34.34   maintenance 0.0    gpumem 6.0   augment 0.285\n",
      "tick 97    kimg 391.2    time 4h 20m 44s   sec/tick 138.4   sec/kimg 34.34   maintenance 0.0    gpumem 6.0   augment 0.286\n",
      "tick 98    kimg 395.2    time 4h 23m 03s   sec/tick 138.4   sec/kimg 34.32   maintenance 0.0    gpumem 6.0   augment 0.283\n",
      "tick 99    kimg 399.2    time 4h 25m 21s   sec/tick 138.4   sec/kimg 34.32   maintenance 0.0    gpumem 6.0   augment 0.287\n",
      "tick 100   kimg 403.3    time 4h 27m 40s   sec/tick 138.7   sec/kimg 34.40   maintenance 0.0    gpumem 6.0   augment 0.283\n",
      "Evaluating metrics...\n",
      "network-snapshot-000403        time 7m 01s       fid50k_full 40.1253\n",
      "tick 101   kimg 407.3    time 4h 37m 08s   sec/tick 138.1   sec/kimg 34.25   maintenance 430.0  gpumem 6.0   augment 0.282\n",
      "tick 102   kimg 411.3    time 4h 39m 27s   sec/tick 138.8   sec/kimg 34.43   maintenance 0.0    gpumem 6.0   augment 0.293\n",
      "tick 103   kimg 415.4    time 4h 41m 45s   sec/tick 138.6   sec/kimg 34.37   maintenance 0.0    gpumem 6.0   augment 0.287\n",
      "tick 104   kimg 419.4    time 4h 44m 04s   sec/tick 138.4   sec/kimg 34.32   maintenance 0.0    gpumem 6.0   augment 0.288\n",
      "tick 105   kimg 423.4    time 4h 46m 22s   sec/tick 138.2   sec/kimg 34.26   maintenance 0.0    gpumem 6.0   augment 0.289\n",
      "tick 106   kimg 427.5    time 4h 48m 40s   sec/tick 138.4   sec/kimg 34.33   maintenance 0.0    gpumem 6.0   augment 0.287\n",
      "tick 107   kimg 431.5    time 4h 50m 59s   sec/tick 138.2   sec/kimg 34.28   maintenance 0.0    gpumem 6.0   augment 0.287\n",
      "tick 108   kimg 435.5    time 4h 53m 17s   sec/tick 138.1   sec/kimg 34.24   maintenance 0.0    gpumem 6.0   augment 0.288\n",
      "tick 109   kimg 439.6    time 4h 55m 35s   sec/tick 138.1   sec/kimg 34.26   maintenance 0.0    gpumem 6.0   augment 0.295\n",
      "tick 110   kimg 443.6    time 4h 57m 53s   sec/tick 138.6   sec/kimg 34.37   maintenance 0.0    gpumem 6.0   augment 0.298\n",
      "tick 111   kimg 447.6    time 5h 00m 12s   sec/tick 138.4   sec/kimg 34.32   maintenance 0.0    gpumem 6.0   augment 0.294\n",
      "tick 112   kimg 451.6    time 5h 02m 30s   sec/tick 138.1   sec/kimg 34.26   maintenance 0.0    gpumem 6.0   augment 0.284\n",
      "tick 113   kimg 455.7    time 5h 04m 48s   sec/tick 138.1   sec/kimg 34.25   maintenance 0.0    gpumem 6.0   augment 0.289\n",
      "tick 114   kimg 459.7    time 5h 07m 07s   sec/tick 138.5   sec/kimg 34.36   maintenance 0.0    gpumem 6.0   augment 0.296\n",
      "tick 115   kimg 463.7    time 5h 09m 25s   sec/tick 138.5   sec/kimg 34.35   maintenance 0.0    gpumem 6.0   augment 0.294\n",
      "tick 116   kimg 467.8    time 5h 11m 44s   sec/tick 138.5   sec/kimg 34.34   maintenance 0.0    gpumem 6.0   augment 0.298\n",
      "tick 117   kimg 471.8    time 5h 14m 02s   sec/tick 138.2   sec/kimg 34.27   maintenance 0.0    gpumem 6.0   augment 0.298\n",
      "tick 118   kimg 475.8    time 5h 16m 20s   sec/tick 138.5   sec/kimg 34.35   maintenance 0.0    gpumem 6.0   augment 0.294\n",
      "tick 119   kimg 479.9    time 5h 18m 39s   sec/tick 138.4   sec/kimg 34.33   maintenance 0.0    gpumem 6.0   augment 0.289\n",
      "tick 120   kimg 483.9    time 5h 20m 57s   sec/tick 138.6   sec/kimg 34.37   maintenance 0.0    gpumem 6.0   augment 0.288\n",
      "Evaluating metrics...\n",
      "network-snapshot-000483        time 6m 59s       fid50k_full 37.9389\n",
      "tick 121   kimg 487.9    time 5h 30m 23s   sec/tick 137.9   sec/kimg 34.21   maintenance 428.0  gpumem 6.0   augment 0.289\n"
     ]
    }
   ],
   "source": [
    "#!python stylegan2-ada/train.py --snap=20 --outdir=./training-runs --gpus=1 --data=./datasets/logo --res=128 --kimg=1000 --mirror=False --gamma=16 --augpipe=bgcfnc --freezed=2 --resume=ffhq256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-13T20:20:25.998931Z",
     "iopub.status.busy": "2022-06-13T20:20:25.998624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256,\n",
      "    \"freeze_layers\": 2\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 16.0\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.6,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1,\n",
      "      \"imgfilter\": 1,\n",
      "      \"noise\": 1,\n",
      "      \"cutout\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 20,\n",
      "  \"network_snapshot_ticks\": 20,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 500,\n",
      "  \"minibatch_size\": 16,\n",
      "  \"minibatch_gpu\": 16,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"./training-runs/00000-logo-res128-auto1-gamma16-kimg1000-bgcfnc-resumeffhq256-freezed2/network-snapshot-000483.pkl\",\n",
      "  \"run_dir\": \"./training-runs/00001-logo-res128-auto1-gamma16-kimg500-bgcfnc-resumecustom-freezed2\"\n",
      "}\n",
      "\n",
      "Output directory:  ./training-runs/00001-logo-res128-auto1-gamma16-kimg500-bgcfnc-resumecustom-freezed2\n",
      "Training data:     ./datasets/logo\n",
      "Training length:   500 kimg\n",
      "Resolution:        128\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "Image shape: [3, 128, 128]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
      "Resuming from \"./training-runs/00000-logo-res128-auto1-gamma16-kimg1000-bgcfnc-resumeffhq256-freezed2/network-snapshot-000483.pkl\"\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 12, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 12, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "---                           ---       ---                 ---             \n",
      "Total                         22949277                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 128, 128)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "128x128/FromRGB      -         (?, 128, 128, 128)  -               \n",
      "128x128/Conv0        -         (?, 128, 128, 128)  -               \n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                23734273                                      \n",
      "\n",
      "Exporting sample images...\n",
      "2022-06-13 20:21:33.442553: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 500 kimg...\n",
      "\n",
      "tick 0     kimg 0.1      time 2m 59s       sec/tick 36.5    sec/kimg 571.04  maintenance 142.7  gpumem 5.9   augment 0.001\n",
      "Evaluating metrics...\n",
      "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/metrics/inception_v3_features.pkl ... done\n",
      "Calculating real image statistics for fid50k_full...\n",
      "network-snapshot-000000        time 30m 07s      fid50k_full 37.7274\n",
      "tick 1     kimg 4.1      time 44m 56s      sec/tick 661.2   sec/kimg 163.99  maintenance 1855.7 gpumem 5.9   augment 0.036\n",
      "tick 2     kimg 8.1      time 55m 59s      sec/tick 663.3   sec/kimg 164.50  maintenance 0.0    gpumem 5.9   augment 0.068\n",
      "tick 3     kimg 12.2     time 1h 07m 03s   sec/tick 663.8   sec/kimg 164.63  maintenance 0.0    gpumem 5.9   augment 0.101\n",
      "tick 4     kimg 16.2     time 1h 18m 05s   sec/tick 662.1   sec/kimg 164.22  maintenance 0.0    gpumem 5.9   augment 0.129\n",
      "tick 5     kimg 20.2     time 1h 29m 06s   sec/tick 660.7   sec/kimg 163.86  maintenance 0.0    gpumem 5.9   augment 0.155\n",
      "tick 6     kimg 24.3     time 1h 40m 08s   sec/tick 662.1   sec/kimg 164.20  maintenance 0.0    gpumem 5.9   augment 0.175\n",
      "tick 7     kimg 28.3     time 1h 51m 10s   sec/tick 662.3   sec/kimg 164.26  maintenance 0.0    gpumem 5.9   augment 0.193\n",
      "tick 8     kimg 32.3     time 2h 02m 13s   sec/tick 662.5   sec/kimg 164.30  maintenance 0.0    gpumem 5.9   augment 0.213\n",
      "tick 9     kimg 36.4     time 2h 13m 15s   sec/tick 661.7   sec/kimg 164.12  maintenance 0.0    gpumem 5.9   augment 0.232\n",
      "tick 10    kimg 40.4     time 2h 24m 17s   sec/tick 662.6   sec/kimg 164.34  maintenance 0.0    gpumem 5.9   augment 0.240\n",
      "tick 15    kimg 60.5     time 3h 19m 37s   sec/tick 666.5   sec/kimg 165.30  maintenance 0.0    gpumem 5.9   augment 0.279\n",
      "tick 16    kimg 64.6     time 3h 30m 40s   sec/tick 663.4   sec/kimg 164.54  maintenance 0.0    gpumem 5.9   augment 0.286\n"
     ]
    }
   ],
   "source": [
    "#!python stylegan2-ada/train.py --snap=20 --outdir=./training-runs --gpus=1 --data=./datasets/logo --res=128 --kimg=500 --mirror=False --gamma=16 --augpipe=bgcfnc --freezed=2 --resume=./training-runs/00000-logo-res128-auto1-gamma16-kimg1000-bgcfnc-resumeffhq256-freezed2/network-snapshot-000483.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:09:29.778819Z",
     "iopub.status.busy": "2022-06-14T10:09:29.778465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256,\n",
      "    \"freeze_layers\": 2\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 16.0\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.6,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1,\n",
      "      \"imgfilter\": 1,\n",
      "      \"noise\": 1,\n",
      "      \"cutout\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 20,\n",
      "  \"network_snapshot_ticks\": 20,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 500,\n",
      "  \"minibatch_size\": 16,\n",
      "  \"minibatch_gpu\": 16,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"./training-runs/00001-logo-res128-auto1-gamma16-kimg500-bgcfnc-resumecustom-freezed2/network-snapshot-000080.pkl\",\n",
      "  \"run_dir\": \"./training-runs/00002-logo-res128-auto1-gamma16-kimg500-bgcfnc-resumecustom-freezed2\"\n",
      "}\n",
      "\n",
      "Output directory:  ./training-runs/00002-logo-res128-auto1-gamma16-kimg500-bgcfnc-resumecustom-freezed2\n",
      "Training data:     ./datasets/logo\n",
      "Training length:   500 kimg\n",
      "Resolution:        128\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "Image shape: [3, 128, 128]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
      "Resuming from \"./training-runs/00001-logo-res128-auto1-gamma16-kimg500-bgcfnc-resumecustom-freezed2/network-snapshot-000080.pkl\"\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 12, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 12, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "---                           ---       ---                 ---             \n",
      "Total                         22949277                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 128, 128)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "128x128/FromRGB      -         (?, 128, 128, 128)  -               \n",
      "128x128/Conv0        -         (?, 128, 128, 128)  -               \n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                23734273                                      \n",
      "\n",
      "Exporting sample images...\n",
      "2022-06-14 10:10:27.372766: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 500 kimg...\n",
      "\n",
      "tick 0     kimg 0.1      time 2m 33s       sec/tick 31.0    sec/kimg 483.93  maintenance 122.0  gpumem 5.9   augment 0.001\n",
      "Evaluating metrics...\n",
      "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/metrics/inception_v3_features.pkl ... done\n",
      "Calculating real image statistics for fid50k_full...\n"
     ]
    }
   ],
   "source": [
    "#!python stylegan2-ada/train.py --snap=20 --outdir=./training-runs --gpus=1 --data=./datasets/logo --res=128 --kimg=500 --mirror=False --gamma=16 --augpipe=bgcfnc --freezed=2 --resume=./training-runs/00001-logo-res128-auto1-gamma16-kimg500-bgcfnc-resumecustom-freezed2/network-snapshot-000080.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T21:41:33.633648Z",
     "iopub.status.busy": "2022-06-14T21:41:33.633172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256,\n",
      "    \"freeze_layers\": 2\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 16.0\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.6,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1,\n",
      "      \"imgfilter\": 1,\n",
      "      \"noise\": 1,\n",
      "      \"cutout\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 10,\n",
      "  \"network_snapshot_ticks\": 10,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 500,\n",
      "  \"minibatch_size\": 16,\n",
      "  \"minibatch_gpu\": 16,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"./training-runs/00002-logo-res128-auto1-gamma16-kimg500-bgcfnc-resumecustom-freezed2/network-snapshot-000080.pkl\",\n",
      "  \"run_dir\": \"./training-runs/00003-logo-res128-auto1-gamma16-kimg500-bgcfnc-resumecustom-freezed2\"\n",
      "}\n",
      "\n",
      "Output directory:  ./training-runs/00003-logo-res128-auto1-gamma16-kimg500-bgcfnc-resumecustom-freezed2\n",
      "Training data:     ./datasets/logo\n",
      "Training length:   500 kimg\n",
      "Resolution:        128\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "Image shape: [3, 128, 128]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
      "Resuming from \"./training-runs/00002-logo-res128-auto1-gamma16-kimg500-bgcfnc-resumecustom-freezed2/network-snapshot-000080.pkl\"\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 12, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 12, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "---                           ---       ---                 ---             \n",
      "Total                         22949277                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 128, 128)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "128x128/FromRGB      -         (?, 128, 128, 128)  -               \n",
      "128x128/Conv0        -         (?, 128, 128, 128)  -               \n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                23734273                                      \n",
      "\n",
      "Exporting sample images...\n",
      "2022-06-14 21:42:52.128358: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 500 kimg...\n",
      "\n",
      "2022-06-14 21:44:42.435175: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.13GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "tick 0     kimg 0.1      time 3m 19s       sec/tick 36.0    sec/kimg 562.49  maintenance 162.6  gpumem 6.0   augment 0.001\n",
      "Evaluating metrics...\n",
      "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/metrics/inception_v3_features.pkl ... done\n",
      "Calculating real image statistics for fid50k_full...\n",
      "network-snapshot-000000        time 30m 29s      fid50k_full 33.3452\n"
     ]
    }
   ],
   "source": [
    "#!python stylegan2-ada/train.py --snap=10 --outdir=./training-runs --gpus=1 --data=./datasets/logo --res=128 --kimg=500 --mirror=False --gamma=16 --augpipe=bgcfnc --freezed=2 --resume=./training-runs/00002-logo-res128-auto1-gamma16-kimg500-bgcfnc-resumecustom-freezed2/network-snapshot-000080.pkl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T10:50:49.065348Z",
     "iopub.status.busy": "2022-06-15T10:50:49.065071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256,\n",
      "    \"freeze_layers\": 2\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 16.0\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.6,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1,\n",
      "      \"imgfilter\": 1,\n",
      "      \"noise\": 1,\n",
      "      \"cutout\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 30,\n",
      "  \"network_snapshot_ticks\": 30,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 700,\n",
      "  \"minibatch_size\": 32,\n",
      "  \"minibatch_gpu\": 32,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"./training-runs/00003-logo-res128-auto1-gamma16-kimg500-bgcfnc-resumecustom-freezed2/network-snapshot-000080.pkl\",\n",
      "  \"run_dir\": \"./training-runs/00004-logo-res128-auto1-gamma16-kimg700-bgcfnc-resumecustom-freezed2\"\n",
      "}\n",
      "\n",
      "Output directory:  ./training-runs/00004-logo-res128-auto1-gamma16-kimg700-bgcfnc-resumecustom-freezed2\n",
      "Training data:     ./datasets/logo\n",
      "Training length:   700 kimg\n",
      "Resolution:        128\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "Image shape: [3, 128, 128]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
      "Resuming from \"./training-runs/00003-logo-res128-auto1-gamma16-kimg500-bgcfnc-resumecustom-freezed2/network-snapshot-000080.pkl\"\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 12, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 12, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "---                           ---       ---                 ---             \n",
      "Total                         22949277                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 128, 128)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "128x128/FromRGB      -         (?, 128, 128, 128)  -               \n",
      "128x128/Conv0        -         (?, 128, 128, 128)  -               \n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                23734273                                      \n",
      "\n",
      "Exporting sample images...\n",
      "2022-06-15 10:51:36.335571: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 700 kimg...\n",
      "\n",
      "tick 0     kimg 0.1      time 1m 50s       sec/tick 20.4    sec/kimg 159.41  maintenance 89.2   gpumem 8.2   augment 0.001\n",
      "Evaluating metrics...\n",
      "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/metrics/inception_v3_features.pkl ... done\n",
      "Calculating real image statistics for fid50k_full...\n",
      "network-snapshot-000000        time 6m 48s       fid50k_full 31.4023\n",
      "tick 1     kimg 4.2      time 10m 45s      sec/tick 103.1   sec/kimg 25.18   maintenance 432.0  gpumem 8.4   augment 0.037\n",
      "tick 2     kimg 8.3      time 12m 28s      sec/tick 103.5   sec/kimg 25.26   maintenance 0.0    gpumem 8.6   augment 0.070\n",
      "tick 3     kimg 12.4     time 14m 12s      sec/tick 103.6   sec/kimg 25.29   maintenance 0.0    gpumem 8.6   augment 0.104\n",
      "tick 4     kimg 16.5     time 15m 55s      sec/tick 103.7   sec/kimg 25.31   maintenance 0.0    gpumem 8.6   augment 0.134\n",
      "tick 5     kimg 20.6     time 17m 39s      sec/tick 103.8   sec/kimg 25.35   maintenance 0.0    gpumem 8.6   augment 0.168\n",
      "tick 6     kimg 24.7     time 19m 23s      sec/tick 103.9   sec/kimg 25.36   maintenance 0.0    gpumem 8.6   augment 0.198\n",
      "tick 7     kimg 28.8     time 21m 07s      sec/tick 104.0   sec/kimg 25.38   maintenance 0.0    gpumem 8.6   augment 0.224\n",
      "tick 8     kimg 32.9     time 22m 51s      sec/tick 103.9   sec/kimg 25.37   maintenance 0.0    gpumem 8.6   augment 0.244\n",
      "tick 9     kimg 37.0     time 24m 35s      sec/tick 104.1   sec/kimg 25.41   maintenance 0.0    gpumem 8.6   augment 0.270\n",
      "tick 10    kimg 41.1     time 26m 19s      sec/tick 104.1   sec/kimg 25.41   maintenance 0.0    gpumem 8.6   augment 0.293\n",
      "tick 11    kimg 45.2     time 28m 03s      sec/tick 104.1   sec/kimg 25.42   maintenance 0.0    gpumem 8.6   augment 0.301\n",
      "tick 12    kimg 49.3     time 29m 48s      sec/tick 104.1   sec/kimg 25.42   maintenance 0.0    gpumem 8.6   augment 0.308\n",
      "tick 13    kimg 53.4     time 31m 32s      sec/tick 104.1   sec/kimg 25.42   maintenance 0.0    gpumem 8.6   augment 0.311\n",
      "tick 14    kimg 57.5     time 33m 16s      sec/tick 104.1   sec/kimg 25.41   maintenance 0.0    gpumem 8.6   augment 0.316\n",
      "tick 15    kimg 61.6     time 35m 00s      sec/tick 104.0   sec/kimg 25.39   maintenance 0.0    gpumem 8.9   augment 0.316\n",
      "tick 16    kimg 65.7     time 36m 44s      sec/tick 104.1   sec/kimg 25.42   maintenance 0.0    gpumem 8.9   augment 0.319\n",
      "tick 17    kimg 69.8     time 38m 28s      sec/tick 104.1   sec/kimg 25.42   maintenance 0.0    gpumem 8.9   augment 0.319\n",
      "tick 18    kimg 73.9     time 40m 12s      sec/tick 104.1   sec/kimg 25.42   maintenance 0.0    gpumem 8.9   augment 0.321\n",
      "tick 19    kimg 78.0     time 41m 56s      sec/tick 104.1   sec/kimg 25.40   maintenance 0.0    gpumem 8.9   augment 0.321\n",
      "tick 20    kimg 82.0     time 43m 40s      sec/tick 104.1   sec/kimg 25.41   maintenance 0.0    gpumem 8.9   augment 0.324\n",
      "tick 21    kimg 86.1     time 45m 25s      sec/tick 104.3   sec/kimg 25.47   maintenance 0.0    gpumem 8.9   augment 0.316\n",
      "tick 22    kimg 90.2     time 47m 09s      sec/tick 104.1   sec/kimg 25.42   maintenance 0.0    gpumem 8.9   augment 0.311\n",
      "tick 23    kimg 94.3     time 48m 53s      sec/tick 104.1   sec/kimg 25.41   maintenance 0.0    gpumem 8.9   augment 0.314\n",
      "tick 24    kimg 98.4     time 50m 37s      sec/tick 104.1   sec/kimg 25.42   maintenance 0.0    gpumem 8.9   augment 0.316\n",
      "tick 25    kimg 102.5    time 52m 21s      sec/tick 104.1   sec/kimg 25.41   maintenance 0.0    gpumem 8.9   augment 0.319\n",
      "tick 26    kimg 106.6    time 54m 05s      sec/tick 104.0   sec/kimg 25.40   maintenance 0.0    gpumem 8.9   augment 0.319\n",
      "tick 27    kimg 110.7    time 55m 49s      sec/tick 104.0   sec/kimg 25.39   maintenance 0.0    gpumem 8.9   augment 0.308\n",
      "tick 28    kimg 114.8    time 57m 33s      sec/tick 104.0   sec/kimg 25.39   maintenance 0.0    gpumem 8.9   augment 0.314\n",
      "tick 29    kimg 118.9    time 59m 17s      sec/tick 104.1   sec/kimg 25.42   maintenance 0.0    gpumem 8.9   augment 0.311\n",
      "tick 30    kimg 123.0    time 1h 01m 01s   sec/tick 104.1   sec/kimg 25.42   maintenance 0.0    gpumem 8.9   augment 0.311\n",
      "Evaluating metrics...\n",
      "network-snapshot-000123        time 5m 44s       fid50k_full 31.2450\n",
      "tick 31    kimg 127.1    time 1h 08m 38s   sec/tick 104.1   sec/kimg 25.41   maintenance 352.7  gpumem 8.9   augment 0.319\n",
      "tick 32    kimg 131.2    time 1h 10m 22s   sec/tick 104.2   sec/kimg 25.45   maintenance 0.0    gpumem 8.9   augment 0.326\n",
      "tick 33    kimg 135.3    time 1h 12m 07s   sec/tick 104.1   sec/kimg 25.42   maintenance 0.0    gpumem 8.9   augment 0.321\n",
      "tick 34    kimg 139.4    time 1h 13m 51s   sec/tick 104.0   sec/kimg 25.40   maintenance 0.0    gpumem 8.9   augment 0.316\n",
      "tick 35    kimg 143.5    time 1h 15m 35s   sec/tick 104.1   sec/kimg 25.42   maintenance 0.0    gpumem 8.9   augment 0.316\n",
      "tick 36    kimg 147.6    time 1h 17m 19s   sec/tick 104.2   sec/kimg 25.43   maintenance 0.0    gpumem 8.9   augment 0.324\n",
      "tick 37    kimg 151.7    time 1h 19m 03s   sec/tick 104.2   sec/kimg 25.43   maintenance 0.0    gpumem 8.9   augment 0.321\n",
      "tick 38    kimg 155.8    time 1h 20m 47s   sec/tick 104.2   sec/kimg 25.44   maintenance 0.0    gpumem 8.9   augment 0.319\n",
      "tick 39    kimg 159.9    time 1h 22m 31s   sec/tick 104.1   sec/kimg 25.41   maintenance 0.0    gpumem 8.9   augment 0.329\n",
      "tick 40    kimg 164.0    time 1h 24m 16s   sec/tick 104.3   sec/kimg 25.45   maintenance 0.0    gpumem 8.9   augment 0.332\n",
      "tick 41    kimg 168.1    time 1h 26m 00s   sec/tick 104.1   sec/kimg 25.42   maintenance 0.0    gpumem 8.9   augment 0.332\n",
      "tick 42    kimg 172.2    time 1h 27m 44s   sec/tick 104.1   sec/kimg 25.42   maintenance 0.0    gpumem 8.9   augment 0.332\n",
      "tick 43    kimg 176.3    time 1h 29m 28s   sec/tick 104.2   sec/kimg 25.43   maintenance 0.0    gpumem 8.9   augment 0.329\n",
      "tick 44    kimg 180.4    time 1h 31m 12s   sec/tick 104.0   sec/kimg 25.40   maintenance 0.0    gpumem 8.9   augment 0.326\n",
      "tick 45    kimg 184.4    time 1h 32m 56s   sec/tick 104.1   sec/kimg 25.41   maintenance 0.0    gpumem 8.9   augment 0.319\n",
      "tick 46    kimg 188.5    time 1h 34m 40s   sec/tick 104.0   sec/kimg 25.40   maintenance 0.0    gpumem 8.9   augment 0.321\n",
      "tick 47    kimg 192.6    time 1h 36m 24s   sec/tick 104.1   sec/kimg 25.42   maintenance 0.0    gpumem 8.9   augment 0.324\n",
      "tick 48    kimg 196.7    time 1h 38m 09s   sec/tick 104.3   sec/kimg 25.46   maintenance 0.0    gpumem 8.9   augment 0.332\n",
      "tick 49    kimg 200.8    time 1h 39m 53s   sec/tick 104.0   sec/kimg 25.40   maintenance 0.0    gpumem 8.9   augment 0.326\n",
      "tick 50    kimg 204.9    time 1h 41m 37s   sec/tick 104.2   sec/kimg 25.44   maintenance 0.0    gpumem 8.9   augment 0.319\n",
      "tick 51    kimg 209.0    time 1h 43m 21s   sec/tick 104.2   sec/kimg 25.44   maintenance 0.0    gpumem 8.9   augment 0.311\n",
      "tick 52    kimg 213.1    time 1h 45m 05s   sec/tick 103.9   sec/kimg 25.38   maintenance 0.0    gpumem 8.9   augment 0.314\n",
      "tick 53    kimg 217.2    time 1h 46m 49s   sec/tick 103.9   sec/kimg 25.37   maintenance 0.0    gpumem 8.9   augment 0.311\n",
      "tick 54    kimg 221.3    time 1h 48m 33s   sec/tick 104.0   sec/kimg 25.40   maintenance 0.0    gpumem 8.9   augment 0.314\n",
      "tick 55    kimg 225.4    time 1h 50m 17s   sec/tick 104.1   sec/kimg 25.42   maintenance 0.0    gpumem 8.9   augment 0.306\n",
      "tick 56    kimg 229.5    time 1h 52m 01s   sec/tick 104.1   sec/kimg 25.42   maintenance 0.0    gpumem 8.9   augment 0.308\n",
      "tick 57    kimg 233.6    time 1h 53m 45s   sec/tick 103.9   sec/kimg 25.37   maintenance 0.0    gpumem 8.9   augment 0.306\n",
      "tick 58    kimg 237.7    time 1h 55m 29s   sec/tick 103.9   sec/kimg 25.36   maintenance 0.0    gpumem 8.9   augment 0.306\n",
      "tick 59    kimg 241.8    time 1h 57m 13s   sec/tick 104.1   sec/kimg 25.41   maintenance 0.0    gpumem 8.9   augment 0.314\n",
      "tick 60    kimg 245.9    time 1h 58m 57s   sec/tick 103.8   sec/kimg 25.34   maintenance 0.0    gpumem 8.9   augment 0.314\n",
      "Evaluating metrics...\n",
      "network-snapshot-000245        time 5m 42s       fid50k_full 30.1553\n",
      "tick 61    kimg 250.0    time 2h 06m 32s   sec/tick 103.9   sec/kimg 25.38   maintenance 350.9  gpumem 8.9   augment 0.314\n",
      "tick 62    kimg 254.1    time 2h 08m 16s   sec/tick 103.9   sec/kimg 25.37   maintenance 0.0    gpumem 8.9   augment 0.319\n",
      "tick 63    kimg 258.2    time 2h 10m 00s   sec/tick 104.1   sec/kimg 25.40   maintenance 0.0    gpumem 8.9   augment 0.321\n",
      "tick 64    kimg 262.3    time 2h 11m 44s   sec/tick 103.9   sec/kimg 25.37   maintenance 0.0    gpumem 8.9   augment 0.319\n",
      "tick 65    kimg 266.4    time 2h 13m 28s   sec/tick 103.9   sec/kimg 25.36   maintenance 0.0    gpumem 8.9   augment 0.319\n",
      "tick 66    kimg 270.5    time 2h 15m 12s   sec/tick 104.0   sec/kimg 25.39   maintenance 0.0    gpumem 8.9   augment 0.326\n",
      "tick 67    kimg 274.6    time 2h 16m 56s   sec/tick 103.9   sec/kimg 25.37   maintenance 0.0    gpumem 8.9   augment 0.324\n",
      "tick 68    kimg 278.7    time 2h 18m 40s   sec/tick 104.1   sec/kimg 25.41   maintenance 0.0    gpumem 8.9   augment 0.324\n",
      "tick 69    kimg 282.8    time 2h 20m 24s   sec/tick 104.2   sec/kimg 25.44   maintenance 0.0    gpumem 8.9   augment 0.326\n",
      "tick 70    kimg 286.8    time 2h 22m 08s   sec/tick 104.1   sec/kimg 25.41   maintenance 0.0    gpumem 8.9   augment 0.319\n",
      "tick 71    kimg 290.9    time 2h 23m 52s   sec/tick 104.0   sec/kimg 25.40   maintenance 0.0    gpumem 8.9   augment 0.324\n",
      "tick 72    kimg 295.0    time 2h 25m 36s   sec/tick 104.0   sec/kimg 25.38   maintenance 0.0    gpumem 8.9   augment 0.326\n",
      "tick 73    kimg 299.1    time 2h 27m 20s   sec/tick 104.1   sec/kimg 25.40   maintenance 0.0    gpumem 8.9   augment 0.321\n",
      "tick 74    kimg 303.2    time 2h 29m 04s   sec/tick 103.9   sec/kimg 25.38   maintenance 0.0    gpumem 8.9   augment 0.319\n",
      "tick 75    kimg 307.3    time 2h 30m 48s   sec/tick 103.9   sec/kimg 25.38   maintenance 0.0    gpumem 8.9   augment 0.321\n",
      "tick 76    kimg 311.4    time 2h 32m 32s   sec/tick 103.9   sec/kimg 25.38   maintenance 0.0    gpumem 8.9   augment 0.332\n",
      "tick 77    kimg 315.5    time 2h 34m 16s   sec/tick 103.9   sec/kimg 25.36   maintenance 0.0    gpumem 8.9   augment 0.337\n",
      "tick 78    kimg 319.6    time 2h 36m 00s   sec/tick 104.0   sec/kimg 25.40   maintenance 0.0    gpumem 8.9   augment 0.329\n",
      "tick 79    kimg 323.7    time 2h 37m 44s   sec/tick 104.0   sec/kimg 25.39   maintenance 0.0    gpumem 8.9   augment 0.334\n",
      "tick 80    kimg 327.8    time 2h 39m 28s   sec/tick 104.0   sec/kimg 25.39   maintenance 0.0    gpumem 8.9   augment 0.329\n",
      "tick 81    kimg 331.9    time 2h 41m 12s   sec/tick 104.0   sec/kimg 25.39   maintenance 0.0    gpumem 8.9   augment 0.326\n",
      "tick 82    kimg 336.0    time 2h 42m 56s   sec/tick 103.9   sec/kimg 25.38   maintenance 0.0    gpumem 8.9   augment 0.316\n",
      "tick 83    kimg 340.1    time 2h 44m 40s   sec/tick 104.1   sec/kimg 25.42   maintenance 0.0    gpumem 8.9   augment 0.321\n",
      "tick 84    kimg 344.2    time 2h 46m 24s   sec/tick 103.9   sec/kimg 25.37   maintenance 0.0    gpumem 8.9   augment 0.319\n",
      "tick 85    kimg 348.3    time 2h 48m 08s   sec/tick 104.0   sec/kimg 25.39   maintenance 0.0    gpumem 8.9   augment 0.332\n",
      "tick 86    kimg 352.4    time 2h 49m 52s   sec/tick 104.0   sec/kimg 25.38   maintenance 0.0    gpumem 8.9   augment 0.329\n",
      "tick 87    kimg 356.5    time 2h 51m 36s   sec/tick 104.0   sec/kimg 25.38   maintenance 0.0    gpumem 8.9   augment 0.329\n",
      "tick 88    kimg 360.6    time 2h 53m 20s   sec/tick 104.1   sec/kimg 25.41   maintenance 0.0    gpumem 8.9   augment 0.332\n",
      "tick 89    kimg 364.7    time 2h 55m 04s   sec/tick 104.0   sec/kimg 25.40   maintenance 0.0    gpumem 8.9   augment 0.329\n",
      "tick 90    kimg 368.8    time 2h 56m 48s   sec/tick 104.0   sec/kimg 25.40   maintenance 0.0    gpumem 8.9   augment 0.332\n",
      "Evaluating metrics...\n",
      "network-snapshot-000368        time 5m 44s       fid50k_full 28.6500\n",
      "tick 91    kimg 372.9    time 3h 04m 25s   sec/tick 104.0   sec/kimg 25.39   maintenance 352.8  gpumem 8.9   augment 0.326\n",
      "tick 92    kimg 377.0    time 3h 06m 09s   sec/tick 104.1   sec/kimg 25.41   maintenance 0.0    gpumem 8.9   augment 0.329\n",
      "tick 93    kimg 381.1    time 3h 07m 53s   sec/tick 104.0   sec/kimg 25.40   maintenance 0.0    gpumem 8.9   augment 0.332\n",
      "tick 94    kimg 385.2    time 3h 09m 37s   sec/tick 104.1   sec/kimg 25.42   maintenance 0.0    gpumem 8.9   augment 0.337\n",
      "tick 95    kimg 389.2    time 3h 11m 21s   sec/tick 104.1   sec/kimg 25.41   maintenance 0.0    gpumem 8.9   augment 0.329\n",
      "tick 96    kimg 393.3    time 3h 13m 05s   sec/tick 104.0   sec/kimg 25.40   maintenance 0.0    gpumem 8.9   augment 0.326\n",
      "tick 97    kimg 397.4    time 3h 14m 49s   sec/tick 104.1   sec/kimg 25.40   maintenance 0.0    gpumem 8.9   augment 0.326\n",
      "tick 98    kimg 401.5    time 3h 16m 34s   sec/tick 104.0   sec/kimg 25.40   maintenance 0.0    gpumem 8.9   augment 0.334\n",
      "tick 99    kimg 405.6    time 3h 18m 17s   sec/tick 103.9   sec/kimg 25.37   maintenance 0.0    gpumem 8.9   augment 0.329\n",
      "tick 100   kimg 409.7    time 3h 20m 01s   sec/tick 104.0   sec/kimg 25.39   maintenance 0.0    gpumem 8.9   augment 0.329\n",
      "tick 101   kimg 413.8    time 3h 21m 45s   sec/tick 104.0   sec/kimg 25.40   maintenance 0.0    gpumem 8.9   augment 0.326\n",
      "tick 102   kimg 417.9    time 3h 23m 30s   sec/tick 104.1   sec/kimg 25.41   maintenance 0.0    gpumem 8.9   augment 0.329\n",
      "tick 103   kimg 422.0    time 3h 25m 14s   sec/tick 104.0   sec/kimg 25.39   maintenance 0.0    gpumem 8.9   augment 0.326\n",
      "tick 104   kimg 426.1    time 3h 26m 58s   sec/tick 104.0   sec/kimg 25.39   maintenance 0.0    gpumem 8.9   augment 0.332\n",
      "tick 105   kimg 430.2    time 3h 28m 42s   sec/tick 104.0   sec/kimg 25.39   maintenance 0.0    gpumem 8.9   augment 0.321\n",
      "tick 106   kimg 434.3    time 3h 30m 26s   sec/tick 104.1   sec/kimg 25.41   maintenance 0.0    gpumem 8.9   augment 0.321\n",
      "tick 107   kimg 438.4    time 3h 32m 10s   sec/tick 104.1   sec/kimg 25.43   maintenance 0.0    gpumem 8.9   augment 0.339\n",
      "tick 108   kimg 442.5    time 3h 33m 54s   sec/tick 104.0   sec/kimg 25.40   maintenance 0.0    gpumem 8.9   augment 0.342\n",
      "tick 109   kimg 446.6    time 3h 35m 38s   sec/tick 104.0   sec/kimg 25.40   maintenance 0.0    gpumem 8.9   augment 0.347\n",
      "tick 110   kimg 450.7    time 3h 37m 22s   sec/tick 104.0   sec/kimg 25.39   maintenance 0.0    gpumem 8.9   augment 0.332\n",
      "tick 111   kimg 454.8    time 3h 39m 06s   sec/tick 104.1   sec/kimg 25.43   maintenance 0.0    gpumem 8.9   augment 0.334\n",
      "tick 112   kimg 458.9    time 3h 40m 50s   sec/tick 104.0   sec/kimg 25.40   maintenance 0.0    gpumem 8.9   augment 0.326\n",
      "tick 113   kimg 463.0    time 3h 42m 34s   sec/tick 104.1   sec/kimg 25.40   maintenance 0.0    gpumem 8.9   augment 0.334\n",
      "tick 114   kimg 467.1    time 3h 44m 18s   sec/tick 104.0   sec/kimg 25.40   maintenance 0.0    gpumem 8.9   augment 0.337\n",
      "tick 115   kimg 471.2    time 3h 46m 02s   sec/tick 104.0   sec/kimg 25.39   maintenance 0.0    gpumem 8.9   augment 0.337\n",
      "tick 116   kimg 475.3    time 3h 47m 46s   sec/tick 104.1   sec/kimg 25.40   maintenance 0.0    gpumem 8.9   augment 0.334\n",
      "tick 117   kimg 479.4    time 3h 49m 30s   sec/tick 104.1   sec/kimg 25.41   maintenance 0.0    gpumem 8.9   augment 0.329\n",
      "tick 118   kimg 483.5    time 3h 51m 14s   sec/tick 103.9   sec/kimg 25.37   maintenance 0.0    gpumem 8.9   augment 0.332\n",
      "tick 119   kimg 487.6    time 3h 52m 58s   sec/tick 104.0   sec/kimg 25.40   maintenance 0.0    gpumem 8.9   augment 0.332\n",
      "tick 120   kimg 491.6    time 3h 54m 43s   sec/tick 104.1   sec/kimg 25.41   maintenance 0.0    gpumem 8.9   augment 0.337\n",
      "Evaluating metrics...\n",
      "network-snapshot-000491        time 5m 45s       fid50k_full 28.1035\n",
      "tick 121   kimg 495.7    time 4h 02m 20s   sec/tick 104.1   sec/kimg 25.41   maintenance 353.1  gpumem 8.9   augment 0.332\n",
      "tick 122   kimg 499.8    time 4h 04m 04s   sec/tick 104.0   sec/kimg 25.38   maintenance 0.0    gpumem 8.9   augment 0.329\n",
      "tick 123   kimg 503.9    time 4h 05m 48s   sec/tick 103.9   sec/kimg 25.36   maintenance 0.0    gpumem 8.9   augment 0.329\n",
      "tick 124   kimg 508.0    time 4h 07m 32s   sec/tick 104.0   sec/kimg 25.39   maintenance 0.0    gpumem 8.9   augment 0.339\n",
      "tick 125   kimg 512.1    time 4h 09m 16s   sec/tick 104.1   sec/kimg 25.42   maintenance 0.0    gpumem 8.9   augment 0.342\n",
      "tick 126   kimg 516.2    time 4h 11m 00s   sec/tick 104.1   sec/kimg 25.41   maintenance 0.0    gpumem 8.9   augment 0.332\n",
      "tick 127   kimg 520.3    time 4h 12m 44s   sec/tick 104.1   sec/kimg 25.41   maintenance 0.0    gpumem 8.9   augment 0.319\n"
     ]
    }
   ],
   "source": [
    "#!python stylegan2-ada/train.py --snap=30 --outdir=./training-runs --gpus=1 --data=./datasets/logo --res=128 --kimg=700 --mirror=False --gamma=16 --augpipe=bgcfnc --freezed=2 --resume=./training-runs/00003-logo-res128-auto1-gamma16-kimg500-bgcfnc-resumecustom-freezed2/network-snapshot-000080.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traning stage 2: without \"--freezed=2\" parameter (around 1700 kimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T16:55:12.160994Z",
     "iopub.status.busy": "2022-06-15T16:55:12.160680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 16.0\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.6,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1,\n",
      "      \"imgfilter\": 1,\n",
      "      \"noise\": 1,\n",
      "      \"cutout\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 30,\n",
      "  \"network_snapshot_ticks\": 30,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 1000,\n",
      "  \"minibatch_size\": 32,\n",
      "  \"minibatch_gpu\": 32,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"./training-runs/00004-logo-res128-auto1-gamma16-kimg700-bgcfnc-resumecustom-freezed2/network-snapshot-000700.pkl\",\n",
      "  \"run_dir\": \"./training-runs/00005-logo-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom\"\n",
      "}\n",
      "\n",
      "Output directory:  ./training-runs/00005-logo-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom\n",
      "Training data:     ./datasets/logo\n",
      "Training length:   1000 kimg\n",
      "Resolution:        128\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "Image shape: [3, 128, 128]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
      "Resuming from \"./training-runs/00004-logo-res128-auto1-gamma16-kimg700-bgcfnc-resumecustom-freezed2/network-snapshot-000700.pkl\"\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 12, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 12, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "---                           ---       ---                 ---             \n",
      "Total                         22949277                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 128, 128)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "128x128/FromRGB      512       (?, 128, 128, 128)  (1, 1, 3, 128)  \n",
      "128x128/Conv0        147584    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                23882369                                      \n",
      "\n",
      "Exporting sample images...\n",
      "2022-06-15 16:56:02.671530: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 1000 kimg...\n",
      "\n",
      "tick 0     kimg 0.1      time 2m 10s       sec/tick 25.9    sec/kimg 202.06  maintenance 103.8  gpumem 8.2   augment 0.001\n",
      "Evaluating metrics...\n",
      "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/metrics/inception_v3_features.pkl ... done\n",
      "Calculating real image statistics for fid50k_full...\n",
      "network-snapshot-000000        time 11m 50s      fid50k_full 27.2310\n",
      "tick 1     kimg 4.2      time 18m 37s      sec/tick 245.8   sec/kimg 60.01   maintenance 741.8  gpumem 8.7   augment 0.032\n",
      "tick 2     kimg 8.3      time 22m 44s      sec/tick 246.4   sec/kimg 60.15   maintenance 0.0    gpumem 8.7   augment 0.058\n",
      "tick 3     kimg 12.4     time 26m 50s      sec/tick 246.6   sec/kimg 60.20   maintenance 0.0    gpumem 8.8   augment 0.091\n",
      "tick 4     kimg 16.5     time 30m 57s      sec/tick 246.9   sec/kimg 60.27   maintenance 0.0    gpumem 8.8   augment 0.124\n",
      "tick 5     kimg 20.6     time 35m 04s      sec/tick 247.1   sec/kimg 60.33   maintenance 0.0    gpumem 8.8   augment 0.152\n",
      "tick 6     kimg 24.7     time 39m 11s      sec/tick 247.1   sec/kimg 60.32   maintenance 0.0    gpumem 8.8   augment 0.170\n",
      "tick 7     kimg 28.8     time 43m 19s      sec/tick 247.4   sec/kimg 60.39   maintenance 0.0    gpumem 8.8   augment 0.209\n",
      "tick 8     kimg 32.9     time 47m 26s      sec/tick 247.4   sec/kimg 60.41   maintenance 0.0    gpumem 8.8   augment 0.234\n",
      "tick 9     kimg 37.0     time 51m 34s      sec/tick 247.7   sec/kimg 60.46   maintenance 0.0    gpumem 9.2   augment 0.252\n",
      "tick 10    kimg 41.1     time 55m 42s      sec/tick 247.8   sec/kimg 60.50   maintenance 0.0    gpumem 9.2   augment 0.270\n",
      "tick 11    kimg 45.2     time 59m 50s      sec/tick 247.9   sec/kimg 60.52   maintenance 0.0    gpumem 9.2   augment 0.285\n",
      "tick 12    kimg 49.3     time 1h 03m 57s   sec/tick 247.8   sec/kimg 60.50   maintenance 0.0    gpumem 9.2   augment 0.296\n",
      "tick 13    kimg 53.4     time 1h 08m 05s   sec/tick 248.1   sec/kimg 60.56   maintenance 0.0    gpumem 9.2   augment 0.298\n",
      "tick 14    kimg 57.5     time 1h 12m 13s   sec/tick 248.0   sec/kimg 60.55   maintenance 0.0    gpumem 9.2   augment 0.301\n",
      "tick 15    kimg 61.6     time 1h 16m 22s   sec/tick 248.0   sec/kimg 60.55   maintenance 0.0    gpumem 9.2   augment 0.306\n",
      "tick 16    kimg 65.7     time 1h 20m 30s   sec/tick 248.0   sec/kimg 60.55   maintenance 0.0    gpumem 9.2   augment 0.308\n",
      "tick 17    kimg 69.8     time 1h 24m 37s   sec/tick 247.9   sec/kimg 60.51   maintenance 0.0    gpumem 9.2   augment 0.308\n",
      "tick 18    kimg 73.9     time 1h 28m 45s   sec/tick 248.0   sec/kimg 60.55   maintenance 0.0    gpumem 9.2   augment 0.311\n",
      "tick 19    kimg 78.0     time 1h 32m 54s   sec/tick 248.1   sec/kimg 60.56   maintenance 0.0    gpumem 9.2   augment 0.308\n",
      "tick 20    kimg 82.0     time 1h 37m 02s   sec/tick 248.0   sec/kimg 60.55   maintenance 0.0    gpumem 9.2   augment 0.311\n",
      "tick 21    kimg 86.1     time 1h 41m 09s   sec/tick 247.9   sec/kimg 60.51   maintenance 0.0    gpumem 9.2   augment 0.306\n",
      "tick 22    kimg 90.2     time 1h 45m 17s   sec/tick 248.0   sec/kimg 60.54   maintenance 0.0    gpumem 9.2   augment 0.311\n",
      "tick 23    kimg 94.3     time 1h 49m 25s   sec/tick 247.7   sec/kimg 60.48   maintenance 0.0    gpumem 9.2   augment 0.308\n",
      "tick 24    kimg 98.4     time 1h 53m 33s   sec/tick 248.1   sec/kimg 60.57   maintenance 0.0    gpumem 9.2   augment 0.298\n",
      "tick 25    kimg 102.5    time 1h 57m 41s   sec/tick 247.8   sec/kimg 60.50   maintenance 0.0    gpumem 9.2   augment 0.301\n",
      "tick 26    kimg 106.6    time 2h 01m 49s   sec/tick 247.9   sec/kimg 60.52   maintenance 0.0    gpumem 9.2   augment 0.303\n",
      "tick 27    kimg 110.7    time 2h 05m 57s   sec/tick 247.9   sec/kimg 60.53   maintenance 0.0    gpumem 9.2   augment 0.311\n",
      "tick 28    kimg 114.8    time 2h 10m 05s   sec/tick 247.8   sec/kimg 60.50   maintenance 0.0    gpumem 9.2   augment 0.306\n",
      "tick 29    kimg 118.9    time 2h 14m 13s   sec/tick 247.8   sec/kimg 60.49   maintenance 0.0    gpumem 9.2   augment 0.301\n",
      "tick 30    kimg 123.0    time 2h 18m 20s   sec/tick 247.7   sec/kimg 60.47   maintenance 0.0    gpumem 9.2   augment 0.301\n",
      "Evaluating metrics...\n",
      "network-snapshot-000123        time 10m 32s      fid50k_full 28.0125\n",
      "tick 31    kimg 127.1    time 2h 33m 13s   sec/tick 248.0   sec/kimg 60.56   maintenance 644.3  gpumem 9.2   augment 0.303\n",
      "tick 32    kimg 131.2    time 2h 37m 21s   sec/tick 248.2   sec/kimg 60.61   maintenance 0.0    gpumem 9.2   augment 0.303\n",
      "tick 33    kimg 135.3    time 2h 41m 29s   sec/tick 248.1   sec/kimg 60.56   maintenance 0.0    gpumem 9.2   augment 0.306\n",
      "tick 34    kimg 139.4    time 2h 45m 37s   sec/tick 248.1   sec/kimg 60.57   maintenance 0.0    gpumem 9.2   augment 0.306\n",
      "tick 35    kimg 143.5    time 2h 49m 45s   sec/tick 248.0   sec/kimg 60.55   maintenance 0.0    gpumem 9.2   augment 0.311\n",
      "tick 36    kimg 147.6    time 2h 53m 53s   sec/tick 247.9   sec/kimg 60.52   maintenance 0.0    gpumem 9.2   augment 0.311\n",
      "tick 37    kimg 151.7    time 2h 58m 01s   sec/tick 248.1   sec/kimg 60.56   maintenance 0.0    gpumem 9.2   augment 0.316\n",
      "tick 38    kimg 155.8    time 3h 02m 09s   sec/tick 248.1   sec/kimg 60.56   maintenance 0.0    gpumem 9.2   augment 0.319\n",
      "tick 39    kimg 159.9    time 3h 06m 17s   sec/tick 248.1   sec/kimg 60.57   maintenance 0.0    gpumem 9.2   augment 0.326\n",
      "tick 40    kimg 164.0    time 3h 10m 25s   sec/tick 248.2   sec/kimg 60.59   maintenance 0.0    gpumem 9.2   augment 0.337\n",
      "tick 41    kimg 168.1    time 3h 14m 34s   sec/tick 248.3   sec/kimg 60.61   maintenance 0.0    gpumem 9.2   augment 0.329\n",
      "tick 42    kimg 172.2    time 3h 18m 42s   sec/tick 248.1   sec/kimg 60.57   maintenance 0.0    gpumem 9.2   augment 0.319\n",
      "tick 43    kimg 176.3    time 3h 22m 50s   sec/tick 248.1   sec/kimg 60.58   maintenance 0.0    gpumem 9.2   augment 0.311\n",
      "tick 44    kimg 180.4    time 3h 26m 58s   sec/tick 248.2   sec/kimg 60.60   maintenance 0.0    gpumem 9.2   augment 0.321\n",
      "tick 45    kimg 184.4    time 3h 31m 06s   sec/tick 248.1   sec/kimg 60.58   maintenance 0.0    gpumem 9.2   augment 0.321\n",
      "tick 46    kimg 188.5    time 3h 35m 15s   sec/tick 248.1   sec/kimg 60.58   maintenance 0.0    gpumem 9.2   augment 0.316\n",
      "tick 47    kimg 192.6    time 3h 39m 23s   sec/tick 248.3   sec/kimg 60.63   maintenance 0.0    gpumem 9.2   augment 0.308\n",
      "tick 48    kimg 196.7    time 3h 43m 31s   sec/tick 248.1   sec/kimg 60.57   maintenance 0.0    gpumem 9.2   augment 0.306\n",
      "tick 49    kimg 200.8    time 3h 47m 39s   sec/tick 248.2   sec/kimg 60.59   maintenance 0.0    gpumem 9.2   augment 0.314\n",
      "tick 50    kimg 204.9    time 3h 51m 47s   sec/tick 248.3   sec/kimg 60.61   maintenance 0.0    gpumem 9.2   augment 0.324\n",
      "tick 51    kimg 209.0    time 3h 55m 56s   sec/tick 248.2   sec/kimg 60.59   maintenance 0.0    gpumem 9.2   augment 0.321\n",
      "tick 52    kimg 213.1    time 4h 00m 04s   sec/tick 248.2   sec/kimg 60.58   maintenance 0.0    gpumem 9.2   augment 0.332\n",
      "tick 53    kimg 217.2    time 4h 04m 12s   sec/tick 248.3   sec/kimg 60.62   maintenance 0.0    gpumem 9.2   augment 0.329\n",
      "tick 54    kimg 221.3    time 4h 08m 20s   sec/tick 248.3   sec/kimg 60.61   maintenance 0.0    gpumem 9.2   augment 0.332\n",
      "tick 55    kimg 225.4    time 4h 12m 29s   sec/tick 248.5   sec/kimg 60.67   maintenance 0.0    gpumem 9.2   augment 0.339\n",
      "tick 56    kimg 229.5    time 4h 16m 37s   sec/tick 248.3   sec/kimg 60.63   maintenance 0.0    gpumem 9.2   augment 0.344\n",
      "tick 57    kimg 233.6    time 4h 20m 46s   sec/tick 248.3   sec/kimg 60.61   maintenance 0.0    gpumem 9.2   augment 0.347\n",
      "tick 58    kimg 237.7    time 4h 24m 54s   sec/tick 248.5   sec/kimg 60.67   maintenance 0.0    gpumem 9.2   augment 0.344\n",
      "tick 59    kimg 241.8    time 4h 29m 04s   sec/tick 249.5   sec/kimg 60.90   maintenance 0.0    gpumem 9.2   augment 0.347\n",
      "tick 60    kimg 245.9    time 4h 33m 15s   sec/tick 251.0   sec/kimg 61.27   maintenance 0.0    gpumem 9.2   augment 0.344\n",
      "Evaluating metrics...\n",
      "network-snapshot-000245        time 10m 45s      fid50k_full 27.2700\n",
      "tick 61    kimg 250.0    time 4h 48m 24s   sec/tick 250.1   sec/kimg 61.05   maintenance 658.9  gpumem 9.2   augment 0.332\n",
      "tick 62    kimg 254.1    time 4h 52m 33s   sec/tick 249.5   sec/kimg 60.90   maintenance 0.0    gpumem 9.2   augment 0.324\n",
      "tick 63    kimg 258.2    time 4h 56m 42s   sec/tick 249.4   sec/kimg 60.88   maintenance 0.0    gpumem 9.2   augment 0.326\n",
      "tick 64    kimg 262.3    time 5h 00m 52s   sec/tick 249.4   sec/kimg 60.88   maintenance 0.0    gpumem 9.2   augment 0.324\n",
      "tick 65    kimg 266.4    time 5h 05m 01s   sec/tick 249.5   sec/kimg 60.92   maintenance 0.0    gpumem 9.2   augment 0.324\n",
      "tick 66    kimg 270.5    time 5h 09m 10s   sec/tick 249.0   sec/kimg 60.78   maintenance 0.0    gpumem 9.2   augment 0.319\n",
      "tick 67    kimg 274.6    time 5h 13m 19s   sec/tick 248.8   sec/kimg 60.75   maintenance 0.0    gpumem 9.2   augment 0.316\n",
      "tick 68    kimg 278.7    time 5h 17m 28s   sec/tick 248.7   sec/kimg 60.72   maintenance 0.0    gpumem 9.2   augment 0.311\n",
      "tick 69    kimg 282.8    time 5h 21m 36s   sec/tick 248.6   sec/kimg 60.70   maintenance 0.0    gpumem 9.2   augment 0.311\n",
      "tick 70    kimg 286.8    time 5h 25m 45s   sec/tick 248.6   sec/kimg 60.69   maintenance 0.0    gpumem 9.2   augment 0.308\n",
      "tick 73    kimg 299.1    time 5h 38m 11s   sec/tick 248.8   sec/kimg 60.74   maintenance 0.0    gpumem 9.2   augment 0.319\n"
     ]
    }
   ],
   "source": [
    "#!python stylegan2-ada/train.py --snap=30 --outdir=./training-runs --gpus=1 --data=./datasets/logo --res=128 --kimg=1000 --mirror=False --gamma=16 --augpipe=bgcfnc --resume=./training-runs/00004-logo-res128-auto1-gamma16-kimg700-bgcfnc-resumecustom-freezed2/network-snapshot-000700.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T22:40:15.871615Z",
     "iopub.status.busy": "2022-06-15T22:40:15.871327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 16.0\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.6,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1,\n",
      "      \"imgfilter\": 1,\n",
      "      \"noise\": 1,\n",
      "      \"cutout\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 30,\n",
      "  \"network_snapshot_ticks\": 30,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 1000,\n",
      "  \"minibatch_size\": 32,\n",
      "  \"minibatch_gpu\": 32,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"./training-runs/00005-logo-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom/network-snapshot-000245.pkl\",\n",
      "  \"run_dir\": \"./training-runs/00006-logo-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom\"\n",
      "}\n",
      "\n",
      "Output directory:  ./training-runs/00006-logo-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom\n",
      "Training data:     ./datasets/logo\n",
      "Training length:   1000 kimg\n",
      "Resolution:        128\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "Image shape: [3, 128, 128]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
      "Resuming from \"./training-runs/00005-logo-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom/network-snapshot-000245.pkl\"\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 12, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 12, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "---                           ---       ---                 ---             \n",
      "Total                         22949277                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 128, 128)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "128x128/FromRGB      512       (?, 128, 128, 128)  (1, 1, 3, 128)  \n",
      "128x128/Conv0        147584    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                23882369                                      \n",
      "\n",
      "Exporting sample images...\n",
      "2022-06-15 22:40:58.122584: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 1000 kimg...\n",
      "\n",
      "tick 0     kimg 0.1      time 1m 40s       sec/tick 20.0    sec/kimg 156.22  maintenance 80.5   gpumem 8.3   augment 0.001\n",
      "Evaluating metrics...\n",
      "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/metrics/inception_v3_features.pkl ... done\n",
      "Calculating real image statistics for fid50k_full...\n",
      "network-snapshot-000000        time 6m 44s       fid50k_full 27.1637\n",
      "tick 1     kimg 4.2      time 10m 37s      sec/tick 108.9   sec/kimg 26.60   maintenance 427.2  gpumem 8.6   augment 0.040\n",
      "tick 2     kimg 8.3      time 12m 26s      sec/tick 109.4   sec/kimg 26.71   maintenance 0.0    gpumem 8.6   augment 0.070\n",
      "tick 3     kimg 12.4     time 14m 15s      sec/tick 109.5   sec/kimg 26.72   maintenance 0.0    gpumem 8.6   augment 0.104\n",
      "tick 4     kimg 16.5     time 16m 05s      sec/tick 109.4   sec/kimg 26.71   maintenance 0.0    gpumem 8.6   augment 0.140\n",
      "tick 5     kimg 20.6     time 17m 54s      sec/tick 109.5   sec/kimg 26.74   maintenance 0.0    gpumem 8.6   augment 0.165\n",
      "tick 6     kimg 24.7     time 19m 44s      sec/tick 109.6   sec/kimg 26.77   maintenance 0.0    gpumem 8.7   augment 0.193\n",
      "tick 7     kimg 28.8     time 21m 34s      sec/tick 109.8   sec/kimg 26.81   maintenance 0.0    gpumem 8.7   augment 0.224\n"
     ]
    }
   ],
   "source": [
    "#!python stylegan2-ada/train.py --snap=30 --outdir=./training-runs --gpus=1 --data=./datasets/logo --res=128 --kimg=1000 --mirror=False --gamma=16 --augpipe=bgcfnc --resume=./training-runs/00005-logo-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom/network-snapshot-000245.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T10:02:34.573398Z",
     "iopub.status.busy": "2022-06-16T10:02:34.572999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 16.0\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.6,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1,\n",
      "      \"imgfilter\": 1,\n",
      "      \"noise\": 1,\n",
      "      \"cutout\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 30,\n",
      "  \"network_snapshot_ticks\": 30,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 1000,\n",
      "  \"minibatch_size\": 32,\n",
      "  \"minibatch_gpu\": 32,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"./training-runs/00006-logo-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom/network-snapshot-000614.pkl\",\n",
      "  \"run_dir\": \"./training-runs-full/00000-logo-full-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom\"\n",
      "}\n",
      "\n",
      "Output directory:  ./training-runs-full/00000-logo-full-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom\n",
      "Training data:     ./datasets/logo-full\n",
      "Training length:   1000 kimg\n",
      "Resolution:        128\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "Image shape: [3, 128, 128]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
      "Resuming from \"./training-runs/00006-logo-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom/network-snapshot-000614.pkl\"\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 12, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 12, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "---                           ---       ---                 ---             \n",
      "Total                         22949277                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 128, 128)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "128x128/FromRGB      512       (?, 128, 128, 128)  (1, 1, 3, 128)  \n",
      "128x128/Conv0        147584    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                23882369                                      \n",
      "\n",
      "Exporting sample images...\n",
      "2022-06-16 10:03:32.690257: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 1000 kimg...\n",
      "\n",
      "tick 0     kimg 0.1      time 2m 23s       sec/tick 27.7    sec/kimg 216.31  maintenance 115.8  gpumem 8.9   augment 0.001\n",
      "Evaluating metrics...\n",
      "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/metrics/inception_v3_features.pkl ... done\n",
      "Calculating real image statistics for fid50k_full...\n",
      "network-snapshot-000000        time 12m 40s      fid50k_full 24.3327\n",
      "tick 1     kimg 4.2      time 19m 43s      sec/tick 246.8   sec/kimg 60.25   maintenance 792.6  gpumem 8.9   augment 0.029\n",
      "tick 2     kimg 8.3      time 23m 51s      sec/tick 247.6   sec/kimg 60.45   maintenance 0.0    gpumem 8.9   augment 0.065\n",
      "tick 3     kimg 12.4     time 27m 58s      sec/tick 247.8   sec/kimg 60.49   maintenance 0.0    gpumem 8.9   augment 0.096\n",
      "tick 4     kimg 16.5     time 32m 06s      sec/tick 247.9   sec/kimg 60.53   maintenance 0.0    gpumem 8.9   augment 0.132\n",
      "tick 5     kimg 20.6     time 36m 14s      sec/tick 248.1   sec/kimg 60.58   maintenance 0.0    gpumem 8.9   augment 0.157\n",
      "tick 6     kimg 24.7     time 40m 23s      sec/tick 248.5   sec/kimg 60.67   maintenance 0.0    gpumem 8.9   augment 0.193\n",
      "tick 7     kimg 28.8     time 44m 32s      sec/tick 248.6   sec/kimg 60.69   maintenance 0.0    gpumem 8.9   augment 0.219\n",
      "tick 8     kimg 32.9     time 48m 40s      sec/tick 248.5   sec/kimg 60.66   maintenance 0.0    gpumem 8.9   augment 0.239\n",
      "tick 9     kimg 37.0     time 52m 49s      sec/tick 248.8   sec/kimg 60.73   maintenance 0.0    gpumem 8.9   augment 0.257\n",
      "tick 10    kimg 41.1     time 56m 58s      sec/tick 249.4   sec/kimg 60.89   maintenance 0.0    gpumem 8.9   augment 0.270\n",
      "tick 11    kimg 45.2     time 1h 01m 07s   sec/tick 248.7   sec/kimg 60.73   maintenance 0.0    gpumem 8.9   augment 0.275\n",
      "tick 12    kimg 49.3     time 1h 05m 16s   sec/tick 248.8   sec/kimg 60.74   maintenance 0.0    gpumem 8.9   augment 0.288\n",
      "tick 13    kimg 53.4     time 1h 09m 24s   sec/tick 248.6   sec/kimg 60.68   maintenance 0.0    gpumem 8.9   augment 0.296\n",
      "tick 49    kimg 200.8    time 3h 49m 34s   sec/tick 249.3   sec/kimg 60.86   maintenance 0.0    gpumem 8.9   augment 0.321\n"
     ]
    }
   ],
   "source": [
    "#!python stylegan2-ada/train.py --snap=30 --outdir=./training-runs-full --gpus=1 --data=./datasets/logo-full --res=128 --kimg=1000 --mirror=False --gamma=16 --augpipe=bgcfnc --resume=./training-runs/00006-logo-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom/network-snapshot-000614.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T17:04:34.057251Z",
     "iopub.status.busy": "2022-06-16T17:04:34.056977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 16.0\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.6,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1,\n",
      "      \"imgfilter\": 1,\n",
      "      \"noise\": 1,\n",
      "      \"cutout\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 30,\n",
      "  \"network_snapshot_ticks\": 30,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 1000,\n",
      "  \"minibatch_size\": 32,\n",
      "  \"minibatch_gpu\": 32,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"./training-runs-full/00000-logo-full-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom/network-snapshot-000245.pkl\",\n",
      "  \"run_dir\": \"./training-runs-full/00001-logo-full-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom\"\n",
      "}\n",
      "\n",
      "Output directory:  ./training-runs-full/00001-logo-full-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom\n",
      "Training data:     ./datasets/logo-full\n",
      "Training length:   1000 kimg\n",
      "Resolution:        128\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "Image shape: [3, 128, 128]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
      "Resuming from \"./training-runs-full/00000-logo-full-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom/network-snapshot-000245.pkl\"\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 12, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 12, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "---                           ---       ---                 ---             \n",
      "Total                         22949277                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 128, 128)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "128x128/FromRGB      512       (?, 128, 128, 128)  (1, 1, 3, 128)  \n",
      "128x128/Conv0        147584    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                23882369                                      \n",
      "\n",
      "Exporting sample images...\n",
      "2022-06-16 17:05:20.045491: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 1000 kimg...\n",
      "\n",
      "tick 0     kimg 0.1      time 1m 49s       sec/tick 20.5    sec/kimg 160.15  maintenance 88.8   gpumem 8.5   augment 0.001\n",
      "Evaluating metrics...\n",
      "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/metrics/inception_v3_features.pkl ... done\n",
      "Calculating real image statistics for fid50k_full...\n",
      "network-snapshot-000000        time 7m 19s       fid50k_full 22.2586\n",
      "tick 1     kimg 4.2      time 11m 22s      sec/tick 108.9   sec/kimg 26.58   maintenance 463.8  gpumem 8.7   augment 0.035\n",
      "tick 2     kimg 8.3      time 13m 11s      sec/tick 109.4   sec/kimg 26.71   maintenance 0.0    gpumem 8.7   augment 0.070\n",
      "tick 3     kimg 12.4     time 15m 01s      sec/tick 109.3   sec/kimg 26.68   maintenance 0.0    gpumem 8.7   augment 0.104\n",
      "tick 4     kimg 16.5     time 16m 50s      sec/tick 109.3   sec/kimg 26.69   maintenance 0.0    gpumem 8.7   augment 0.137\n",
      "tick 5     kimg 20.6     time 18m 40s      sec/tick 109.5   sec/kimg 26.73   maintenance 0.0    gpumem 8.7   augment 0.165\n",
      "tick 6     kimg 24.7     time 20m 29s      sec/tick 109.5   sec/kimg 26.73   maintenance 0.0    gpumem 8.7   augment 0.196\n",
      "tick 7     kimg 28.8     time 22m 19s      sec/tick 109.6   sec/kimg 26.76   maintenance 0.0    gpumem 8.7   augment 0.227\n",
      "tick 8     kimg 32.9     time 24m 08s      sec/tick 109.7   sec/kimg 26.78   maintenance 0.0    gpumem 8.7   augment 0.247\n",
      "tick 9     kimg 37.0     time 25m 58s      sec/tick 109.7   sec/kimg 26.79   maintenance 0.0    gpumem 8.7   augment 0.270\n",
      "tick 10    kimg 41.1     time 27m 48s      sec/tick 109.6   sec/kimg 26.77   maintenance 0.0    gpumem 8.7   augment 0.283\n",
      "tick 11    kimg 45.2     time 29m 38s      sec/tick 109.8   sec/kimg 26.80   maintenance 0.0    gpumem 8.7   augment 0.301\n",
      "tick 12    kimg 49.3     time 31m 27s      sec/tick 109.8   sec/kimg 26.81   maintenance 0.0    gpumem 8.7   augment 0.308\n",
      "tick 13    kimg 53.4     time 33m 17s      sec/tick 109.9   sec/kimg 26.82   maintenance 0.0    gpumem 8.7   augment 0.311\n",
      "tick 14    kimg 57.5     time 35m 07s      sec/tick 109.8   sec/kimg 26.80   maintenance 0.0    gpumem 8.7   augment 0.311\n",
      "tick 15    kimg 61.6     time 36m 57s      sec/tick 109.8   sec/kimg 26.81   maintenance 0.0    gpumem 8.7   augment 0.308\n",
      "tick 16    kimg 65.7     time 38m 47s      sec/tick 109.7   sec/kimg 26.78   maintenance 0.0    gpumem 8.7   augment 0.306\n",
      "tick 17    kimg 69.8     time 40m 36s      sec/tick 109.8   sec/kimg 26.82   maintenance 0.0    gpumem 8.7   augment 0.316\n",
      "tick 18    kimg 73.9     time 42m 26s      sec/tick 109.8   sec/kimg 26.82   maintenance 0.0    gpumem 8.7   augment 0.326\n",
      "tick 19    kimg 78.0     time 44m 16s      sec/tick 109.8   sec/kimg 26.81   maintenance 0.0    gpumem 8.7   augment 0.329\n",
      "tick 20    kimg 82.0     time 46m 06s      sec/tick 109.7   sec/kimg 26.79   maintenance 0.0    gpumem 8.7   augment 0.329\n",
      "tick 21    kimg 86.1     time 47m 56s      sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 8.7   augment 0.332\n",
      "tick 22    kimg 90.2     time 49m 46s      sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.7   augment 0.332\n",
      "tick 23    kimg 94.3     time 51m 36s      sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 8.7   augment 0.329\n",
      "tick 24    kimg 98.4     time 53m 26s      sec/tick 109.8   sec/kimg 26.82   maintenance 0.0    gpumem 8.7   augment 0.321\n",
      "tick 25    kimg 102.5    time 55m 15s      sec/tick 109.8   sec/kimg 26.80   maintenance 0.0    gpumem 8.7   augment 0.326\n",
      "tick 26    kimg 106.6    time 57m 05s      sec/tick 109.8   sec/kimg 26.81   maintenance 0.0    gpumem 8.7   augment 0.332\n",
      "tick 27    kimg 110.7    time 58m 55s      sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 8.7   augment 0.326\n",
      "tick 28    kimg 114.8    time 1h 00m 45s   sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 8.7   augment 0.329\n",
      "tick 29    kimg 118.9    time 1h 02m 35s   sec/tick 109.8   sec/kimg 26.82   maintenance 0.0    gpumem 8.7   augment 0.321\n",
      "tick 30    kimg 123.0    time 1h 04m 25s   sec/tick 109.8   sec/kimg 26.81   maintenance 0.0    gpumem 8.7   augment 0.319\n",
      "Evaluating metrics...\n",
      "network-snapshot-000123        time 5m 40s       fid50k_full 22.4545\n",
      "tick 31    kimg 127.1    time 1h 12m 03s   sec/tick 109.9   sec/kimg 26.84   maintenance 348.1  gpumem 8.7   augment 0.332\n",
      "tick 32    kimg 131.2    time 1h 13m 53s   sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 8.7   augment 0.332\n",
      "tick 33    kimg 135.3    time 1h 15m 43s   sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 8.7   augment 0.334\n",
      "tick 34    kimg 139.4    time 1h 17m 33s   sec/tick 109.8   sec/kimg 26.81   maintenance 0.0    gpumem 8.7   augment 0.342\n",
      "tick 35    kimg 143.5    time 1h 19m 23s   sec/tick 109.8   sec/kimg 26.81   maintenance 0.0    gpumem 8.7   augment 0.342\n",
      "tick 36    kimg 147.6    time 1h 21m 13s   sec/tick 109.8   sec/kimg 26.81   maintenance 0.0    gpumem 8.7   augment 0.339\n",
      "tick 37    kimg 151.7    time 1h 23m 03s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 8.7   augment 0.339\n",
      "tick 38    kimg 155.8    time 1h 24m 53s   sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 8.7   augment 0.339\n",
      "tick 39    kimg 159.9    time 1h 26m 43s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 8.7   augment 0.334\n",
      "tick 40    kimg 164.0    time 1h 28m 32s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.7   augment 0.334\n",
      "tick 41    kimg 168.1    time 1h 30m 22s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 8.7   augment 0.337\n",
      "tick 42    kimg 172.2    time 1h 32m 12s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 8.7   augment 0.337\n",
      "tick 43    kimg 176.3    time 1h 34m 02s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.7   augment 0.337\n",
      "tick 44    kimg 180.4    time 1h 35m 52s   sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 8.7   augment 0.339\n",
      "tick 45    kimg 184.4    time 1h 37m 42s   sec/tick 109.7   sec/kimg 26.79   maintenance 0.0    gpumem 8.7   augment 0.342\n",
      "tick 46    kimg 188.5    time 1h 39m 32s   sec/tick 109.8   sec/kimg 26.81   maintenance 0.0    gpumem 8.7   augment 0.342\n",
      "tick 47    kimg 192.6    time 1h 41m 22s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 8.7   augment 0.337\n",
      "tick 48    kimg 196.7    time 1h 43m 12s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.7   augment 0.337\n",
      "tick 49    kimg 200.8    time 1h 45m 02s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 8.7   augment 0.339\n",
      "tick 50    kimg 204.9    time 1h 46m 52s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.7   augment 0.339\n",
      "tick 51    kimg 209.0    time 1h 48m 42s   sec/tick 109.9   sec/kimg 26.82   maintenance 0.0    gpumem 8.7   augment 0.332\n",
      "tick 52    kimg 213.1    time 1h 50m 31s   sec/tick 109.8   sec/kimg 26.82   maintenance 0.0    gpumem 8.7   augment 0.324\n",
      "tick 53    kimg 217.2    time 1h 52m 21s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.7   augment 0.326\n",
      "tick 54    kimg 221.3    time 1h 54m 11s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.7   augment 0.332\n",
      "tick 55    kimg 225.4    time 1h 56m 01s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 8.7   augment 0.334\n",
      "tick 56    kimg 229.5    time 1h 57m 51s   sec/tick 109.7   sec/kimg 26.79   maintenance 0.0    gpumem 8.7   augment 0.339\n",
      "tick 57    kimg 233.6    time 1h 59m 41s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.7   augment 0.332\n",
      "tick 58    kimg 237.7    time 2h 01m 31s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.7   augment 0.332\n",
      "tick 59    kimg 241.8    time 2h 03m 21s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 8.7   augment 0.337\n",
      "tick 60    kimg 245.9    time 2h 05m 11s   sec/tick 109.8   sec/kimg 26.81   maintenance 0.0    gpumem 8.7   augment 0.339\n",
      "Evaluating metrics...\n",
      "network-snapshot-000245        time 5m 39s       fid50k_full 20.8016\n",
      "tick 61    kimg 250.0    time 2h 12m 48s   sec/tick 109.9   sec/kimg 26.83   maintenance 347.4  gpumem 8.7   augment 0.339\n",
      "tick 62    kimg 254.1    time 2h 14m 38s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 8.7   augment 0.342\n",
      "tick 63    kimg 258.2    time 2h 16m 28s   sec/tick 109.8   sec/kimg 26.80   maintenance 0.0    gpumem 8.7   augment 0.337\n",
      "tick 64    kimg 262.3    time 2h 18m 18s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.7   augment 0.337\n",
      "tick 65    kimg 266.4    time 2h 20m 07s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.7   augment 0.337\n",
      "tick 66    kimg 270.5    time 2h 21m 57s   sec/tick 110.0   sec/kimg 26.87   maintenance 0.0    gpumem 8.7   augment 0.342\n",
      "tick 67    kimg 274.6    time 2h 23m 47s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 8.7   augment 0.349\n",
      "tick 68    kimg 278.7    time 2h 25m 37s   sec/tick 109.9   sec/kimg 26.82   maintenance 0.0    gpumem 8.7   augment 0.349\n",
      "tick 69    kimg 282.8    time 2h 27m 27s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 8.7   augment 0.344\n",
      "tick 70    kimg 286.8    time 2h 29m 17s   sec/tick 109.9   sec/kimg 26.82   maintenance 0.0    gpumem 8.7   augment 0.339\n",
      "tick 71    kimg 290.9    time 2h 31m 07s   sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 8.7   augment 0.339\n",
      "tick 72    kimg 295.0    time 2h 32m 57s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.7   augment 0.332\n",
      "tick 73    kimg 299.1    time 2h 34m 47s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 8.7   augment 0.334\n",
      "tick 74    kimg 303.2    time 2h 36m 37s   sec/tick 109.9   sec/kimg 26.82   maintenance 0.0    gpumem 8.7   augment 0.326\n",
      "tick 75    kimg 307.3    time 2h 38m 27s   sec/tick 109.8   sec/kimg 26.81   maintenance 0.0    gpumem 8.7   augment 0.326\n",
      "tick 76    kimg 311.4    time 2h 40m 17s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 8.7   augment 0.334\n",
      "tick 77    kimg 315.5    time 2h 42m 07s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 8.7   augment 0.329\n",
      "tick 78    kimg 319.6    time 2h 43m 57s   sec/tick 109.8   sec/kimg 26.82   maintenance 0.0    gpumem 8.7   augment 0.332\n",
      "tick 79    kimg 323.7    time 2h 45m 47s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 8.7   augment 0.329\n",
      "tick 80    kimg 327.8    time 2h 47m 37s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 8.7   augment 0.329\n",
      "tick 81    kimg 331.9    time 2h 49m 27s   sec/tick 109.9   sec/kimg 26.82   maintenance 0.0    gpumem 8.7   augment 0.337\n",
      "tick 82    kimg 336.0    time 2h 51m 16s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.7   augment 0.334\n",
      "tick 83    kimg 340.1    time 2h 53m 06s   sec/tick 109.8   sec/kimg 26.82   maintenance 0.0    gpumem 8.7   augment 0.332\n",
      "tick 84    kimg 344.2    time 2h 54m 56s   sec/tick 109.6   sec/kimg 26.75   maintenance 0.0    gpumem 8.7   augment 0.344\n",
      "tick 85    kimg 348.3    time 2h 56m 46s   sec/tick 109.8   sec/kimg 26.80   maintenance 0.0    gpumem 8.7   augment 0.342\n",
      "tick 86    kimg 352.4    time 2h 58m 36s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 8.7   augment 0.332\n",
      "tick 87    kimg 356.5    time 3h 00m 26s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 8.7   augment 0.326\n",
      "tick 88    kimg 360.6    time 3h 02m 15s   sec/tick 109.8   sec/kimg 26.81   maintenance 0.0    gpumem 8.7   augment 0.314\n",
      "tick 89    kimg 364.7    time 3h 04m 05s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.7   augment 0.319\n",
      "tick 90    kimg 368.8    time 3h 05m 55s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.7   augment 0.314\n",
      "Evaluating metrics...\n",
      "network-snapshot-000368        time 5m 41s       fid50k_full 20.9908\n",
      "tick 91    kimg 372.9    time 3h 13m 34s   sec/tick 109.8   sec/kimg 26.80   maintenance 349.3  gpumem 8.7   augment 0.319\n",
      "tick 92    kimg 377.0    time 3h 15m 24s   sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 8.7   augment 0.329\n",
      "tick 93    kimg 381.1    time 3h 17m 14s   sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 8.7   augment 0.329\n",
      "tick 94    kimg 385.2    time 3h 19m 04s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.7   augment 0.326\n",
      "tick 95    kimg 389.2    time 3h 20m 54s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.7   augment 0.319\n",
      "tick 96    kimg 393.3    time 3h 22m 44s   sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 8.7   augment 0.319\n",
      "tick 97    kimg 397.4    time 3h 24m 34s   sec/tick 109.9   sec/kimg 26.82   maintenance 0.0    gpumem 8.7   augment 0.326\n",
      "tick 98    kimg 401.5    time 3h 26m 24s   sec/tick 110.1   sec/kimg 26.87   maintenance 0.0    gpumem 8.7   augment 0.321\n",
      "tick 99    kimg 405.6    time 3h 28m 14s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 8.7   augment 0.332\n",
      "tick 100   kimg 409.7    time 3h 30m 04s   sec/tick 109.8   sec/kimg 26.81   maintenance 0.0    gpumem 8.7   augment 0.337\n",
      "tick 101   kimg 413.8    time 3h 31m 54s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 8.7   augment 0.337\n",
      "tick 102   kimg 417.9    time 3h 33m 44s   sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 8.7   augment 0.329\n",
      "tick 103   kimg 422.0    time 3h 35m 34s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 8.7   augment 0.329\n",
      "tick 104   kimg 426.1    time 3h 37m 24s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 8.7   augment 0.334\n",
      "tick 105   kimg 430.2    time 3h 39m 14s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.7   augment 0.329\n",
      "tick 106   kimg 434.3    time 3h 41m 04s   sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 8.7   augment 0.339\n",
      "tick 107   kimg 438.4    time 3h 42m 54s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.7   augment 0.339\n",
      "tick 108   kimg 442.5    time 3h 44m 44s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.7   augment 0.334\n",
      "tick 109   kimg 446.6    time 3h 46m 34s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 8.7   augment 0.339\n",
      "tick 110   kimg 450.7    time 3h 48m 24s   sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 8.7   augment 0.347\n",
      "tick 111   kimg 454.8    time 3h 50m 14s   sec/tick 110.0   sec/kimg 26.87   maintenance 0.0    gpumem 8.7   augment 0.347\n",
      "tick 112   kimg 458.9    time 3h 52m 04s   sec/tick 109.8   sec/kimg 26.80   maintenance 0.0    gpumem 8.7   augment 0.339\n",
      "tick 113   kimg 463.0    time 3h 53m 54s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 8.7   augment 0.334\n",
      "tick 114   kimg 467.1    time 3h 55m 44s   sec/tick 110.0   sec/kimg 26.84   maintenance 0.0    gpumem 8.7   augment 0.334\n",
      "tick 115   kimg 471.2    time 3h 57m 33s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.7   augment 0.332\n",
      "tick 116   kimg 475.3    time 3h 59m 23s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 8.7   augment 0.324\n",
      "tick 117   kimg 479.4    time 4h 01m 13s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 8.7   augment 0.329\n",
      "tick 118   kimg 483.5    time 4h 03m 03s   sec/tick 109.8   sec/kimg 26.82   maintenance 0.0    gpumem 8.7   augment 0.321\n",
      "tick 119   kimg 487.6    time 4h 04m 53s   sec/tick 109.8   sec/kimg 26.81   maintenance 0.0    gpumem 8.7   augment 0.326\n",
      "tick 120   kimg 491.6    time 4h 06m 43s   sec/tick 109.9   sec/kimg 26.82   maintenance 0.0    gpumem 8.7   augment 0.321\n",
      "Evaluating metrics...\n",
      "network-snapshot-000491        time 5m 40s       fid50k_full 21.0367\n",
      "tick 121   kimg 495.7    time 4h 14m 21s   sec/tick 109.8   sec/kimg 26.80   maintenance 348.3  gpumem 8.7   augment 0.324\n",
      "tick 122   kimg 499.8    time 4h 16m 11s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 8.7   augment 0.326\n",
      "tick 123   kimg 503.9    time 4h 18m 01s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.7   augment 0.324\n",
      "tick 124   kimg 508.0    time 4h 19m 51s   sec/tick 109.9   sec/kimg 26.82   maintenance 0.0    gpumem 8.7   augment 0.326\n",
      "tick 125   kimg 512.1    time 4h 21m 41s   sec/tick 109.8   sec/kimg 26.82   maintenance 0.0    gpumem 8.7   augment 0.329\n",
      "tick 126   kimg 516.2    time 4h 23m 31s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 8.7   augment 0.337\n",
      "tick 127   kimg 520.3    time 4h 25m 21s   sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 8.7   augment 0.332\n",
      "tick 128   kimg 524.4    time 4h 27m 11s   sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 8.7   augment 0.326\n",
      "tick 129   kimg 528.5    time 4h 29m 01s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 8.7   augment 0.334\n",
      "tick 130   kimg 532.6    time 4h 30m 50s   sec/tick 109.8   sec/kimg 26.81   maintenance 0.0    gpumem 8.7   augment 0.342\n",
      "tick 131   kimg 536.7    time 4h 32m 40s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 8.7   augment 0.342\n",
      "tick 132   kimg 540.8    time 4h 34m 30s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 8.7   augment 0.337\n",
      "tick 133   kimg 544.9    time 4h 36m 21s   sec/tick 110.0   sec/kimg 26.87   maintenance 0.0    gpumem 8.7   augment 0.339\n",
      "tick 134   kimg 549.0    time 4h 38m 11s   sec/tick 110.0   sec/kimg 26.87   maintenance 0.0    gpumem 8.7   augment 0.344\n",
      "tick 135   kimg 553.1    time 4h 40m 00s   sec/tick 109.9   sec/kimg 26.82   maintenance 0.0    gpumem 8.7   augment 0.344\n",
      "tick 136   kimg 557.2    time 4h 41m 50s   sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 8.7   augment 0.347\n",
      "tick 137   kimg 561.3    time 4h 43m 40s   sec/tick 109.9   sec/kimg 26.82   maintenance 0.0    gpumem 8.7   augment 0.357\n",
      "tick 138   kimg 565.4    time 4h 45m 30s   sec/tick 110.1   sec/kimg 26.87   maintenance 0.0    gpumem 8.7   augment 0.349\n",
      "tick 139   kimg 569.5    time 4h 47m 21s   sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 8.7   augment 0.352\n",
      "tick 140   kimg 573.6    time 4h 49m 11s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 8.7   augment 0.342\n",
      "tick 141   kimg 577.7    time 4h 51m 00s   sec/tick 109.8   sec/kimg 26.82   maintenance 0.0    gpumem 8.7   augment 0.339\n",
      "tick 142   kimg 581.8    time 4h 52m 50s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 8.7   augment 0.342\n",
      "tick 143   kimg 585.9    time 4h 54m 40s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 8.7   augment 0.332\n",
      "tick 144   kimg 590.0    time 4h 56m 30s   sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 8.7   augment 0.337\n",
      "tick 145   kimg 594.0    time 4h 58m 20s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.7   augment 0.342\n",
      "tick 146   kimg 598.1    time 5h 00m 10s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 8.7   augment 0.344\n",
      "tick 147   kimg 602.2    time 5h 02m 00s   sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 8.7   augment 0.349\n",
      "tick 148   kimg 606.3    time 5h 03m 50s   sec/tick 110.0   sec/kimg 26.84   maintenance 0.0    gpumem 8.7   augment 0.349\n",
      "tick 149   kimg 610.4    time 5h 05m 40s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 8.7   augment 0.344\n",
      "tick 150   kimg 614.5    time 5h 07m 30s   sec/tick 109.8   sec/kimg 26.81   maintenance 0.0    gpumem 8.7   augment 0.339\n",
      "Evaluating metrics...\n",
      "network-snapshot-000614        time 5m 40s       fid50k_full 20.4701\n",
      "tick 151   kimg 618.6    time 5h 15m 09s   sec/tick 110.1   sec/kimg 26.88   maintenance 348.7  gpumem 8.7   augment 0.337\n",
      "tick 152   kimg 622.7    time 5h 16m 59s   sec/tick 109.9   sec/kimg 26.82   maintenance 0.0    gpumem 8.7   augment 0.339\n",
      "tick 153   kimg 626.8    time 5h 18m 49s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 8.7   augment 0.339\n",
      "tick 154   kimg 630.9    time 5h 20m 39s   sec/tick 110.1   sec/kimg 26.87   maintenance 0.0    gpumem 8.7   augment 0.332\n",
      "tick 155   kimg 635.0    time 5h 22m 29s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 8.7   augment 0.334\n",
      "tick 156   kimg 639.1    time 5h 24m 19s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.7   augment 0.332\n",
      "tick 157   kimg 643.2    time 5h 26m 09s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 8.7   augment 0.329\n",
      "tick 158   kimg 647.3    time 5h 27m 58s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.7   augment 0.339\n",
      "tick 159   kimg 651.4    time 5h 29m 48s   sec/tick 109.8   sec/kimg 26.81   maintenance 0.0    gpumem 8.7   augment 0.339\n",
      "tick 160   kimg 655.5    time 5h 31m 38s   sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 8.7   augment 0.342\n"
     ]
    }
   ],
   "source": [
    "#!python stylegan2-ada/train.py --snap=30 --outdir=./training-runs-full --gpus=1 --data=./datasets/logo-full --res=128 --kimg=1000 --mirror=False --gamma=16 --augpipe=bgcfnc --resume=./training-runs-full/00000-logo-full-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom/network-snapshot-000245.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T00:01:44.369828Z",
     "iopub.status.busy": "2022-06-17T00:01:44.369513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 16.0\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.6,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1,\n",
      "      \"imgfilter\": 1,\n",
      "      \"noise\": 1,\n",
      "      \"cutout\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 30,\n",
      "  \"network_snapshot_ticks\": 30,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 1000,\n",
      "  \"minibatch_size\": 32,\n",
      "  \"minibatch_gpu\": 32,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"./training-runs-full/00001-logo-full-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom/network-snapshot-000614.pkl\",\n",
      "  \"run_dir\": \"./training-runs-full/00002-logo-full-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom\"\n",
      "}\n",
      "\n",
      "Output directory:  ./training-runs-full/00002-logo-full-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom\n",
      "Training data:     ./datasets/logo-full\n",
      "Training length:   1000 kimg\n",
      "Resolution:        128\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "Image shape: [3, 128, 128]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
      "Resuming from \"./training-runs-full/00001-logo-full-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom/network-snapshot-000614.pkl\"\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 12, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 12, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "---                           ---       ---                 ---             \n",
      "Total                         22949277                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 128, 128)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "128x128/FromRGB      512       (?, 128, 128, 128)  (1, 1, 3, 128)  \n",
      "128x128/Conv0        147584    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                23882369                                      \n",
      "\n",
      "Exporting sample images...\n",
      "2022-06-17 00:02:31.381721: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 1000 kimg...\n",
      "\n",
      "tick 0     kimg 0.1      time 1m 50s       sec/tick 20.8    sec/kimg 162.62  maintenance 89.1   gpumem 8.2   augment 0.001\n",
      "Evaluating metrics...\n",
      "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/metrics/inception_v3_features.pkl ... done\n",
      "Calculating real image statistics for fid50k_full...\n",
      "network-snapshot-000000        time 7m 25s       fid50k_full 20.4234\n",
      "tick 1     kimg 4.2      time 11m 29s      sec/tick 109.0   sec/kimg 26.62   maintenance 469.6  gpumem 8.7   augment 0.032\n",
      "tick 2     kimg 8.3      time 13m 18s      sec/tick 109.2   sec/kimg 26.67   maintenance 0.0    gpumem 8.7   augment 0.065\n",
      "tick 3     kimg 12.4     time 15m 07s      sec/tick 109.5   sec/kimg 26.72   maintenance 0.0    gpumem 8.8   augment 0.101\n",
      "tick 4     kimg 16.5     time 16m 57s      sec/tick 109.5   sec/kimg 26.73   maintenance 0.0    gpumem 8.8   augment 0.134\n",
      "tick 5     kimg 20.6     time 18m 46s      sec/tick 109.6   sec/kimg 26.77   maintenance 0.0    gpumem 8.8   augment 0.165\n",
      "tick 6     kimg 24.7     time 20m 36s      sec/tick 109.8   sec/kimg 26.80   maintenance 0.0    gpumem 8.8   augment 0.196\n",
      "tick 7     kimg 28.8     time 22m 26s      sec/tick 109.7   sec/kimg 26.78   maintenance 0.0    gpumem 8.8   augment 0.224\n",
      "tick 8     kimg 32.9     time 24m 16s      sec/tick 109.8   sec/kimg 26.81   maintenance 0.0    gpumem 8.8   augment 0.250\n",
      "tick 9     kimg 37.0     time 26m 06s      sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.8   augment 0.268\n",
      "tick 10    kimg 41.1     time 27m 56s      sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 8.8   augment 0.283\n",
      "tick 11    kimg 45.2     time 29m 46s      sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 8.8   augment 0.291\n",
      "tick 12    kimg 49.3     time 31m 36s      sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 8.8   augment 0.308\n",
      "tick 13    kimg 53.4     time 33m 26s      sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 8.8   augment 0.311\n",
      "tick 14    kimg 57.5     time 35m 16s      sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 8.8   augment 0.319\n",
      "tick 15    kimg 61.6     time 37m 06s      sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 8.8   augment 0.321\n",
      "tick 16    kimg 65.7     time 38m 56s      sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 8.8   augment 0.316\n"
     ]
    }
   ],
   "source": [
    "#!python stylegan2-ada/train.py --snap=30 --outdir=./training-runs-full --gpus=1 --data=./datasets/logo-full --res=128 --kimg=1000 --mirror=False --gamma=16 --augpipe=bgcfnc --resume=./training-runs-full/00001-logo-full-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom/network-snapshot-000614.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T13:28:56.686818Z",
     "iopub.status.busy": "2022-06-17T13:28:56.686533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 16.0\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.6,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1,\n",
      "      \"imgfilter\": 1,\n",
      "      \"noise\": 1,\n",
      "      \"cutout\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 40,\n",
      "  \"network_snapshot_ticks\": 40,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 1000,\n",
      "  \"minibatch_size\": 32,\n",
      "  \"minibatch_gpu\": 32,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"./training-runs-full/00002-logo-full-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom/network-snapshot-000614.pkl\",\n",
      "  \"run_dir\": \"./training-runs-full/00003-logo-full-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom\"\n",
      "}\n",
      "\n",
      "Output directory:  ./training-runs-full/00003-logo-full-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom\n",
      "Training data:     ./datasets/logo-full\n",
      "Training length:   1000 kimg\n",
      "Resolution:        128\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "Image shape: [3, 128, 128]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
      "Resuming from \"./training-runs-full/00002-logo-full-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom/network-snapshot-000614.pkl\"\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 12, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 12, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "---                           ---       ---                 ---             \n",
      "Total                         22949277                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 128, 128)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "128x128/FromRGB      512       (?, 128, 128, 128)  (1, 1, 3, 128)  \n",
      "128x128/Conv0        147584    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                23882369                                      \n",
      "\n",
      "Exporting sample images...\n",
      "2022-06-17 13:29:44.294697: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 1000 kimg...\n",
      "\n",
      "tick 0     kimg 0.1      time 1m 51s       sec/tick 20.6    sec/kimg 160.72  maintenance 90.3   gpumem 8.2   augment 0.001\n",
      "Evaluating metrics...\n",
      "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/metrics/inception_v3_features.pkl ... done\n",
      "Calculating real image statistics for fid50k_full...\n",
      "network-snapshot-000000        time 7m 19s       fid50k_full 19.2631\n",
      "tick 1     kimg 4.2      time 11m 23s      sec/tick 108.9   sec/kimg 26.58   maintenance 462.9  gpumem 8.6   augment 0.040\n",
      "tick 2     kimg 8.3      time 13m 11s      sec/tick 108.9   sec/kimg 26.59   maintenance 0.0    gpumem 8.6   augment 0.076\n",
      "tick 3     kimg 12.4     time 15m 01s      sec/tick 109.2   sec/kimg 26.65   maintenance 0.0    gpumem 8.6   augment 0.109\n",
      "tick 4     kimg 16.5     time 16m 50s      sec/tick 109.1   sec/kimg 26.64   maintenance 0.0    gpumem 8.6   augment 0.145\n",
      "tick 5     kimg 20.6     time 18m 39s      sec/tick 109.3   sec/kimg 26.69   maintenance 0.0    gpumem 8.6   augment 0.175\n",
      "tick 6     kimg 24.7     time 20m 28s      sec/tick 109.3   sec/kimg 26.69   maintenance 0.0    gpumem 8.6   augment 0.209\n",
      "tick 7     kimg 28.8     time 22m 18s      sec/tick 109.3   sec/kimg 26.69   maintenance 0.0    gpumem 8.6   augment 0.234\n",
      "tick 8     kimg 32.9     time 24m 07s      sec/tick 109.4   sec/kimg 26.71   maintenance 0.0    gpumem 8.6   augment 0.260\n",
      "tick 9     kimg 37.0     time 25m 57s      sec/tick 109.6   sec/kimg 26.76   maintenance 0.0    gpumem 8.6   augment 0.283\n",
      "tick 10    kimg 41.1     time 27m 46s      sec/tick 109.5   sec/kimg 26.73   maintenance 0.0    gpumem 8.7   augment 0.298\n",
      "tick 11    kimg 45.2     time 29m 36s      sec/tick 109.5   sec/kimg 26.73   maintenance 0.0    gpumem 8.7   augment 0.316\n",
      "tick 12    kimg 49.3     time 31m 26s      sec/tick 109.7   sec/kimg 26.77   maintenance 0.0    gpumem 8.7   augment 0.324\n",
      "tick 13    kimg 53.4     time 33m 15s      sec/tick 109.8   sec/kimg 26.80   maintenance 0.0    gpumem 8.7   augment 0.326\n",
      "tick 14    kimg 57.5     time 35m 05s      sec/tick 109.7   sec/kimg 26.78   maintenance 0.0    gpumem 8.7   augment 0.334\n",
      "tick 15    kimg 61.6     time 36m 55s      sec/tick 109.6   sec/kimg 26.75   maintenance 0.0    gpumem 8.7   augment 0.329\n",
      "tick 16    kimg 65.7     time 38m 44s      sec/tick 109.7   sec/kimg 26.78   maintenance 0.0    gpumem 8.7   augment 0.332\n",
      "tick 17    kimg 69.8     time 40m 34s      sec/tick 109.7   sec/kimg 26.78   maintenance 0.0    gpumem 8.7   augment 0.337\n",
      "tick 18    kimg 73.9     time 42m 24s      sec/tick 109.7   sec/kimg 26.77   maintenance 0.0    gpumem 8.7   augment 0.344\n",
      "tick 19    kimg 78.0     time 44m 13s      sec/tick 109.6   sec/kimg 26.77   maintenance 0.0    gpumem 8.7   augment 0.344\n",
      "tick 20    kimg 82.0     time 46m 03s      sec/tick 109.5   sec/kimg 26.73   maintenance 0.0    gpumem 8.7   augment 0.352\n",
      "tick 21    kimg 86.1     time 47m 53s      sec/tick 109.8   sec/kimg 26.81   maintenance 0.0    gpumem 8.7   augment 0.344\n",
      "tick 22    kimg 90.2     time 49m 42s      sec/tick 109.7   sec/kimg 26.78   maintenance 0.0    gpumem 8.7   augment 0.344\n",
      "tick 23    kimg 94.3     time 51m 32s      sec/tick 109.6   sec/kimg 26.76   maintenance 0.0    gpumem 8.7   augment 0.349\n",
      "tick 24    kimg 98.4     time 53m 22s      sec/tick 109.7   sec/kimg 26.77   maintenance 0.0    gpumem 8.7   augment 0.349\n",
      "tick 25    kimg 102.5    time 55m 11s      sec/tick 109.5   sec/kimg 26.75   maintenance 0.0    gpumem 8.7   augment 0.347\n",
      "tick 26    kimg 106.6    time 57m 01s      sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.7   augment 0.347\n",
      "tick 27    kimg 110.7    time 58m 51s      sec/tick 109.9   sec/kimg 26.82   maintenance 0.0    gpumem 8.7   augment 0.342\n",
      "tick 28    kimg 114.8    time 1h 00m 41s   sec/tick 109.7   sec/kimg 26.79   maintenance 0.0    gpumem 8.7   augment 0.339\n",
      "tick 29    kimg 118.9    time 1h 02m 30s   sec/tick 109.7   sec/kimg 26.79   maintenance 0.0    gpumem 8.7   augment 0.339\n",
      "tick 30    kimg 123.0    time 1h 04m 20s   sec/tick 109.6   sec/kimg 26.76   maintenance 0.0    gpumem 8.7   augment 0.337\n",
      "tick 31    kimg 127.1    time 1h 06m 10s   sec/tick 109.6   sec/kimg 26.75   maintenance 0.0    gpumem 8.7   augment 0.337\n",
      "tick 32    kimg 131.2    time 1h 08m 00s   sec/tick 109.9   sec/kimg 26.82   maintenance 0.0    gpumem 8.7   augment 0.344\n",
      "tick 33    kimg 135.3    time 1h 09m 49s   sec/tick 109.6   sec/kimg 26.76   maintenance 0.0    gpumem 8.7   augment 0.344\n",
      "tick 34    kimg 139.4    time 1h 11m 39s   sec/tick 109.7   sec/kimg 26.79   maintenance 0.0    gpumem 8.7   augment 0.347\n",
      "tick 35    kimg 143.5    time 1h 13m 29s   sec/tick 109.7   sec/kimg 26.78   maintenance 0.0    gpumem 8.7   augment 0.352\n",
      "tick 36    kimg 147.6    time 1h 15m 18s   sec/tick 109.7   sec/kimg 26.78   maintenance 0.0    gpumem 8.7   augment 0.362\n",
      "tick 37    kimg 151.7    time 1h 17m 08s   sec/tick 109.8   sec/kimg 26.80   maintenance 0.0    gpumem 8.7   augment 0.357\n",
      "tick 38    kimg 155.8    time 1h 18m 58s   sec/tick 109.7   sec/kimg 26.78   maintenance 0.0    gpumem 8.7   augment 0.347\n",
      "tick 39    kimg 159.9    time 1h 20m 48s   sec/tick 109.8   sec/kimg 26.81   maintenance 0.0    gpumem 8.7   augment 0.339\n",
      "tick 40    kimg 164.0    time 1h 22m 37s   sec/tick 109.6   sec/kimg 26.77   maintenance 0.0    gpumem 8.7   augment 0.342\n",
      "Evaluating metrics...\n",
      "network-snapshot-000163        time 5m 44s       fid50k_full 19.3298\n",
      "tick 41    kimg 168.1    time 1h 30m 20s   sec/tick 109.9   sec/kimg 26.82   maintenance 352.8  gpumem 8.7   augment 0.332\n",
      "tick 42    kimg 172.2    time 1h 32m 10s   sec/tick 109.9   sec/kimg 26.82   maintenance 0.0    gpumem 8.7   augment 0.329\n",
      "tick 43    kimg 176.3    time 1h 34m 00s   sec/tick 109.8   sec/kimg 26.79   maintenance 0.0    gpumem 8.7   augment 0.337\n",
      "tick 44    kimg 180.4    time 1h 35m 49s   sec/tick 109.6   sec/kimg 26.77   maintenance 0.0    gpumem 8.7   augment 0.347\n",
      "tick 45    kimg 184.4    time 1h 37m 39s   sec/tick 109.7   sec/kimg 26.79   maintenance 0.0    gpumem 8.7   augment 0.342\n",
      "tick 46    kimg 188.5    time 1h 39m 29s   sec/tick 109.6   sec/kimg 26.76   maintenance 0.0    gpumem 8.7   augment 0.347\n",
      "tick 47    kimg 192.6    time 1h 41m 18s   sec/tick 109.6   sec/kimg 26.76   maintenance 0.0    gpumem 8.7   augment 0.347\n",
      "tick 48    kimg 196.7    time 1h 43m 08s   sec/tick 109.8   sec/kimg 26.81   maintenance 0.0    gpumem 8.7   augment 0.344\n",
      "tick 49    kimg 200.8    time 1h 44m 58s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.7   augment 0.344\n",
      "tick 50    kimg 204.9    time 1h 46m 48s   sec/tick 109.6   sec/kimg 26.77   maintenance 0.0    gpumem 8.8   augment 0.347\n",
      "tick 51    kimg 209.0    time 1h 48m 37s   sec/tick 109.8   sec/kimg 26.80   maintenance 0.0    gpumem 8.8   augment 0.339\n",
      "tick 52    kimg 213.1    time 1h 50m 27s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.8   augment 0.337\n",
      "tick 53    kimg 217.2    time 1h 52m 17s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 8.8   augment 0.339\n",
      "tick 54    kimg 221.3    time 1h 54m 07s   sec/tick 109.6   sec/kimg 26.77   maintenance 0.0    gpumem 8.8   augment 0.339\n",
      "tick 55    kimg 225.4    time 1h 55m 57s   sec/tick 109.7   sec/kimg 26.78   maintenance 0.0    gpumem 8.8   augment 0.339\n",
      "tick 56    kimg 229.5    time 1h 57m 46s   sec/tick 109.6   sec/kimg 26.77   maintenance 0.0    gpumem 8.8   augment 0.344\n",
      "tick 57    kimg 233.6    time 1h 59m 36s   sec/tick 109.7   sec/kimg 26.79   maintenance 0.0    gpumem 8.8   augment 0.344\n",
      "tick 58    kimg 237.7    time 2h 01m 26s   sec/tick 109.7   sec/kimg 26.79   maintenance 0.0    gpumem 8.8   augment 0.347\n",
      "tick 59    kimg 241.8    time 2h 03m 16s   sec/tick 109.7   sec/kimg 26.79   maintenance 0.0    gpumem 8.8   augment 0.347\n",
      "tick 60    kimg 245.9    time 2h 05m 05s   sec/tick 109.7   sec/kimg 26.79   maintenance 0.0    gpumem 8.8   augment 0.344\n",
      "tick 61    kimg 250.0    time 2h 06m 55s   sec/tick 109.7   sec/kimg 26.79   maintenance 0.0    gpumem 8.8   augment 0.342\n",
      "tick 62    kimg 254.1    time 2h 08m 45s   sec/tick 109.7   sec/kimg 26.79   maintenance 0.0    gpumem 8.8   augment 0.344\n",
      "tick 63    kimg 258.2    time 2h 10m 35s   sec/tick 109.7   sec/kimg 26.79   maintenance 0.0    gpumem 8.8   augment 0.344\n",
      "tick 64    kimg 262.3    time 2h 12m 24s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.8   augment 0.342\n",
      "tick 65    kimg 266.4    time 2h 14m 14s   sec/tick 109.7   sec/kimg 26.78   maintenance 0.0    gpumem 8.8   augment 0.349\n",
      "tick 66    kimg 270.5    time 2h 16m 04s   sec/tick 109.7   sec/kimg 26.78   maintenance 0.0    gpumem 8.8   augment 0.349\n",
      "tick 67    kimg 274.6    time 2h 17m 54s   sec/tick 109.7   sec/kimg 26.78   maintenance 0.0    gpumem 8.8   augment 0.352\n",
      "tick 68    kimg 278.7    time 2h 19m 43s   sec/tick 109.5   sec/kimg 26.74   maintenance 0.0    gpumem 8.8   augment 0.347\n",
      "tick 69    kimg 282.8    time 2h 21m 33s   sec/tick 109.6   sec/kimg 26.75   maintenance 0.0    gpumem 8.8   augment 0.344\n",
      "tick 70    kimg 286.8    time 2h 23m 22s   sec/tick 109.6   sec/kimg 26.77   maintenance 0.0    gpumem 8.8   augment 0.342\n",
      "tick 71    kimg 290.9    time 2h 25m 12s   sec/tick 109.7   sec/kimg 26.78   maintenance 0.0    gpumem 8.8   augment 0.342\n",
      "tick 72    kimg 295.0    time 2h 27m 02s   sec/tick 109.6   sec/kimg 26.76   maintenance 0.0    gpumem 8.8   augment 0.349\n",
      "tick 73    kimg 299.1    time 2h 28m 51s   sec/tick 109.7   sec/kimg 26.79   maintenance 0.0    gpumem 8.8   augment 0.347\n",
      "tick 74    kimg 303.2    time 2h 30m 41s   sec/tick 109.6   sec/kimg 26.75   maintenance 0.0    gpumem 8.8   augment 0.355\n",
      "tick 75    kimg 307.3    time 2h 32m 31s   sec/tick 109.7   sec/kimg 26.79   maintenance 0.0    gpumem 8.8   augment 0.352\n",
      "tick 76    kimg 311.4    time 2h 34m 21s   sec/tick 109.8   sec/kimg 26.80   maintenance 0.0    gpumem 8.8   augment 0.355\n",
      "tick 77    kimg 315.5    time 2h 36m 10s   sec/tick 109.6   sec/kimg 26.76   maintenance 0.0    gpumem 8.8   augment 0.352\n",
      "tick 78    kimg 319.6    time 2h 38m 00s   sec/tick 109.6   sec/kimg 26.75   maintenance 0.0    gpumem 8.8   augment 0.360\n",
      "tick 135   kimg 553.1    time 4h 33m 56s   sec/tick 109.8   sec/kimg 26.80   maintenance 0.0    gpumem 8.8   augment 0.352\n",
      "tick 136   kimg 557.2    time 4h 35m 46s   sec/tick 109.7   sec/kimg 26.79   maintenance 0.0    gpumem 8.8   augment 0.355\n",
      "tick 137   kimg 561.3    time 4h 37m 35s   sec/tick 109.7   sec/kimg 26.77   maintenance 0.0    gpumem 8.8   augment 0.357\n",
      "tick 138   kimg 565.4    time 4h 39m 25s   sec/tick 109.7   sec/kimg 26.78   maintenance 0.0    gpumem 8.8   augment 0.355\n",
      "tick 139   kimg 569.5    time 4h 41m 15s   sec/tick 109.7   sec/kimg 26.78   maintenance 0.0    gpumem 8.8   augment 0.355\n",
      "tick 140   kimg 573.6    time 4h 43m 04s   sec/tick 109.7   sec/kimg 26.78   maintenance 0.0    gpumem 8.8   augment 0.352\n",
      "tick 141   kimg 577.7    time 4h 44m 54s   sec/tick 109.8   sec/kimg 26.82   maintenance 0.0    gpumem 8.8   augment 0.355\n",
      "tick 142   kimg 581.8    time 4h 46m 44s   sec/tick 109.7   sec/kimg 26.78   maintenance 0.0    gpumem 8.8   augment 0.357\n",
      "tick 143   kimg 585.9    time 4h 48m 34s   sec/tick 109.7   sec/kimg 26.78   maintenance 0.0    gpumem 8.8   augment 0.352\n",
      "tick 144   kimg 590.0    time 4h 50m 23s   sec/tick 109.6   sec/kimg 26.75   maintenance 0.0    gpumem 8.8   augment 0.355\n",
      "tick 145   kimg 594.0    time 4h 52m 13s   sec/tick 109.7   sec/kimg 26.78   maintenance 0.0    gpumem 8.8   augment 0.355\n",
      "tick 146   kimg 598.1    time 4h 54m 02s   sec/tick 109.7   sec/kimg 26.77   maintenance 0.0    gpumem 8.8   augment 0.352\n",
      "tick 147   kimg 602.2    time 4h 55m 52s   sec/tick 109.6   sec/kimg 26.77   maintenance 0.0    gpumem 8.8   augment 0.352\n",
      "tick 148   kimg 606.3    time 4h 57m 42s   sec/tick 109.6   sec/kimg 26.75   maintenance 0.0    gpumem 8.8   augment 0.357\n",
      "tick 149   kimg 610.4    time 4h 59m 31s   sec/tick 109.7   sec/kimg 26.79   maintenance 0.0    gpumem 8.8   augment 0.357\n",
      "tick 150   kimg 614.5    time 5h 01m 21s   sec/tick 109.6   sec/kimg 26.75   maintenance 0.0    gpumem 8.8   augment 0.347\n",
      "tick 151   kimg 618.6    time 5h 03m 11s   sec/tick 109.7   sec/kimg 26.77   maintenance 0.0    gpumem 8.8   augment 0.355\n",
      "tick 152   kimg 622.7    time 5h 05m 00s   sec/tick 109.7   sec/kimg 26.79   maintenance 0.0    gpumem 8.8   augment 0.347\n",
      "tick 153   kimg 626.8    time 5h 06m 50s   sec/tick 109.8   sec/kimg 26.80   maintenance 0.0    gpumem 8.8   augment 0.349\n",
      "tick 154   kimg 630.9    time 5h 08m 40s   sec/tick 109.7   sec/kimg 26.77   maintenance 0.0    gpumem 8.8   augment 0.344\n",
      "tick 155   kimg 635.0    time 5h 10m 29s   sec/tick 109.6   sec/kimg 26.76   maintenance 0.0    gpumem 8.8   augment 0.342\n",
      "tick 156   kimg 639.1    time 5h 12m 19s   sec/tick 109.7   sec/kimg 26.78   maintenance 0.0    gpumem 8.8   augment 0.339\n"
     ]
    }
   ],
   "source": [
    "#!python stylegan2-ada/train.py --snap=40 --outdir=./training-runs-full --gpus=1 --data=./datasets/logo-full --res=128 --kimg=1000 --mirror=False --gamma=16 --augpipe=bgcfnc --resume=./training-runs-full/00002-logo-full-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom/network-snapshot-000614.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T21:00:42.371732Z",
     "iopub.status.busy": "2022-06-17T21:00:42.371448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 16.0\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.6,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1,\n",
      "      \"imgfilter\": 1,\n",
      "      \"noise\": 1,\n",
      "      \"cutout\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 40,\n",
      "  \"network_snapshot_ticks\": 40,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 1000,\n",
      "  \"minibatch_size\": 32,\n",
      "  \"minibatch_gpu\": 32,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"./training-runs-full/00003-logo-full-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom/network-snapshot-000655.pkl\",\n",
      "  \"run_dir\": \"./training-runs-full/00004-logo-full-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom\"\n",
      "}\n",
      "\n",
      "Output directory:  ./training-runs-full/00004-logo-full-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom\n",
      "Training data:     ./datasets/logo-full\n",
      "Training length:   1000 kimg\n",
      "Resolution:        128\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "Image shape: [3, 128, 128]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
      "Resuming from \"./training-runs-full/00003-logo-full-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom/network-snapshot-000655.pkl\"\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 12, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 12, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "---                           ---       ---                 ---             \n",
      "Total                         22949277                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 128, 128)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "128x128/FromRGB      512       (?, 128, 128, 128)  (1, 1, 3, 128)  \n",
      "128x128/Conv0        147584    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                23882369                                      \n",
      "\n",
      "Exporting sample images...\n",
      "2022-06-17 21:01:27.739123: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 1000 kimg...\n",
      "\n",
      "tick 0     kimg 0.1      time 1m 49s       sec/tick 20.9    sec/kimg 163.39  maintenance 87.7   gpumem 8.6   augment 0.001\n",
      "Evaluating metrics...\n",
      "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/metrics/inception_v3_features.pkl ... done\n",
      "Calculating real image statistics for fid50k_full...\n",
      "network-snapshot-000000        time 7m 24s       fid50k_full 18.8450\n",
      "tick 1     kimg 4.2      time 11m 26s      sec/tick 109.3   sec/kimg 26.68   maintenance 468.4  gpumem 8.6   augment 0.037\n",
      "tick 2     kimg 8.3      time 13m 16s      sec/tick 109.7   sec/kimg 26.77   maintenance 0.0    gpumem 8.6   augment 0.076\n",
      "tick 3     kimg 12.4     time 15m 06s      sec/tick 109.7   sec/kimg 26.78   maintenance 0.0    gpumem 8.6   augment 0.111\n",
      "tick 4     kimg 16.5     time 16m 55s      sec/tick 109.8   sec/kimg 26.81   maintenance 0.0    gpumem 8.6   augment 0.150\n",
      "tick 5     kimg 20.6     time 18m 45s      sec/tick 110.0   sec/kimg 26.84   maintenance 0.0    gpumem 8.6   augment 0.183\n",
      "tick 6     kimg 24.7     time 20m 36s      sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 8.6   augment 0.219\n",
      "tick 7     kimg 28.8     time 22m 26s      sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 8.6   augment 0.244\n",
      "tick 8     kimg 32.9     time 24m 16s      sec/tick 110.1   sec/kimg 26.87   maintenance 0.0    gpumem 8.6   augment 0.268\n",
      "tick 9     kimg 37.0     time 26m 06s      sec/tick 110.3   sec/kimg 26.92   maintenance 0.0    gpumem 8.6   augment 0.293\n",
      "tick 10    kimg 41.1     time 27m 56s      sec/tick 110.3   sec/kimg 26.94   maintenance 0.0    gpumem 8.6   augment 0.308\n",
      "tick 11    kimg 45.2     time 29m 47s      sec/tick 110.3   sec/kimg 26.92   maintenance 0.0    gpumem 8.6   augment 0.321\n",
      "tick 12    kimg 49.3     time 31m 37s      sec/tick 110.2   sec/kimg 26.90   maintenance 0.0    gpumem 8.6   augment 0.337\n",
      "tick 13    kimg 53.4     time 33m 27s      sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 8.6   augment 0.344\n",
      "tick 14    kimg 57.5     time 35m 18s      sec/tick 110.3   sec/kimg 26.92   maintenance 0.0    gpumem 8.6   augment 0.344\n",
      "tick 15    kimg 61.6     time 37m 08s      sec/tick 110.2   sec/kimg 26.92   maintenance 0.0    gpumem 8.6   augment 0.344\n",
      "tick 16    kimg 65.7     time 38m 58s      sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 8.6   augment 0.347\n",
      "tick 17    kimg 69.8     time 40m 49s      sec/tick 110.4   sec/kimg 26.94   maintenance 0.0    gpumem 8.6   augment 0.360\n",
      "tick 18    kimg 73.9     time 42m 39s      sec/tick 110.6   sec/kimg 26.99   maintenance 0.0    gpumem 8.6   augment 0.367\n",
      "tick 19    kimg 78.0     time 44m 29s      sec/tick 110.2   sec/kimg 26.92   maintenance 0.0    gpumem 8.6   augment 0.365\n",
      "tick 20    kimg 82.0     time 46m 20s      sec/tick 110.4   sec/kimg 26.97   maintenance 0.0    gpumem 8.6   augment 0.367\n",
      "tick 21    kimg 86.1     time 48m 10s      sec/tick 110.3   sec/kimg 26.93   maintenance 0.0    gpumem 8.6   augment 0.372\n",
      "tick 22    kimg 90.2     time 50m 01s      sec/tick 110.4   sec/kimg 26.94   maintenance 0.0    gpumem 8.6   augment 0.367\n",
      "tick 23    kimg 94.3     time 51m 51s      sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 8.6   augment 0.360\n",
      "tick 24    kimg 98.4     time 53m 41s      sec/tick 110.3   sec/kimg 26.93   maintenance 0.0    gpumem 8.6   augment 0.357\n",
      "tick 25    kimg 102.5    time 55m 32s      sec/tick 110.2   sec/kimg 26.90   maintenance 0.0    gpumem 8.6   augment 0.365\n",
      "tick 26    kimg 106.6    time 57m 22s      sec/tick 110.5   sec/kimg 26.99   maintenance 0.0    gpumem 8.6   augment 0.362\n",
      "tick 27    kimg 110.7    time 59m 12s      sec/tick 110.4   sec/kimg 26.94   maintenance 0.0    gpumem 8.6   augment 0.375\n",
      "tick 28    kimg 114.8    time 1h 01m 03s   sec/tick 110.3   sec/kimg 26.93   maintenance 0.0    gpumem 8.6   augment 0.370\n",
      "tick 29    kimg 118.9    time 1h 02m 53s   sec/tick 110.2   sec/kimg 26.91   maintenance 0.0    gpumem 8.6   augment 0.367\n",
      "tick 30    kimg 123.0    time 1h 04m 43s   sec/tick 110.3   sec/kimg 26.92   maintenance 0.0    gpumem 8.6   augment 0.372\n",
      "tick 31    kimg 127.1    time 1h 06m 34s   sec/tick 110.3   sec/kimg 26.94   maintenance 0.0    gpumem 8.6   augment 0.370\n",
      "tick 32    kimg 131.2    time 1h 08m 24s   sec/tick 110.2   sec/kimg 26.91   maintenance 0.0    gpumem 8.6   augment 0.367\n",
      "tick 33    kimg 135.3    time 1h 10m 14s   sec/tick 110.2   sec/kimg 26.90   maintenance 0.0    gpumem 8.6   augment 0.370\n",
      "tick 34    kimg 139.4    time 1h 12m 05s   sec/tick 110.3   sec/kimg 26.94   maintenance 0.0    gpumem 8.6   augment 0.365\n",
      "tick 35    kimg 143.5    time 1h 13m 55s   sec/tick 110.4   sec/kimg 26.95   maintenance 0.0    gpumem 8.6   augment 0.365\n",
      "tick 36    kimg 147.6    time 1h 15m 45s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.6   augment 0.370\n",
      "tick 37    kimg 151.7    time 1h 17m 36s   sec/tick 110.4   sec/kimg 26.95   maintenance 0.0    gpumem 8.6   augment 0.370\n",
      "tick 38    kimg 155.8    time 1h 19m 26s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 8.6   augment 0.365\n",
      "tick 39    kimg 159.9    time 1h 21m 17s   sec/tick 110.5   sec/kimg 26.99   maintenance 0.0    gpumem 8.6   augment 0.362\n",
      "tick 40    kimg 164.0    time 1h 23m 07s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 8.6   augment 0.365\n",
      "Evaluating metrics...\n",
      "network-snapshot-000163        time 5m 44s       fid50k_full 18.0706\n",
      "tick 41    kimg 168.1    time 1h 30m 50s   sec/tick 110.2   sec/kimg 26.91   maintenance 352.5  gpumem 8.6   augment 0.360\n",
      "tick 42    kimg 172.2    time 1h 32m 40s   sec/tick 110.4   sec/kimg 26.94   maintenance 0.0    gpumem 8.6   augment 0.357\n",
      "tick 43    kimg 176.3    time 1h 34m 31s   sec/tick 110.2   sec/kimg 26.92   maintenance 0.0    gpumem 8.6   augment 0.367\n",
      "tick 44    kimg 180.4    time 1h 36m 21s   sec/tick 110.2   sec/kimg 26.91   maintenance 0.0    gpumem 8.6   augment 0.367\n",
      "tick 45    kimg 184.4    time 1h 38m 11s   sec/tick 110.4   sec/kimg 26.95   maintenance 0.0    gpumem 8.6   augment 0.362\n",
      "tick 46    kimg 188.5    time 1h 40m 02s   sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 8.6   augment 0.367\n",
      "tick 47    kimg 192.6    time 1h 41m 52s   sec/tick 110.3   sec/kimg 26.92   maintenance 0.0    gpumem 8.6   augment 0.365\n",
      "tick 48    kimg 196.7    time 1h 43m 42s   sec/tick 110.3   sec/kimg 26.94   maintenance 0.0    gpumem 8.6   augment 0.372\n",
      "tick 49    kimg 200.8    time 1h 45m 33s   sec/tick 110.4   sec/kimg 26.94   maintenance 0.0    gpumem 8.6   augment 0.375\n",
      "tick 50    kimg 204.9    time 1h 47m 23s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.6   augment 0.383\n",
      "tick 51    kimg 209.0    time 1h 49m 14s   sec/tick 110.3   sec/kimg 26.94   maintenance 0.0    gpumem 8.6   augment 0.372\n",
      "tick 52    kimg 213.1    time 1h 51m 04s   sec/tick 110.4   sec/kimg 26.95   maintenance 0.0    gpumem 8.6   augment 0.360\n"
     ]
    }
   ],
   "source": [
    "#!python stylegan2-ada/train.py --snap=40 --outdir=./training-runs-full --gpus=1 --data=./datasets/logo-full --res=128 --kimg=1000 --mirror=False --gamma=16 --augpipe=bgcfnc --resume=./training-runs-full/00003-logo-full-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom/network-snapshot-000655.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T10:51:44.927811Z",
     "iopub.status.busy": "2022-06-18T10:51:44.927518Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 16.0\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.6,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1,\n",
      "      \"imgfilter\": 1,\n",
      "      \"noise\": 1,\n",
      "      \"cutout\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 40,\n",
      "  \"network_snapshot_ticks\": 40,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 700,\n",
      "  \"minibatch_size\": 32,\n",
      "  \"minibatch_gpu\": 32,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"./training-runs-full/00004-logo-full-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom/network-snapshot-000655.pkl\",\n",
      "  \"run_dir\": \"./training-runs-full/00005-logo-full-res128-auto1-gamma16-kimg700-bgcfnc-resumecustom\"\n",
      "}\n",
      "\n",
      "Output directory:  ./training-runs-full/00005-logo-full-res128-auto1-gamma16-kimg700-bgcfnc-resumecustom\n",
      "Training data:     ./datasets/logo-full\n",
      "Training length:   700 kimg\n",
      "Resolution:        128\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "Image shape: [3, 128, 128]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
      "Resuming from \"./training-runs-full/00004-logo-full-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom/network-snapshot-000655.pkl\"\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 12, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 12, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "---                           ---       ---                 ---             \n",
      "Total                         22949277                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 128, 128)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "128x128/FromRGB      512       (?, 128, 128, 128)  (1, 1, 3, 128)  \n",
      "128x128/Conv0        147584    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                23882369                                      \n",
      "\n",
      "Exporting sample images...\n",
      "2022-06-18 10:52:31.231922: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 700 kimg...\n",
      "\n",
      "tick 0     kimg 0.1      time 1m 49s       sec/tick 20.7    sec/kimg 161.48  maintenance 87.9   gpumem 8.2   augment 0.001\n",
      "Evaluating metrics...\n",
      "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/metrics/inception_v3_features.pkl ... done\n",
      "Calculating real image statistics for fid50k_full...\n"
     ]
    }
   ],
   "source": [
    "#!python stylegan2-ada/train.py --snap=40 --outdir=./training-runs-full --gpus=1 --data=./datasets/logo-full --res=128 --kimg=700 --mirror=False --gamma=16 --augpipe=bgcfnc --resume=./training-runs-full/00004-logo-full-res128-auto1-gamma16-kimg1000-bgcfnc-resumecustom/network-snapshot-000655.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add --freezed=2 parameter again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T00:05:02.916797Z",
     "iopub.status.busy": "2022-06-19T00:05:02.916496Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256,\n",
      "    \"freeze_layers\": 2\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 16.0\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.6,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1,\n",
      "      \"imgfilter\": 1,\n",
      "      \"noise\": 1,\n",
      "      \"cutout\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 40,\n",
      "  \"network_snapshot_ticks\": 40,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 700,\n",
      "  \"minibatch_size\": 32,\n",
      "  \"minibatch_gpu\": 32,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"./training-runs-full/00005-logo-full-res128-auto1-gamma16-kimg700-bgcfnc-resumecustom/network-snapshot-000700.pkl\",\n",
      "  \"run_dir\": \"./training-runs-full/00006-logo-full-res128-auto1-gamma16-kimg700-bgcfnc-resumecustom-freezed2\"\n",
      "}\n",
      "\n",
      "Output directory:  ./training-runs-full/00006-logo-full-res128-auto1-gamma16-kimg700-bgcfnc-resumecustom-freezed2\n",
      "Training data:     ./datasets/logo-full\n",
      "Training length:   700 kimg\n",
      "Resolution:        128\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "Image shape: [3, 128, 128]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
      "Resuming from \"./training-runs-full/00005-logo-full-res128-auto1-gamma16-kimg700-bgcfnc-resumecustom/network-snapshot-000700.pkl\"\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 12, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 12, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "---                           ---       ---                 ---             \n",
      "Total                         22949277                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 128, 128)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "128x128/FromRGB      -         (?, 128, 128, 128)  -               \n",
      "128x128/Conv0        -         (?, 128, 128, 128)  -               \n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                23734273                                      \n",
      "\n",
      "Exporting sample images...\n",
      "2022-06-19 00:05:46.156138: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 700 kimg...\n",
      "\n",
      "tick 0     kimg 0.1      time 1m 46s       sec/tick 19.8    sec/kimg 154.64  maintenance 86.4   gpumem 8.2   augment 0.001\n",
      "Evaluating metrics...\n",
      "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/metrics/inception_v3_features.pkl ... done\n",
      "Calculating real image statistics for fid50k_full...\n"
     ]
    }
   ],
   "source": [
    "#!python stylegan2-ada/train.py --snap=40 --outdir=./training-runs-full --gpus=1 --data=./datasets/logo-full --res=128 --kimg=700 --mirror=False --gamma=16 --freezed=2 --augpipe=bgcfnc --resume=./training-runs-full/00005-logo-full-res128-auto1-gamma16-kimg700-bgcfnc-resumecustom/network-snapshot-000700.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T12:15:31.205399Z",
     "iopub.status.busy": "2022-06-19T12:15:31.205112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256,\n",
      "    \"freeze_layers\": 2\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 16.0\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.6,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1,\n",
      "      \"imgfilter\": 1,\n",
      "      \"noise\": 1,\n",
      "      \"cutout\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 40,\n",
      "  \"network_snapshot_ticks\": 40,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 700,\n",
      "  \"minibatch_size\": 32,\n",
      "  \"minibatch_gpu\": 32,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"./training-runs-full/00006-logo-full-res128-auto1-gamma16-kimg700-bgcfnc-resumecustom-freezed2/network-snapshot-000700.pkl\",\n",
      "  \"run_dir\": \"./training-runs-full/00007-logo-full-res128-auto1-gamma16-kimg700-bgcfnc-resumecustom-freezed2\"\n",
      "}\n",
      "\n",
      "Output directory:  ./training-runs-full/00007-logo-full-res128-auto1-gamma16-kimg700-bgcfnc-resumecustom-freezed2\n",
      "Training data:     ./datasets/logo-full\n",
      "Training length:   700 kimg\n",
      "Resolution:        128\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "Image shape: [3, 128, 128]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
      "Resuming from \"./training-runs-full/00006-logo-full-res128-auto1-gamma16-kimg700-bgcfnc-resumecustom-freezed2/network-snapshot-000700.pkl\"\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 12, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 12, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "---                           ---       ---                 ---             \n",
      "Total                         22949277                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 128, 128)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "128x128/FromRGB      -         (?, 128, 128, 128)  -               \n",
      "128x128/Conv0        -         (?, 128, 128, 128)  -               \n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                23734273                                      \n",
      "\n",
      "Exporting sample images...\n",
      "2022-06-19 12:16:18.023177: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 700 kimg...\n",
      "\n",
      "tick 0     kimg 0.1      time 1m 51s       sec/tick 20.6    sec/kimg 160.73  maintenance 90.1   gpumem 8.6   augment 0.001\n",
      "Evaluating metrics...\n",
      "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/metrics/inception_v3_features.pkl ... done\n",
      "Calculating real image statistics for fid50k_full...\n",
      "network-snapshot-000000        time 7m 29s       fid50k_full 16.8574\n",
      "tick 1     kimg 4.2      time 11m 28s      sec/tick 103.6   sec/kimg 25.30   maintenance 474.0  gpumem 8.7   augment 0.042\n",
      "tick 2     kimg 8.3      time 13m 12s      sec/tick 103.9   sec/kimg 25.37   maintenance 0.0    gpumem 8.7   augment 0.078\n",
      "tick 3     kimg 12.4     time 14m 56s      sec/tick 103.9   sec/kimg 25.38   maintenance 0.0    gpumem 8.7   augment 0.114\n",
      "tick 4     kimg 16.5     time 16m 40s      sec/tick 104.0   sec/kimg 25.40   maintenance 0.0    gpumem 8.7   augment 0.152\n",
      "tick 5     kimg 20.6     time 18m 24s      sec/tick 104.2   sec/kimg 25.45   maintenance 0.0    gpumem 8.7   augment 0.186\n",
      "tick 6     kimg 24.7     time 20m 09s      sec/tick 104.3   sec/kimg 25.46   maintenance 0.0    gpumem 8.7   augment 0.221\n",
      "tick 7     kimg 28.8     time 21m 53s      sec/tick 104.4   sec/kimg 25.49   maintenance 0.0    gpumem 8.7   augment 0.257\n",
      "tick 8     kimg 32.9     time 23m 38s      sec/tick 104.5   sec/kimg 25.50   maintenance 0.0    gpumem 8.7   augment 0.285\n",
      "tick 9     kimg 37.0     time 25m 22s      sec/tick 104.6   sec/kimg 25.53   maintenance 0.0    gpumem 8.7   augment 0.303\n",
      "tick 10    kimg 41.1     time 27m 07s      sec/tick 104.5   sec/kimg 25.51   maintenance 0.0    gpumem 8.7   augment 0.329\n",
      "tick 11    kimg 45.2     time 28m 51s      sec/tick 104.5   sec/kimg 25.51   maintenance 0.0    gpumem 8.7   augment 0.344\n",
      "tick 12    kimg 49.3     time 30m 36s      sec/tick 104.6   sec/kimg 25.53   maintenance 0.0    gpumem 8.7   augment 0.355\n",
      "tick 13    kimg 53.4     time 32m 21s      sec/tick 104.7   sec/kimg 25.57   maintenance 0.0    gpumem 8.7   augment 0.365\n",
      "tick 14    kimg 57.5     time 34m 05s      sec/tick 104.7   sec/kimg 25.56   maintenance 0.0    gpumem 8.7   augment 0.375\n",
      "tick 15    kimg 61.6     time 35m 50s      sec/tick 104.7   sec/kimg 25.57   maintenance 0.0    gpumem 8.7   augment 0.380\n",
      "tick 16    kimg 65.7     time 37m 35s      sec/tick 104.6   sec/kimg 25.55   maintenance 0.0    gpumem 8.7   augment 0.383\n",
      "tick 17    kimg 69.8     time 39m 19s      sec/tick 104.7   sec/kimg 25.55   maintenance 0.0    gpumem 8.7   augment 0.383\n",
      "tick 18    kimg 73.9     time 41m 04s      sec/tick 104.6   sec/kimg 25.55   maintenance 0.0    gpumem 8.7   augment 0.380\n",
      "tick 19    kimg 78.0     time 42m 49s      sec/tick 104.6   sec/kimg 25.54   maintenance 0.0    gpumem 8.7   augment 0.383\n",
      "tick 20    kimg 82.0     time 44m 33s      sec/tick 104.7   sec/kimg 25.56   maintenance 0.0    gpumem 8.7   augment 0.383\n",
      "tick 21    kimg 86.1     time 46m 18s      sec/tick 104.7   sec/kimg 25.55   maintenance 0.0    gpumem 8.7   augment 0.388\n",
      "tick 22    kimg 90.2     time 48m 03s      sec/tick 104.6   sec/kimg 25.54   maintenance 0.0    gpumem 8.7   augment 0.388\n",
      "tick 23    kimg 94.3     time 49m 47s      sec/tick 104.5   sec/kimg 25.52   maintenance 0.0    gpumem 8.7   augment 0.385\n",
      "tick 24    kimg 98.4     time 51m 32s      sec/tick 104.7   sec/kimg 25.56   maintenance 0.0    gpumem 8.7   augment 0.383\n",
      "tick 25    kimg 102.5    time 53m 17s      sec/tick 104.7   sec/kimg 25.56   maintenance 0.0    gpumem 8.7   augment 0.390\n",
      "tick 26    kimg 106.6    time 55m 01s      sec/tick 104.6   sec/kimg 25.53   maintenance 0.0    gpumem 8.7   augment 0.388\n",
      "tick 27    kimg 110.7    time 56m 46s      sec/tick 104.7   sec/kimg 25.55   maintenance 0.0    gpumem 8.7   augment 0.388\n",
      "tick 28    kimg 114.8    time 58m 31s      sec/tick 104.7   sec/kimg 25.55   maintenance 0.0    gpumem 8.7   augment 0.388\n",
      "tick 29    kimg 118.9    time 1h 00m 15s   sec/tick 104.7   sec/kimg 25.56   maintenance 0.0    gpumem 8.7   augment 0.385\n",
      "tick 30    kimg 123.0    time 1h 02m 00s   sec/tick 104.6   sec/kimg 25.54   maintenance 0.0    gpumem 8.7   augment 0.383\n",
      "tick 31    kimg 127.1    time 1h 03m 45s   sec/tick 104.7   sec/kimg 25.57   maintenance 0.0    gpumem 8.7   augment 0.378\n",
      "tick 32    kimg 131.2    time 1h 05m 30s   sec/tick 104.8   sec/kimg 25.58   maintenance 0.0    gpumem 8.7   augment 0.383\n",
      "tick 33    kimg 135.3    time 1h 07m 14s   sec/tick 104.7   sec/kimg 25.56   maintenance 0.0    gpumem 8.7   augment 0.372\n",
      "tick 34    kimg 139.4    time 1h 08m 59s   sec/tick 104.7   sec/kimg 25.57   maintenance 0.0    gpumem 8.7   augment 0.370\n",
      "tick 35    kimg 143.5    time 1h 10m 44s   sec/tick 104.7   sec/kimg 25.57   maintenance 0.0    gpumem 8.7   augment 0.383\n",
      "tick 36    kimg 147.6    time 1h 12m 29s   sec/tick 104.8   sec/kimg 25.59   maintenance 0.0    gpumem 8.7   augment 0.380\n",
      "tick 37    kimg 151.7    time 1h 14m 13s   sec/tick 104.9   sec/kimg 25.60   maintenance 0.0    gpumem 8.7   augment 0.385\n",
      "tick 38    kimg 155.8    time 1h 15m 58s   sec/tick 104.8   sec/kimg 25.58   maintenance 0.0    gpumem 8.7   augment 0.385\n",
      "tick 39    kimg 159.9    time 1h 17m 43s   sec/tick 104.7   sec/kimg 25.55   maintenance 0.0    gpumem 8.7   augment 0.378\n",
      "tick 40    kimg 164.0    time 1h 19m 27s   sec/tick 104.6   sec/kimg 25.54   maintenance 0.0    gpumem 8.7   augment 0.375\n",
      "Evaluating metrics...\n",
      "network-snapshot-000163        time 5m 46s       fid50k_full 17.5880\n",
      "tick 41    kimg 168.1    time 1h 27m 06s   sec/tick 104.5   sec/kimg 25.52   maintenance 354.1  gpumem 8.7   augment 0.375\n",
      "tick 42    kimg 172.2    time 1h 28m 51s   sec/tick 104.5   sec/kimg 25.52   maintenance 0.0    gpumem 8.7   augment 0.380\n",
      "tick 43    kimg 176.3    time 1h 30m 35s   sec/tick 104.7   sec/kimg 25.57   maintenance 0.0    gpumem 8.7   augment 0.388\n",
      "tick 44    kimg 180.4    time 1h 32m 20s   sec/tick 104.6   sec/kimg 25.53   maintenance 0.0    gpumem 8.7   augment 0.396\n",
      "tick 45    kimg 184.4    time 1h 34m 05s   sec/tick 104.7   sec/kimg 25.56   maintenance 0.0    gpumem 8.7   augment 0.393\n",
      "tick 46    kimg 188.5    time 1h 35m 49s   sec/tick 104.7   sec/kimg 25.55   maintenance 0.0    gpumem 8.7   augment 0.396\n",
      "tick 47    kimg 192.6    time 1h 37m 34s   sec/tick 104.9   sec/kimg 25.61   maintenance 0.0    gpumem 8.7   augment 0.396\n",
      "tick 48    kimg 196.7    time 1h 39m 19s   sec/tick 105.0   sec/kimg 25.62   maintenance 0.0    gpumem 8.7   augment 0.401\n",
      "tick 49    kimg 200.8    time 1h 41m 04s   sec/tick 104.9   sec/kimg 25.62   maintenance 0.0    gpumem 8.7   augment 0.390\n",
      "tick 50    kimg 204.9    time 1h 42m 49s   sec/tick 104.8   sec/kimg 25.58   maintenance 0.0    gpumem 8.7   augment 0.390\n",
      "tick 51    kimg 209.0    time 1h 44m 34s   sec/tick 104.5   sec/kimg 25.51   maintenance 0.0    gpumem 8.8   augment 0.393\n",
      "tick 52    kimg 213.1    time 1h 46m 18s   sec/tick 104.6   sec/kimg 25.54   maintenance 0.0    gpumem 8.8   augment 0.388\n",
      "tick 53    kimg 217.2    time 1h 48m 03s   sec/tick 104.6   sec/kimg 25.55   maintenance 0.0    gpumem 8.8   augment 0.393\n",
      "tick 54    kimg 221.3    time 1h 49m 47s   sec/tick 104.7   sec/kimg 25.55   maintenance 0.0    gpumem 8.8   augment 0.396\n",
      "tick 55    kimg 225.4    time 1h 51m 32s   sec/tick 104.7   sec/kimg 25.56   maintenance 0.0    gpumem 8.8   augment 0.393\n",
      "tick 56    kimg 229.5    time 1h 53m 17s   sec/tick 104.7   sec/kimg 25.57   maintenance 0.0    gpumem 8.8   augment 0.398\n",
      "tick 57    kimg 233.6    time 1h 55m 02s   sec/tick 104.7   sec/kimg 25.55   maintenance 0.0    gpumem 8.8   augment 0.393\n",
      "tick 58    kimg 237.7    time 1h 56m 46s   sec/tick 104.7   sec/kimg 25.56   maintenance 0.0    gpumem 8.8   augment 0.396\n"
     ]
    }
   ],
   "source": [
    "#!python stylegan2-ada/train.py --snap=40 --outdir=./training-runs-full --gpus=1 --data=./datasets/logo-full --res=128 --kimg=700 --mirror=False --gamma=16 --freezed=2 --augpipe=bgcfnc --resume=./training-runs-full/00006-logo-full-res128-auto1-gamma16-kimg700-bgcfnc-resumecustom-freezed2/network-snapshot-000700.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T19:31:16.009048Z",
     "iopub.status.busy": "2022-06-19T19:31:16.008733Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256,\n",
      "    \"freeze_layers\": 2\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 16.0\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.6,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1,\n",
      "      \"imgfilter\": 1,\n",
      "      \"noise\": 1,\n",
      "      \"cutout\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 40,\n",
      "  \"network_snapshot_ticks\": 40,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 700,\n",
      "  \"minibatch_size\": 32,\n",
      "  \"minibatch_gpu\": 32,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"./training-runs-full/00007-logo-full-res128-auto1-gamma16-kimg700-bgcfnc-resumecustom-freezed2/network-snapshot-000700.pkl\",\n",
      "  \"run_dir\": \"./training-runs-full/00008-logo-full-res128-auto1-gamma16-kimg700-bgcfnc-resumecustom-freezed2\"\n",
      "}\n",
      "\n",
      "Output directory:  ./training-runs-full/00008-logo-full-res128-auto1-gamma16-kimg700-bgcfnc-resumecustom-freezed2\n",
      "Training data:     ./datasets/logo-full\n",
      "Training length:   700 kimg\n",
      "Resolution:        128\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "Image shape: [3, 128, 128]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Loading... Done.\n",
      "Resuming from \"./training-runs-full/00007-logo-full-res128-auto1-gamma16-kimg700-bgcfnc-resumecustom-freezed2/network-snapshot-000700.pkl\"\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 12, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 12, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "---                           ---       ---                 ---             \n",
      "Total                         22949277                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 128, 128)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "128x128/FromRGB      -         (?, 128, 128, 128)  -               \n",
      "128x128/Conv0        -         (?, 128, 128, 128)  -               \n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                23734273                                      \n",
      "\n",
      "Exporting sample images...\n",
      "2022-06-19 19:31:31.303034: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 700 kimg...\n",
      "\n",
      "tick 0     kimg 0.1      time 1m 26s       sec/tick 21.1    sec/kimg 164.98  maintenance 64.4   gpumem 8.5   augment 0.001\n",
      "Evaluating metrics...\n",
      "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/metrics/inception_v3_features.pkl ... done\n",
      "Calculating real image statistics for fid50k_full...\n",
      "network-snapshot-000000        time 7m 36s       fid50k_full 16.6541\n",
      "tick 1     kimg 4.2      time 11m 12s      sec/tick 103.9   sec/kimg 25.36   maintenance 482.6  gpumem 8.7   augment 0.042\n",
      "tick 2     kimg 8.3      time 12m 56s      sec/tick 104.2   sec/kimg 25.44   maintenance 0.0    gpumem 8.7   augment 0.081\n",
      "tick 3     kimg 12.4     time 14m 41s      sec/tick 104.3   sec/kimg 25.46   maintenance 0.0    gpumem 8.7   augment 0.119\n",
      "tick 4     kimg 16.5     time 16m 25s      sec/tick 104.5   sec/kimg 25.52   maintenance 0.0    gpumem 8.7   augment 0.157\n",
      "tick 5     kimg 20.6     time 18m 10s      sec/tick 104.7   sec/kimg 25.55   maintenance 0.0    gpumem 8.7   augment 0.193\n",
      "tick 6     kimg 24.7     time 19m 55s      sec/tick 104.9   sec/kimg 25.60   maintenance 0.0    gpumem 8.7   augment 0.229\n",
      "tick 7     kimg 28.8     time 21m 39s      sec/tick 104.5   sec/kimg 25.52   maintenance 0.0    gpumem 8.7   augment 0.260\n",
      "tick 8     kimg 32.9     time 23m 24s      sec/tick 104.6   sec/kimg 25.54   maintenance 0.0    gpumem 8.7   augment 0.291\n",
      "tick 9     kimg 37.0     time 25m 09s      sec/tick 104.8   sec/kimg 25.59   maintenance 0.0    gpumem 8.7   augment 0.311\n",
      "tick 10    kimg 41.1     time 26m 54s      sec/tick 104.9   sec/kimg 25.60   maintenance 0.0    gpumem 8.7   augment 0.334\n",
      "tick 11    kimg 45.2     time 28m 39s      sec/tick 105.0   sec/kimg 25.64   maintenance 0.0    gpumem 8.7   augment 0.344\n",
      "tick 12    kimg 49.3     time 30m 23s      sec/tick 104.9   sec/kimg 25.60   maintenance 0.0    gpumem 8.7   augment 0.355\n",
      "tick 13    kimg 53.4     time 32m 08s      sec/tick 105.0   sec/kimg 25.63   maintenance 0.0    gpumem 8.7   augment 0.365\n",
      "tick 14    kimg 57.5     time 33m 53s      sec/tick 105.0   sec/kimg 25.63   maintenance 0.0    gpumem 8.7   augment 0.375\n",
      "tick 15    kimg 61.6     time 35m 38s      sec/tick 105.1   sec/kimg 25.66   maintenance 0.0    gpumem 8.7   augment 0.378\n",
      "tick 16    kimg 65.7     time 37m 23s      sec/tick 105.0   sec/kimg 25.62   maintenance 0.0    gpumem 8.7   augment 0.378\n",
      "tick 17    kimg 69.8     time 39m 08s      sec/tick 104.9   sec/kimg 25.62   maintenance 0.0    gpumem 8.7   augment 0.383\n",
      "tick 18    kimg 73.9     time 40m 54s      sec/tick 105.1   sec/kimg 25.66   maintenance 0.0    gpumem 8.7   augment 0.385\n",
      "tick 19    kimg 78.0     time 42m 39s      sec/tick 105.0   sec/kimg 25.63   maintenance 0.0    gpumem 8.7   augment 0.388\n",
      "tick 20    kimg 82.0     time 44m 23s      sec/tick 104.9   sec/kimg 25.60   maintenance 0.0    gpumem 8.7   augment 0.390\n",
      "tick 21    kimg 86.1     time 46m 08s      sec/tick 105.0   sec/kimg 25.62   maintenance 0.0    gpumem 8.7   augment 0.385\n",
      "tick 22    kimg 90.2     time 47m 53s      sec/tick 105.1   sec/kimg 25.65   maintenance 0.0    gpumem 8.7   augment 0.383\n",
      "tick 23    kimg 94.3     time 49m 38s      sec/tick 105.0   sec/kimg 25.63   maintenance 0.0    gpumem 8.7   augment 0.390\n",
      "tick 24    kimg 98.4     time 51m 24s      sec/tick 105.1   sec/kimg 25.67   maintenance 0.0    gpumem 8.7   augment 0.401\n",
      "tick 25    kimg 102.5    time 53m 09s      sec/tick 105.2   sec/kimg 25.67   maintenance 0.0    gpumem 8.7   augment 0.401\n",
      "tick 26    kimg 106.6    time 54m 54s      sec/tick 105.1   sec/kimg 25.65   maintenance 0.0    gpumem 8.7   augment 0.396\n",
      "tick 27    kimg 110.7    time 56m 39s      sec/tick 105.1   sec/kimg 25.66   maintenance 0.0    gpumem 8.7   augment 0.398\n",
      "tick 28    kimg 114.8    time 58m 24s      sec/tick 104.9   sec/kimg 25.61   maintenance 0.0    gpumem 8.7   augment 0.398\n",
      "tick 29    kimg 118.9    time 1h 00m 09s   sec/tick 105.1   sec/kimg 25.67   maintenance 0.0    gpumem 8.7   augment 0.396\n",
      "tick 30    kimg 123.0    time 1h 01m 54s   sec/tick 105.0   sec/kimg 25.63   maintenance 0.0    gpumem 8.7   augment 0.398\n",
      "tick 31    kimg 127.1    time 1h 03m 39s   sec/tick 105.1   sec/kimg 25.65   maintenance 0.0    gpumem 8.7   augment 0.390\n",
      "tick 32    kimg 131.2    time 1h 05m 24s   sec/tick 104.9   sec/kimg 25.61   maintenance 0.0    gpumem 8.7   augment 0.393\n",
      "tick 33    kimg 135.3    time 1h 07m 09s   sec/tick 105.0   sec/kimg 25.63   maintenance 0.0    gpumem 8.7   augment 0.388\n",
      "tick 34    kimg 139.4    time 1h 08m 54s   sec/tick 104.9   sec/kimg 25.62   maintenance 0.0    gpumem 8.7   augment 0.388\n",
      "tick 35    kimg 143.5    time 1h 10m 39s   sec/tick 105.1   sec/kimg 25.65   maintenance 0.0    gpumem 8.7   augment 0.396\n",
      "tick 36    kimg 147.6    time 1h 12m 24s   sec/tick 105.4   sec/kimg 25.72   maintenance 0.0    gpumem 8.7   augment 0.398\n",
      "tick 37    kimg 151.7    time 1h 14m 10s   sec/tick 105.4   sec/kimg 25.73   maintenance 0.0    gpumem 8.7   augment 0.398\n",
      "tick 38    kimg 155.8    time 1h 15m 55s   sec/tick 105.4   sec/kimg 25.72   maintenance 0.0    gpumem 8.7   augment 0.396\n",
      "tick 39    kimg 159.9    time 1h 17m 41s   sec/tick 105.4   sec/kimg 25.73   maintenance 0.0    gpumem 8.7   augment 0.388\n",
      "tick 40    kimg 164.0    time 1h 19m 26s   sec/tick 105.4   sec/kimg 25.72   maintenance 0.0    gpumem 8.7   augment 0.390\n",
      "Evaluating metrics...\n",
      "network-snapshot-000163        time 5m 55s       fid50k_full 17.3610\n",
      "tick 41    kimg 168.1    time 1h 27m 16s   sec/tick 105.1   sec/kimg 25.67   maintenance 365.4  gpumem 8.7   augment 0.385\n",
      "tick 42    kimg 172.2    time 1h 29m 02s   sec/tick 105.3   sec/kimg 25.70   maintenance 0.0    gpumem 8.7   augment 0.393\n",
      "tick 43    kimg 176.3    time 1h 30m 47s   sec/tick 105.0   sec/kimg 25.63   maintenance 0.0    gpumem 8.7   augment 0.390\n",
      "tick 44    kimg 180.4    time 1h 32m 32s   sec/tick 104.9   sec/kimg 25.62   maintenance 0.0    gpumem 8.7   augment 0.398\n",
      "tick 45    kimg 184.4    time 1h 34m 17s   sec/tick 105.2   sec/kimg 25.68   maintenance 0.0    gpumem 8.7   augment 0.393\n",
      "tick 46    kimg 188.5    time 1h 36m 02s   sec/tick 104.9   sec/kimg 25.62   maintenance 0.0    gpumem 8.7   augment 0.390\n",
      "tick 47    kimg 192.6    time 1h 37m 47s   sec/tick 104.9   sec/kimg 25.62   maintenance 0.0    gpumem 8.7   augment 0.390\n",
      "tick 48    kimg 196.7    time 1h 39m 32s   sec/tick 105.0   sec/kimg 25.63   maintenance 0.0    gpumem 8.7   augment 0.390\n",
      "tick 49    kimg 200.8    time 1h 41m 17s   sec/tick 105.0   sec/kimg 25.64   maintenance 0.0    gpumem 8.7   augment 0.383\n",
      "tick 50    kimg 204.9    time 1h 43m 02s   sec/tick 104.9   sec/kimg 25.61   maintenance 0.0    gpumem 8.7   augment 0.385\n",
      "tick 51    kimg 209.0    time 1h 44m 47s   sec/tick 105.1   sec/kimg 25.67   maintenance 0.0    gpumem 8.7   augment 0.388\n",
      "tick 52    kimg 213.1    time 1h 46m 32s   sec/tick 105.4   sec/kimg 25.74   maintenance 0.0    gpumem 8.7   augment 0.393\n",
      "tick 53    kimg 217.2    time 1h 48m 18s   sec/tick 105.9   sec/kimg 25.84   maintenance 0.0    gpumem 8.7   augment 0.396\n",
      "tick 54    kimg 221.3    time 1h 50m 04s   sec/tick 105.7   sec/kimg 25.80   maintenance 0.0    gpumem 8.7   augment 0.396\n",
      "tick 55    kimg 225.4    time 1h 51m 49s   sec/tick 105.4   sec/kimg 25.74   maintenance 0.0    gpumem 8.7   augment 0.396\n",
      "tick 56    kimg 229.5    time 1h 53m 35s   sec/tick 105.5   sec/kimg 25.75   maintenance 0.0    gpumem 8.7   augment 0.408\n",
      "tick 57    kimg 233.6    time 1h 55m 20s   sec/tick 105.3   sec/kimg 25.70   maintenance 0.0    gpumem 8.7   augment 0.398\n",
      "tick 58    kimg 237.7    time 1h 57m 05s   sec/tick 104.9   sec/kimg 25.61   maintenance 0.0    gpumem 8.7   augment 0.406\n",
      "tick 59    kimg 241.8    time 1h 58m 50s   sec/tick 105.0   sec/kimg 25.62   maintenance 0.0    gpumem 8.7   augment 0.406\n",
      "tick 60    kimg 245.9    time 2h 00m 35s   sec/tick 105.1   sec/kimg 25.65   maintenance 0.0    gpumem 8.7   augment 0.401\n",
      "tick 61    kimg 250.0    time 2h 02m 20s   sec/tick 105.3   sec/kimg 25.70   maintenance 0.0    gpumem 8.7   augment 0.390\n",
      "tick 62    kimg 254.1    time 2h 04m 06s   sec/tick 105.2   sec/kimg 25.68   maintenance 0.0    gpumem 8.7   augment 0.388\n",
      "tick 63    kimg 258.2    time 2h 05m 51s   sec/tick 105.5   sec/kimg 25.75   maintenance 0.0    gpumem 8.7   augment 0.383\n",
      "tick 64    kimg 262.3    time 2h 07m 36s   sec/tick 105.4   sec/kimg 25.72   maintenance 0.0    gpumem 8.9   augment 0.388\n",
      "tick 65    kimg 266.4    time 2h 09m 22s   sec/tick 105.2   sec/kimg 25.69   maintenance 0.0    gpumem 8.9   augment 0.390\n",
      "tick 66    kimg 270.5    time 2h 11m 07s   sec/tick 105.6   sec/kimg 25.77   maintenance 0.0    gpumem 8.9   augment 0.396\n",
      "tick 67    kimg 274.6    time 2h 12m 53s   sec/tick 105.4   sec/kimg 25.73   maintenance 0.0    gpumem 8.9   augment 0.388\n",
      "tick 68    kimg 278.7    time 2h 14m 38s   sec/tick 105.0   sec/kimg 25.64   maintenance 0.0    gpumem 8.9   augment 0.393\n",
      "tick 69    kimg 282.8    time 2h 16m 23s   sec/tick 105.1   sec/kimg 25.65   maintenance 0.0    gpumem 8.9   augment 0.396\n",
      "tick 70    kimg 286.8    time 2h 18m 08s   sec/tick 104.9   sec/kimg 25.61   maintenance 0.0    gpumem 8.9   augment 0.396\n",
      "tick 71    kimg 290.9    time 2h 19m 53s   sec/tick 105.0   sec/kimg 25.62   maintenance 0.0    gpumem 8.9   augment 0.396\n"
     ]
    }
   ],
   "source": [
    "#!python stylegan2-ada/train.py --snap=40 --outdir=./training-runs-full --gpus=1 --data=./datasets/logo-full --res=128 --kimg=700 --mirror=False --gamma=16 --freezed=2 --augpipe=bgcfnc --resume=./training-runs-full/00007-logo-full-res128-auto1-gamma16-kimg700-bgcfnc-resumecustom-freezed2/network-snapshot-000700.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T00:34:05.949819Z",
     "iopub.status.busy": "2022-06-20T00:34:05.949492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256,\n",
      "    \"freeze_layers\": 2\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 16.0\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.6,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1,\n",
      "      \"imgfilter\": 1,\n",
      "      \"noise\": 1,\n",
      "      \"cutout\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 40,\n",
      "  \"network_snapshot_ticks\": 40,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 800,\n",
      "  \"minibatch_size\": 32,\n",
      "  \"minibatch_gpu\": 32,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"./training-runs-full/00008-logo-full-res128-auto1-gamma16-kimg700-bgcfnc-resumecustom-freezed2/network-snapshot-000491.pkl\",\n",
      "  \"run_dir\": \"./training-runs-full/00009-logo-full-res128-auto1-gamma16-kimg800-bgcfnc-resumecustom-freezed2\"\n",
      "}\n",
      "\n",
      "Output directory:  ./training-runs-full/00009-logo-full-res128-auto1-gamma16-kimg800-bgcfnc-resumecustom-freezed2\n",
      "Training data:     ./datasets/logo-full\n",
      "Training length:   800 kimg\n",
      "Resolution:        128\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "Image shape: [3, 128, 128]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
      "Resuming from \"./training-runs-full/00008-logo-full-res128-auto1-gamma16-kimg700-bgcfnc-resumecustom-freezed2/network-snapshot-000491.pkl\"\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 12, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 12, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "---                           ---       ---                 ---             \n",
      "Total                         22949277                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 128, 128)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "128x128/FromRGB      -         (?, 128, 128, 128)  -               \n",
      "128x128/Conv0        -         (?, 128, 128, 128)  -               \n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                23734273                                      \n",
      "\n",
      "Exporting sample images...\n",
      "2022-06-20 00:34:48.381794: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 800 kimg...\n",
      "\n",
      "tick 0     kimg 0.1      time 1m 46s       sec/tick 20.1    sec/kimg 157.00  maintenance 85.8   gpumem 8.7   augment 0.001\n",
      "Evaluating metrics...\n",
      "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/metrics/inception_v3_features.pkl ... done\n",
      "Calculating real image statistics for fid50k_full...\n"
     ]
    }
   ],
   "source": [
    "#!python stylegan2-ada/train.py --snap=40 --outdir=./training-runs-full --gpus=1 --data=./datasets/logo-full --res=128 --kimg=800 --mirror=False --gamma=16 --freezed=2 --augpipe=bgcfnc --resume=./training-runs-full/00008-logo-full-res128-auto1-gamma16-kimg700-bgcfnc-resumecustom-freezed2/network-snapshot-000491.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without --freezed=2 parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T12:23:40.519773Z",
     "iopub.status.busy": "2022-06-20T12:23:40.519322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 16.0\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.6,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1,\n",
      "      \"imgfilter\": 1,\n",
      "      \"noise\": 1,\n",
      "      \"cutout\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 40,\n",
      "  \"network_snapshot_ticks\": 40,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 750,\n",
      "  \"minibatch_size\": 32,\n",
      "  \"minibatch_gpu\": 32,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"./training-runs-full/00009-logo-full-res128-auto1-gamma16-kimg800-bgcfnc-resumecustom-freezed2/network-snapshot-000655.pkl\",\n",
      "  \"run_dir\": \"./training-runs-full/00010-logo-full-res128-auto1-gamma16-kimg750-bgcfnc-resumecustom\"\n",
      "}\n",
      "\n",
      "Output directory:  ./training-runs-full/00010-logo-full-res128-auto1-gamma16-kimg750-bgcfnc-resumecustom\n",
      "Training data:     ./datasets/logo-full\n",
      "Training length:   750 kimg\n",
      "Resolution:        128\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "Image shape: [3, 128, 128]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Loading... Done.\n",
      "Resuming from \"./training-runs-full/00009-logo-full-res128-auto1-gamma16-kimg800-bgcfnc-resumecustom-freezed2/network-snapshot-000655.pkl\"\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 12, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 12, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "---                           ---       ---                 ---             \n",
      "Total                         22949277                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 128, 128)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "128x128/FromRGB      512       (?, 128, 128, 128)  (1, 1, 3, 128)  \n",
      "128x128/Conv0        147584    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                23882369                                      \n",
      "\n",
      "Exporting sample images...\n",
      "2022-06-20 12:23:53.027093: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 750 kimg...\n",
      "\n",
      "tick 0     kimg 0.1      time 1m 19s       sec/tick 21.2    sec/kimg 165.60  maintenance 57.4   gpumem 8.3   augment 0.001\n",
      "Evaluating metrics...\n",
      "network-snapshot-000000        time 5m 51s       fid50k_full 16.8865\n",
      "tick 1     kimg 4.2      time 9m 24s       sec/tick 109.0   sec/kimg 26.62   maintenance 376.8  gpumem 8.6   augment 0.035\n",
      "tick 2     kimg 8.3      time 11m 14s      sec/tick 109.4   sec/kimg 26.72   maintenance 0.0    gpumem 8.6   augment 0.068\n",
      "tick 3     kimg 12.4     time 13m 03s      sec/tick 109.4   sec/kimg 26.71   maintenance 0.0    gpumem 8.6   augment 0.099\n",
      "tick 4     kimg 16.5     time 14m 53s      sec/tick 109.5   sec/kimg 26.74   maintenance 0.0    gpumem 8.6   augment 0.134\n",
      "tick 5     kimg 20.6     time 16m 42s      sec/tick 109.6   sec/kimg 26.76   maintenance 0.0    gpumem 8.6   augment 0.168\n",
      "tick 6     kimg 24.7     time 18m 32s      sec/tick 109.6   sec/kimg 26.75   maintenance 0.0    gpumem 8.6   augment 0.201\n",
      "tick 7     kimg 28.8     time 20m 21s      sec/tick 109.3   sec/kimg 26.68   maintenance 0.0    gpumem 8.6   augment 0.234\n",
      "tick 8     kimg 32.9     time 22m 11s      sec/tick 109.2   sec/kimg 26.67   maintenance 0.0    gpumem 8.7   augment 0.262\n",
      "tick 9     kimg 37.0     time 24m 00s      sec/tick 109.5   sec/kimg 26.73   maintenance 0.0    gpumem 8.7   augment 0.293\n",
      "tick 10    kimg 41.1     time 25m 49s      sec/tick 109.5   sec/kimg 26.73   maintenance 0.0    gpumem 8.7   augment 0.308\n",
      "tick 11    kimg 45.2     time 27m 39s      sec/tick 109.4   sec/kimg 26.72   maintenance 0.0    gpumem 8.7   augment 0.329\n",
      "tick 12    kimg 49.3     time 29m 28s      sec/tick 109.4   sec/kimg 26.71   maintenance 0.0    gpumem 8.7   augment 0.349\n",
      "tick 13    kimg 53.4     time 31m 18s      sec/tick 109.6   sec/kimg 26.75   maintenance 0.0    gpumem 8.7   augment 0.347\n",
      "tick 14    kimg 57.5     time 33m 08s      sec/tick 109.7   sec/kimg 26.77   maintenance 0.0    gpumem 8.7   augment 0.357\n",
      "tick 15    kimg 61.6     time 34m 57s      sec/tick 109.6   sec/kimg 26.76   maintenance 0.0    gpumem 8.7   augment 0.355\n",
      "tick 16    kimg 65.7     time 36m 47s      sec/tick 109.5   sec/kimg 26.73   maintenance 0.0    gpumem 8.7   augment 0.362\n",
      "tick 17    kimg 69.8     time 38m 36s      sec/tick 109.7   sec/kimg 26.78   maintenance 0.0    gpumem 8.7   augment 0.372\n",
      "tick 18    kimg 73.9     time 40m 26s      sec/tick 109.5   sec/kimg 26.74   maintenance 0.0    gpumem 8.7   augment 0.378\n",
      "tick 19    kimg 78.0     time 42m 16s      sec/tick 109.7   sec/kimg 26.77   maintenance 0.0    gpumem 8.7   augment 0.378\n",
      "tick 20    kimg 82.0     time 44m 05s      sec/tick 109.6   sec/kimg 26.77   maintenance 0.0    gpumem 8.7   augment 0.385\n",
      "tick 21    kimg 86.1     time 45m 55s      sec/tick 109.5   sec/kimg 26.73   maintenance 0.0    gpumem 8.7   augment 0.390\n",
      "tick 22    kimg 90.2     time 47m 45s      sec/tick 109.7   sec/kimg 26.78   maintenance 0.0    gpumem 8.7   augment 0.393\n",
      "tick 23    kimg 94.3     time 49m 34s      sec/tick 109.7   sec/kimg 26.78   maintenance 0.0    gpumem 8.7   augment 0.390\n",
      "tick 24    kimg 98.4     time 51m 24s      sec/tick 109.8   sec/kimg 26.80   maintenance 0.0    gpumem 8.7   augment 0.403\n",
      "tick 25    kimg 102.5    time 53m 14s      sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 8.7   augment 0.403\n",
      "tick 26    kimg 106.6    time 55m 04s      sec/tick 110.1   sec/kimg 26.87   maintenance 0.0    gpumem 8.7   augment 0.401\n",
      "tick 27    kimg 110.7    time 56m 54s      sec/tick 110.2   sec/kimg 26.89   maintenance 0.0    gpumem 8.7   augment 0.403\n",
      "tick 28    kimg 114.8    time 58m 45s      sec/tick 110.1   sec/kimg 26.89   maintenance 0.0    gpumem 8.7   augment 0.403\n",
      "tick 29    kimg 118.9    time 1h 00m 35s   sec/tick 110.2   sec/kimg 26.89   maintenance 0.0    gpumem 8.7   augment 0.406\n",
      "tick 30    kimg 123.0    time 1h 02m 25s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 8.7   augment 0.393\n",
      "tick 31    kimg 127.1    time 1h 04m 15s   sec/tick 110.1   sec/kimg 26.87   maintenance 0.0    gpumem 8.7   augment 0.390\n",
      "tick 32    kimg 131.2    time 1h 06m 05s   sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 8.7   augment 0.390\n",
      "tick 33    kimg 135.3    time 1h 07m 55s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.7   augment 0.390\n",
      "tick 34    kimg 139.4    time 1h 09m 45s   sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 8.7   augment 0.390\n",
      "tick 35    kimg 143.5    time 1h 11m 35s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 8.7   augment 0.406\n",
      "tick 36    kimg 147.6    time 1h 13m 25s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.7   augment 0.411\n",
      "tick 37    kimg 151.7    time 1h 15m 15s   sec/tick 109.8   sec/kimg 26.80   maintenance 0.0    gpumem 8.8   augment 0.411\n",
      "tick 38    kimg 155.8    time 1h 17m 04s   sec/tick 109.7   sec/kimg 26.78   maintenance 0.0    gpumem 8.8   augment 0.411\n",
      "tick 39    kimg 159.9    time 1h 18m 54s   sec/tick 109.8   sec/kimg 26.81   maintenance 0.0    gpumem 8.8   augment 0.401\n",
      "tick 40    kimg 164.0    time 1h 20m 44s   sec/tick 109.8   sec/kimg 26.80   maintenance 0.0    gpumem 8.8   augment 0.398\n",
      "Evaluating metrics...\n",
      "network-snapshot-000163        time 5m 49s       fid50k_full 17.3055\n",
      "tick 41    kimg 168.1    time 1h 28m 31s   sec/tick 109.7   sec/kimg 26.79   maintenance 357.3  gpumem 8.8   augment 0.385\n",
      "tick 42    kimg 172.2    time 1h 30m 21s   sec/tick 109.7   sec/kimg 26.79   maintenance 0.0    gpumem 8.8   augment 0.390\n",
      "tick 43    kimg 176.3    time 1h 32m 10s   sec/tick 109.7   sec/kimg 26.79   maintenance 0.0    gpumem 8.8   augment 0.390\n",
      "tick 44    kimg 180.4    time 1h 34m 01s   sec/tick 110.0   sec/kimg 26.87   maintenance 0.0    gpumem 8.8   augment 0.393\n",
      "tick 45    kimg 184.4    time 1h 35m 51s   sec/tick 110.1   sec/kimg 26.89   maintenance 0.0    gpumem 8.8   augment 0.385\n",
      "tick 46    kimg 188.5    time 1h 37m 41s   sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 8.8   augment 0.388\n",
      "tick 47    kimg 192.6    time 1h 39m 31s   sec/tick 110.1   sec/kimg 26.87   maintenance 0.0    gpumem 8.8   augment 0.385\n",
      "tick 48    kimg 196.7    time 1h 41m 21s   sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 8.8   augment 0.388\n",
      "tick 49    kimg 200.8    time 1h 43m 11s   sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 8.8   augment 0.388\n",
      "tick 50    kimg 204.9    time 1h 45m 01s   sec/tick 110.2   sec/kimg 26.90   maintenance 0.0    gpumem 8.8   augment 0.388\n",
      "tick 51    kimg 209.0    time 1h 46m 51s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 8.8   augment 0.383\n",
      "tick 52    kimg 213.1    time 1h 48m 41s   sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 8.8   augment 0.383\n",
      "tick 53    kimg 217.2    time 1h 50m 31s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 8.8   augment 0.388\n",
      "tick 54    kimg 221.3    time 1h 52m 21s   sec/tick 109.7   sec/kimg 26.77   maintenance 0.0    gpumem 8.8   augment 0.396\n",
      "tick 55    kimg 225.4    time 1h 54m 11s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 8.8   augment 0.401\n",
      "tick 56    kimg 229.5    time 1h 56m 01s   sec/tick 110.1   sec/kimg 26.87   maintenance 0.0    gpumem 8.8   augment 0.393\n",
      "tick 57    kimg 233.6    time 1h 57m 51s   sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 8.8   augment 0.403\n",
      "tick 58    kimg 237.7    time 1h 59m 41s   sec/tick 110.2   sec/kimg 26.91   maintenance 0.0    gpumem 8.8   augment 0.406\n",
      "tick 59    kimg 241.8    time 2h 01m 31s   sec/tick 110.2   sec/kimg 26.90   maintenance 0.0    gpumem 8.8   augment 0.401\n",
      "tick 60    kimg 245.9    time 2h 03m 22s   sec/tick 110.2   sec/kimg 26.89   maintenance 0.0    gpumem 8.8   augment 0.398\n",
      "tick 61    kimg 250.0    time 2h 05m 12s   sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 8.8   augment 0.393\n",
      "tick 62    kimg 254.1    time 2h 07m 02s   sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 8.8   augment 0.390\n",
      "tick 63    kimg 258.2    time 2h 08m 52s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 8.8   augment 0.393\n",
      "tick 64    kimg 262.3    time 2h 10m 42s   sec/tick 110.0   sec/kimg 26.87   maintenance 0.0    gpumem 8.8   augment 0.393\n",
      "tick 65    kimg 266.4    time 2h 12m 32s   sec/tick 110.2   sec/kimg 26.90   maintenance 0.0    gpumem 8.8   augment 0.390\n",
      "tick 66    kimg 270.5    time 2h 14m 22s   sec/tick 110.3   sec/kimg 26.92   maintenance 0.0    gpumem 8.8   augment 0.393\n",
      "tick 67    kimg 274.6    time 2h 16m 12s   sec/tick 110.1   sec/kimg 26.87   maintenance 0.0    gpumem 8.8   augment 0.388\n",
      "tick 68    kimg 278.7    time 2h 18m 02s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 8.8   augment 0.393\n",
      "tick 69    kimg 282.8    time 2h 19m 52s   sec/tick 110.2   sec/kimg 26.89   maintenance 0.0    gpumem 8.8   augment 0.396\n",
      "tick 70    kimg 286.8    time 2h 21m 43s   sec/tick 110.1   sec/kimg 26.89   maintenance 0.0    gpumem 8.8   augment 0.390\n",
      "tick 71    kimg 290.9    time 2h 23m 33s   sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 8.8   augment 0.388\n",
      "tick 72    kimg 295.0    time 2h 25m 23s   sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 8.8   augment 0.393\n",
      "tick 73    kimg 299.1    time 2h 27m 13s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.9   augment 0.398\n",
      "tick 74    kimg 303.2    time 2h 29m 03s   sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 8.9   augment 0.401\n",
      "tick 75    kimg 307.3    time 2h 30m 53s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 8.9   augment 0.396\n",
      "tick 76    kimg 311.4    time 2h 32m 43s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 8.9   augment 0.388\n",
      "tick 77    kimg 315.5    time 2h 34m 33s   sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 8.9   augment 0.385\n",
      "tick 78    kimg 319.6    time 2h 36m 23s   sec/tick 110.0   sec/kimg 26.87   maintenance 0.0    gpumem 8.9   augment 0.398\n",
      "tick 79    kimg 323.7    time 2h 38m 13s   sec/tick 110.1   sec/kimg 26.89   maintenance 0.0    gpumem 8.9   augment 0.398\n",
      "tick 80    kimg 327.8    time 2h 40m 03s   sec/tick 110.2   sec/kimg 26.91   maintenance 0.0    gpumem 8.9   augment 0.390\n",
      "Evaluating metrics...\n",
      "network-snapshot-000327        time 5m 51s       fid50k_full 16.9226\n",
      "tick 81    kimg 331.9    time 2h 47m 53s   sec/tick 109.9   sec/kimg 26.84   maintenance 360.0  gpumem 8.9   augment 0.390\n",
      "tick 82    kimg 336.0    time 2h 49m 43s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 8.9   augment 0.388\n",
      "tick 83    kimg 340.1    time 2h 51m 33s   sec/tick 110.2   sec/kimg 26.90   maintenance 0.0    gpumem 8.9   augment 0.390\n",
      "tick 84    kimg 344.2    time 2h 53m 23s   sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 8.9   augment 0.383\n",
      "tick 85    kimg 348.3    time 2h 55m 13s   sec/tick 110.1   sec/kimg 26.89   maintenance 0.0    gpumem 8.9   augment 0.383\n",
      "tick 86    kimg 352.4    time 2h 57m 04s   sec/tick 110.2   sec/kimg 26.90   maintenance 0.0    gpumem 8.9   augment 0.380\n",
      "tick 87    kimg 356.5    time 2h 58m 54s   sec/tick 110.1   sec/kimg 26.89   maintenance 0.0    gpumem 8.9   augment 0.378\n",
      "tick 88    kimg 360.6    time 3h 00m 44s   sec/tick 110.2   sec/kimg 26.90   maintenance 0.0    gpumem 8.9   augment 0.375\n"
     ]
    }
   ],
   "source": [
    "#!python stylegan2-ada/train.py --snap=40 --outdir=./training-runs-full --gpus=1 --data=./datasets/logo-full --res=128 --kimg=750 --mirror=False --gamma=16 --augpipe=bgcfnc --resume=./training-runs-full/00009-logo-full-res128-auto1-gamma16-kimg800-bgcfnc-resumecustom-freezed2/network-snapshot-000655.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## change gamma=10 and --target=0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T21:30:44.001815Z",
     "iopub.status.busy": "2022-06-20T21:30:44.001387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 10.0\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.7,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1,\n",
      "      \"imgfilter\": 1,\n",
      "      \"noise\": 1,\n",
      "      \"cutout\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 40,\n",
      "  \"network_snapshot_ticks\": 40,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 750,\n",
      "  \"minibatch_size\": 32,\n",
      "  \"minibatch_gpu\": 32,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"./training-runs-full/00010-logo-full-res128-auto1-gamma16-kimg750-bgcfnc-resumecustom/network-snapshot-000655.pkl\",\n",
      "  \"run_dir\": \"./training-runs-full/00011-logo-full-res128-auto1-gamma10-kimg750-target0.7-bgcfnc-resumecustom\"\n",
      "}\n",
      "\n",
      "Output directory:  ./training-runs-full/00011-logo-full-res128-auto1-gamma10-kimg750-target0.7-bgcfnc-resumecustom\n",
      "Training data:     ./datasets/logo-full\n",
      "Training length:   750 kimg\n",
      "Resolution:        128\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "Image shape: [3, 128, 128]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
      "Resuming from \"./training-runs-full/00010-logo-full-res128-auto1-gamma16-kimg750-bgcfnc-resumecustom/network-snapshot-000655.pkl\"\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 12, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 12, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "---                           ---       ---                 ---             \n",
      "Total                         22949277                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 128, 128)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "128x128/FromRGB      512       (?, 128, 128, 128)  (1, 1, 3, 128)  \n",
      "128x128/Conv0        147584    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                23882369                                      \n",
      "\n",
      "Exporting sample images...\n",
      "2022-06-20 21:31:29.954867: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 750 kimg...\n",
      "\n",
      "tick 0     kimg 0.1      time 1m 49s       sec/tick 20.8    sec/kimg 162.26  maintenance 88.2   gpumem 8.8   augment 0.001\n",
      "Evaluating metrics...\n",
      "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/metrics/inception_v3_features.pkl ... done\n",
      "Calculating real image statistics for fid50k_full...\n",
      "network-snapshot-000000        time 7m 21s       fid50k_full 16.9518\n"
     ]
    }
   ],
   "source": [
    "#!python stylegan2-ada/train.py --snap=40 --outdir=./training-runs-full --gpus=1 --data=./datasets/logo-full --res=128 --kimg=750 --mirror=False --gamma=10 --augpipe=bgcfnc --target=0.7 --resume=./training-runs-full/00010-logo-full-res128-auto1-gamma16-kimg750-bgcfnc-resumecustom/network-snapshot-000655.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-21T13:02:20.508552Z",
     "iopub.status.busy": "2022-06-21T13:02:20.508234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 10.0\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.7,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1,\n",
      "      \"imgfilter\": 1,\n",
      "      \"noise\": 1,\n",
      "      \"cutout\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 40,\n",
      "  \"network_snapshot_ticks\": 40,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 730,\n",
      "  \"minibatch_size\": 32,\n",
      "  \"minibatch_gpu\": 32,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"./training-runs-full/00011-logo-full-res128-auto1-gamma10-kimg750-target0.7-bgcfnc-resumecustom/network-snapshot-000655.pkl\",\n",
      "  \"run_dir\": \"./training-runs-full/00012-logo-full-res128-auto1-gamma10-kimg730-target0.7-bgcfnc-resumecustom\"\n",
      "}\n",
      "\n",
      "Output directory:  ./training-runs-full/00012-logo-full-res128-auto1-gamma10-kimg730-target0.7-bgcfnc-resumecustom\n",
      "Training data:     ./datasets/logo-full\n",
      "Training length:   730 kimg\n",
      "Resolution:        128\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "Image shape: [3, 128, 128]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
      "Resuming from \"./training-runs-full/00011-logo-full-res128-auto1-gamma10-kimg750-target0.7-bgcfnc-resumecustom/network-snapshot-000655.pkl\"\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 12, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 12, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "---                           ---       ---                 ---             \n",
      "Total                         22949277                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 128, 128)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "128x128/FromRGB      512       (?, 128, 128, 128)  (1, 1, 3, 128)  \n",
      "128x128/Conv0        147584    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                23882369                                      \n",
      "\n",
      "Exporting sample images...\n",
      "2022-06-21 13:03:05.757043: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 730 kimg...\n",
      "\n",
      "tick 0     kimg 0.1      time 1m 51s       sec/tick 21.3    sec/kimg 166.28  maintenance 89.9   gpumem 8.5   augment 0.001\n",
      "Evaluating metrics...\n",
      "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/metrics/inception_v3_features.pkl ... done\n",
      "Calculating real image statistics for fid50k_full...\n",
      "tick 9     kimg 37.0     time 26m 23s      sec/tick 110.9   sec/kimg 27.07   maintenance 0.0    gpumem 8.6   augment 0.291\n",
      "tick 10    kimg 41.1     time 28m 13s      sec/tick 110.8   sec/kimg 27.05   maintenance 0.0    gpumem 8.6   augment 0.311\n"
     ]
    }
   ],
   "source": [
    "#!python stylegan2-ada/train.py --snap=40 --outdir=./training-runs-full --gpus=1 --data=./datasets/logo-full --res=128 --kimg=730 --mirror=False --gamma=10 --augpipe=bgcfnc --target=0.7 --resume=./training-runs-full/00011-logo-full-res128-auto1-gamma10-kimg750-target0.7-bgcfnc-resumecustom/network-snapshot-000655.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-23T14:55:46.731780Z",
     "iopub.status.busy": "2022-06-23T14:55:46.731497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 6.0\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.7,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1,\n",
      "      \"imgfilter\": 1,\n",
      "      \"noise\": 1,\n",
      "      \"cutout\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 60,\n",
      "  \"network_snapshot_ticks\": 60,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 700,\n",
      "  \"minibatch_size\": 32,\n",
      "  \"minibatch_gpu\": 32,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"./training-runs-full/00012-logo-full-res128-auto1-gamma10-kimg730-target0.7-bgcfnc-resumecustom/network-snapshot-000655.pkl\",\n",
      "  \"run_dir\": \"./training-runs-full/00013-logo-full-res128-auto1-gamma6-kimg700-target0.7-bgcfnc-resumecustom\"\n",
      "}\n",
      "\n",
      "Output directory:  ./training-runs-full/00013-logo-full-res128-auto1-gamma6-kimg700-target0.7-bgcfnc-resumecustom\n",
      "Training data:     ./datasets/logo-full\n",
      "Training length:   700 kimg\n",
      "Resolution:        128\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "Image shape: [3, 128, 128]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
      "Resuming from \"./training-runs-full/00012-logo-full-res128-auto1-gamma10-kimg730-target0.7-bgcfnc-resumecustom/network-snapshot-000655.pkl\"\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 12, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 12, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "---                           ---       ---                 ---             \n",
      "Total                         22949277                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 128, 128)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "128x128/FromRGB      512       (?, 128, 128, 128)  (1, 1, 3, 128)  \n",
      "128x128/Conv0        147584    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                23882369                                      \n",
      "\n",
      "Exporting sample images...\n",
      "2022-06-23 14:56:34.686617: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 700 kimg...\n",
      "\n",
      "tick 0     kimg 0.1      time 1m 54s       sec/tick 21.3    sec/kimg 166.69  maintenance 92.3   gpumem 9.0   augment 0.001\n",
      "Evaluating metrics...\n",
      "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/metrics/inception_v3_features.pkl ... done\n",
      "Calculating real image statistics for fid50k_full...\n",
      "network-snapshot-000000        time 7m 29s       fid50k_full 16.4891\n",
      "tick 1     kimg 4.2      time 11m 37s      sec/tick 108.7   sec/kimg 26.54   maintenance 474.8  gpumem 9.0   augment 0.032\n",
      "tick 2     kimg 8.3      time 13m 27s      sec/tick 109.4   sec/kimg 26.71   maintenance 0.0    gpumem 9.0   augment 0.068\n",
      "tick 3     kimg 12.4     time 15m 16s      sec/tick 109.4   sec/kimg 26.71   maintenance 0.0    gpumem 9.0   augment 0.099\n",
      "tick 4     kimg 16.5     time 17m 06s      sec/tick 109.5   sec/kimg 26.74   maintenance 0.0    gpumem 9.0   augment 0.134\n",
      "tick 5     kimg 20.6     time 18m 55s      sec/tick 109.7   sec/kimg 26.79   maintenance 0.0    gpumem 9.0   augment 0.170\n",
      "tick 6     kimg 24.7     time 20m 45s      sec/tick 109.7   sec/kimg 26.78   maintenance 0.0    gpumem 9.0   augment 0.204\n",
      "tick 7     kimg 28.8     time 22m 35s      sec/tick 109.8   sec/kimg 26.80   maintenance 0.0    gpumem 9.0   augment 0.234\n",
      "tick 8     kimg 32.9     time 24m 25s      sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 9.0   augment 0.265\n",
      "tick 9     kimg 37.0     time 26m 15s      sec/tick 110.2   sec/kimg 26.90   maintenance 0.0    gpumem 9.0   augment 0.288\n",
      "tick 10    kimg 41.1     time 28m 05s      sec/tick 109.8   sec/kimg 26.82   maintenance 0.0    gpumem 9.0   augment 0.314\n",
      "tick 11    kimg 45.2     time 29m 55s      sec/tick 110.1   sec/kimg 26.87   maintenance 0.0    gpumem 9.0   augment 0.329\n",
      "tick 12    kimg 49.3     time 31m 45s      sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 9.0   augment 0.344\n",
      "tick 13    kimg 53.4     time 33m 35s      sec/tick 110.1   sec/kimg 26.89   maintenance 0.0    gpumem 9.0   augment 0.349\n",
      "tick 14    kimg 57.5     time 35m 25s      sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 9.0   augment 0.355\n",
      "tick 15    kimg 61.6     time 37m 15s      sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 9.0   augment 0.362\n",
      "tick 16    kimg 65.7     time 39m 05s      sec/tick 110.2   sec/kimg 26.92   maintenance 0.0    gpumem 9.0   augment 0.367\n",
      "tick 17    kimg 69.8     time 40m 55s      sec/tick 110.1   sec/kimg 26.89   maintenance 0.0    gpumem 9.0   augment 0.370\n",
      "tick 18    kimg 73.9     time 42m 46s      sec/tick 110.3   sec/kimg 26.93   maintenance 0.0    gpumem 9.0   augment 0.385\n",
      "tick 19    kimg 78.0     time 44m 36s      sec/tick 110.6   sec/kimg 26.99   maintenance 0.0    gpumem 9.0   augment 0.385\n",
      "tick 20    kimg 82.0     time 46m 27s      sec/tick 110.3   sec/kimg 26.93   maintenance 0.0    gpumem 9.0   augment 0.385\n",
      "tick 21    kimg 86.1     time 48m 17s      sec/tick 110.3   sec/kimg 26.93   maintenance 0.0    gpumem 9.0   augment 0.383\n",
      "tick 22    kimg 90.2     time 50m 07s      sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 9.0   augment 0.380\n",
      "tick 23    kimg 94.3     time 51m 57s      sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 9.0   augment 0.378\n",
      "tick 24    kimg 98.4     time 53m 47s      sec/tick 110.3   sec/kimg 26.92   maintenance 0.0    gpumem 9.0   augment 0.385\n",
      "tick 25    kimg 102.5    time 55m 37s      sec/tick 110.2   sec/kimg 26.89   maintenance 0.0    gpumem 9.0   augment 0.393\n",
      "tick 26    kimg 106.6    time 57m 28s      sec/tick 110.0   sec/kimg 26.87   maintenance 0.0    gpumem 9.0   augment 0.396\n",
      "tick 27    kimg 110.7    time 59m 18s      sec/tick 110.1   sec/kimg 26.89   maintenance 0.0    gpumem 9.0   augment 0.398\n",
      "tick 28    kimg 114.8    time 1h 01m 08s   sec/tick 110.1   sec/kimg 26.89   maintenance 0.0    gpumem 9.0   augment 0.396\n",
      "tick 29    kimg 118.9    time 1h 02m 58s   sec/tick 110.2   sec/kimg 26.91   maintenance 0.0    gpumem 9.0   augment 0.393\n",
      "tick 30    kimg 123.0    time 1h 04m 48s   sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 9.0   augment 0.396\n",
      "tick 31    kimg 127.1    time 1h 06m 38s   sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 9.0   augment 0.388\n",
      "tick 32    kimg 131.2    time 1h 08m 28s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 9.0   augment 0.390\n",
      "tick 33    kimg 135.3    time 1h 10m 18s   sec/tick 110.0   sec/kimg 26.87   maintenance 0.0    gpumem 9.0   augment 0.390\n",
      "tick 34    kimg 139.4    time 1h 12m 08s   sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 9.0   augment 0.388\n",
      "tick 35    kimg 143.5    time 1h 13m 58s   sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 9.0   augment 0.390\n",
      "tick 36    kimg 147.6    time 1h 15m 49s   sec/tick 110.2   sec/kimg 26.90   maintenance 0.0    gpumem 9.0   augment 0.396\n",
      "tick 37    kimg 151.7    time 1h 17m 39s   sec/tick 110.2   sec/kimg 26.90   maintenance 0.0    gpumem 9.0   augment 0.401\n",
      "tick 38    kimg 155.8    time 1h 19m 29s   sec/tick 110.2   sec/kimg 26.90   maintenance 0.0    gpumem 9.0   augment 0.396\n",
      "tick 39    kimg 159.9    time 1h 21m 19s   sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 9.0   augment 0.390\n",
      "tick 40    kimg 164.0    time 1h 23m 09s   sec/tick 110.1   sec/kimg 26.87   maintenance 0.0    gpumem 9.0   augment 0.385\n",
      "tick 41    kimg 168.1    time 1h 24m 59s   sec/tick 110.0   sec/kimg 26.87   maintenance 0.0    gpumem 9.0   augment 0.375\n",
      "tick 42    kimg 172.2    time 1h 26m 49s   sec/tick 110.1   sec/kimg 26.87   maintenance 0.0    gpumem 9.0   augment 0.383\n",
      "tick 43    kimg 176.3    time 1h 28m 39s   sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 9.0   augment 0.378\n",
      "tick 44    kimg 180.4    time 1h 30m 30s   sec/tick 110.2   sec/kimg 26.90   maintenance 0.0    gpumem 9.0   augment 0.378\n",
      "tick 45    kimg 184.4    time 1h 32m 20s   sec/tick 110.1   sec/kimg 26.87   maintenance 0.0    gpumem 9.0   augment 0.383\n",
      "tick 46    kimg 188.5    time 1h 34m 10s   sec/tick 110.1   sec/kimg 26.89   maintenance 0.0    gpumem 9.0   augment 0.383\n",
      "tick 47    kimg 192.6    time 1h 36m 00s   sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 9.0   augment 0.383\n",
      "tick 48    kimg 196.7    time 1h 37m 50s   sec/tick 110.1   sec/kimg 26.89   maintenance 0.0    gpumem 9.0   augment 0.390\n",
      "tick 49    kimg 200.8    time 1h 39m 40s   sec/tick 110.2   sec/kimg 26.92   maintenance 0.0    gpumem 9.0   augment 0.388\n",
      "tick 50    kimg 204.9    time 1h 41m 30s   sec/tick 110.2   sec/kimg 26.90   maintenance 0.0    gpumem 9.0   augment 0.390\n",
      "tick 51    kimg 209.0    time 1h 43m 21s   sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 9.0   augment 0.393\n",
      "tick 52    kimg 213.1    time 1h 45m 11s   sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 9.0   augment 0.388\n",
      "tick 53    kimg 217.2    time 1h 47m 01s   sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 9.0   augment 0.390\n",
      "tick 54    kimg 221.3    time 1h 48m 51s   sec/tick 110.3   sec/kimg 26.92   maintenance 0.0    gpumem 9.0   augment 0.388\n",
      "tick 55    kimg 225.4    time 1h 50m 41s   sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 9.0   augment 0.388\n",
      "tick 56    kimg 229.5    time 1h 52m 31s   sec/tick 110.1   sec/kimg 26.89   maintenance 0.0    gpumem 9.0   augment 0.380\n",
      "tick 57    kimg 233.6    time 1h 54m 21s   sec/tick 110.1   sec/kimg 26.87   maintenance 0.0    gpumem 9.0   augment 0.388\n",
      "tick 58    kimg 237.7    time 1h 56m 12s   sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 9.0   augment 0.393\n",
      "tick 59    kimg 241.8    time 1h 58m 02s   sec/tick 110.1   sec/kimg 26.87   maintenance 0.0    gpumem 9.0   augment 0.385\n",
      "tick 60    kimg 245.9    time 1h 59m 52s   sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 9.0   augment 0.385\n",
      "Evaluating metrics...\n",
      "network-snapshot-000245        time 5m 47s       fid50k_full 15.4285\n",
      "tick 61    kimg 250.0    time 2h 07m 38s   sec/tick 110.2   sec/kimg 26.90   maintenance 355.8  gpumem 9.0   augment 0.383\n",
      "tick 62    kimg 254.1    time 2h 09m 28s   sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 9.0   augment 0.383\n",
      "tick 63    kimg 258.2    time 2h 11m 19s   sec/tick 110.4   sec/kimg 26.94   maintenance 0.0    gpumem 9.0   augment 0.388\n",
      "tick 64    kimg 262.3    time 2h 13m 09s   sec/tick 110.3   sec/kimg 26.93   maintenance 0.0    gpumem 9.0   augment 0.385\n",
      "tick 65    kimg 266.4    time 2h 14m 59s   sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 9.0   augment 0.390\n",
      "tick 66    kimg 270.5    time 2h 16m 49s   sec/tick 109.8   sec/kimg 26.82   maintenance 0.0    gpumem 9.0   augment 0.388\n",
      "tick 67    kimg 274.6    time 2h 18m 39s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 9.0   augment 0.383\n",
      "tick 68    kimg 278.7    time 2h 20m 29s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 9.0   augment 0.390\n",
      "tick 69    kimg 282.8    time 2h 22m 19s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.0   augment 0.398\n",
      "tick 70    kimg 286.8    time 2h 24m 10s   sec/tick 110.3   sec/kimg 26.92   maintenance 0.0    gpumem 9.0   augment 0.390\n",
      "tick 71    kimg 290.9    time 2h 26m 00s   sec/tick 110.2   sec/kimg 26.89   maintenance 0.0    gpumem 9.0   augment 0.383\n",
      "tick 72    kimg 295.0    time 2h 27m 50s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 9.0   augment 0.390\n",
      "tick 73    kimg 299.1    time 2h 29m 40s   sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 9.0   augment 0.390\n",
      "tick 74    kimg 303.2    time 2h 31m 30s   sec/tick 110.1   sec/kimg 26.89   maintenance 0.0    gpumem 9.0   augment 0.385\n",
      "tick 75    kimg 307.3    time 2h 33m 20s   sec/tick 110.1   sec/kimg 26.89   maintenance 0.0    gpumem 9.0   augment 0.390\n",
      "tick 76    kimg 311.4    time 2h 35m 11s   sec/tick 110.8   sec/kimg 27.05   maintenance 0.0    gpumem 9.0   augment 0.393\n",
      "tick 77    kimg 315.5    time 2h 37m 01s   sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 9.0   augment 0.398\n",
      "tick 78    kimg 319.6    time 2h 38m 51s   sec/tick 110.1   sec/kimg 26.87   maintenance 0.0    gpumem 9.0   augment 0.401\n",
      "tick 79    kimg 323.7    time 2h 40m 41s   sec/tick 110.1   sec/kimg 26.87   maintenance 0.0    gpumem 9.0   augment 0.401\n",
      "tick 80    kimg 327.8    time 2h 42m 31s   sec/tick 110.2   sec/kimg 26.89   maintenance 0.0    gpumem 9.0   augment 0.403\n",
      "tick 106   kimg 434.3    time 3h 30m 12s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 9.0   augment 0.385\n",
      "tick 107   kimg 438.4    time 3h 32m 02s   sec/tick 109.8   sec/kimg 26.80   maintenance 0.0    gpumem 9.0   augment 0.388\n",
      "tick 108   kimg 442.5    time 3h 33m 52s   sec/tick 109.8   sec/kimg 26.80   maintenance 0.0    gpumem 9.0   augment 0.390\n",
      "tick 109   kimg 446.6    time 3h 35m 42s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 9.0   augment 0.398\n",
      "tick 110   kimg 450.7    time 3h 37m 32s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 9.0   augment 0.398\n",
      "tick 111   kimg 454.8    time 3h 39m 22s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 9.0   augment 0.388\n",
      "tick 112   kimg 458.9    time 3h 41m 11s   sec/tick 109.8   sec/kimg 26.81   maintenance 0.0    gpumem 9.0   augment 0.390\n",
      "tick 113   kimg 463.0    time 3h 43m 01s   sec/tick 109.8   sec/kimg 26.80   maintenance 0.0    gpumem 9.0   augment 0.393\n",
      "tick 114   kimg 467.1    time 3h 44m 51s   sec/tick 110.1   sec/kimg 26.87   maintenance 0.0    gpumem 9.0   augment 0.396\n",
      "tick 115   kimg 471.2    time 3h 46m 41s   sec/tick 110.1   sec/kimg 26.87   maintenance 0.0    gpumem 9.0   augment 0.401\n",
      "tick 116   kimg 475.3    time 3h 48m 31s   sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 9.0   augment 0.401\n",
      "tick 117   kimg 479.4    time 3h 50m 21s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 9.0   augment 0.396\n",
      "tick 118   kimg 483.5    time 3h 52m 11s   sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 9.0   augment 0.385\n",
      "tick 119   kimg 487.6    time 3h 54m 01s   sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 9.0   augment 0.396\n",
      "tick 120   kimg 491.6    time 3h 55m 51s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 9.0   augment 0.396\n",
      "Evaluating metrics...\n",
      "network-snapshot-000491        time 5m 43s       fid50k_full 15.4305\n",
      "tick 121   kimg 495.7    time 4h 03m 33s   sec/tick 110.0   sec/kimg 26.85   maintenance 351.5  gpumem 9.0   augment 0.396\n",
      "tick 122   kimg 499.8    time 4h 05m 23s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 9.0   augment 0.396\n",
      "tick 123   kimg 503.9    time 4h 07m 13s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 9.0   augment 0.390\n",
      "tick 124   kimg 508.0    time 4h 09m 02s   sec/tick 109.7   sec/kimg 26.77   maintenance 0.0    gpumem 9.0   augment 0.388\n",
      "tick 125   kimg 512.1    time 4h 10m 52s   sec/tick 109.9   sec/kimg 26.82   maintenance 0.0    gpumem 9.0   augment 0.383\n",
      "tick 126   kimg 516.2    time 4h 12m 42s   sec/tick 110.0   sec/kimg 26.85   maintenance 0.0    gpumem 9.0   augment 0.380\n",
      "tick 127   kimg 520.3    time 4h 14m 32s   sec/tick 109.8   sec/kimg 26.80   maintenance 0.0    gpumem 9.0   augment 0.370\n"
     ]
    }
   ],
   "source": [
    "#!python stylegan2-ada/train.py --snap=60 --outdir=./training-runs-full --gpus=1 --data=./datasets/logo-full --res=128 --kimg=700 --mirror=False --gamma=6 --augpipe=bgcfnc --target=0.7 --resume=./training-runs-full/00012-logo-full-res128-auto1-gamma10-kimg730-target0.7-bgcfnc-resumecustom/network-snapshot-000655.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-24T00:28:50.127701Z",
     "iopub.status.busy": "2022-06-24T00:28:50.127024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 6.0\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.6,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1,\n",
      "      \"imgfilter\": 1,\n",
      "      \"noise\": 1,\n",
      "      \"cutout\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 60,\n",
      "  \"network_snapshot_ticks\": 60,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 650,\n",
      "  \"minibatch_size\": 32,\n",
      "  \"minibatch_gpu\": 32,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"./training-runs-full/00013-logo-full-res128-auto1-gamma6-kimg700-target0.7-bgcfnc-resumecustom/network-snapshot-000491.pkl\",\n",
      "  \"run_dir\": \"./training-runs-full/00014-logo-full-res128-auto1-gamma6-kimg650-target0.6-bgcfnc-resumecustom\"\n",
      "}\n",
      "\n",
      "Output directory:  ./training-runs-full/00014-logo-full-res128-auto1-gamma6-kimg650-target0.6-bgcfnc-resumecustom\n",
      "Training data:     ./datasets/logo-full\n",
      "Training length:   650 kimg\n",
      "Resolution:        128\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "Image shape: [3, 128, 128]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
      "Resuming from \"./training-runs-full/00013-logo-full-res128-auto1-gamma6-kimg700-target0.7-bgcfnc-resumecustom/network-snapshot-000491.pkl\"\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 12, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 12, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "---                           ---       ---                 ---             \n",
      "Total                         22949277                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 128, 128)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "128x128/FromRGB      512       (?, 128, 128, 128)  (1, 1, 3, 128)  \n",
      "128x128/Conv0        147584    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                23882369                                      \n",
      "\n",
      "Exporting sample images...\n",
      "2022-06-24 00:29:39.027397: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 650 kimg...\n",
      "\n",
      "tick 0     kimg 0.1      time 1m 58s       sec/tick 22.1    sec/kimg 172.95  maintenance 96.2   gpumem 8.2   augment 0.001\n",
      "Evaluating metrics...\n",
      "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/metrics/inception_v3_features.pkl ... done\n",
      "Calculating real image statistics for fid50k_full...\n"
     ]
    }
   ],
   "source": [
    "#!python stylegan2-ada/train.py --snap=60 --outdir=./training-runs-full --gpus=1 --data=./datasets/logo-full --res=128 --kimg=650 --mirror=False --gamma=6 --augpipe=bgcfnc --target=0.6 --resume=./training-runs-full/00013-logo-full-res128-auto1-gamma6-kimg700-target0.7-bgcfnc-resumecustom/network-snapshot-000491.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-24T11:31:35.371261Z",
     "iopub.status.busy": "2022-06-24T11:31:35.370981Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 6.0\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.6,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1,\n",
      "      \"imgfilter\": 1,\n",
      "      \"noise\": 1,\n",
      "      \"cutout\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 60,\n",
      "  \"network_snapshot_ticks\": 60,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 700,\n",
      "  \"minibatch_size\": 32,\n",
      "  \"minibatch_gpu\": 32,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"./training-runs-full/00014-logo-full-res128-auto1-gamma6-kimg650-target0.6-bgcfnc-resumecustom/network-snapshot-000650.pkl\",\n",
      "  \"run_dir\": \"./training-runs-full/00015-logo-full-res128-auto1-gamma6-kimg700-target0.6-bgcfnc-resumecustom\"\n",
      "}\n",
      "\n",
      "Output directory:  ./training-runs-full/00015-logo-full-res128-auto1-gamma6-kimg700-target0.6-bgcfnc-resumecustom\n",
      "Training data:     ./datasets/logo-full\n",
      "Training length:   700 kimg\n",
      "Resolution:        128\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "Image shape: [3, 128, 128]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
      "Resuming from \"./training-runs-full/00014-logo-full-res128-auto1-gamma6-kimg650-target0.6-bgcfnc-resumecustom/network-snapshot-000650.pkl\"\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 12, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 12, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "---                           ---       ---                 ---             \n",
      "Total                         22949277                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 128, 128)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "128x128/FromRGB      512       (?, 128, 128, 128)  (1, 1, 3, 128)  \n",
      "128x128/Conv0        147584    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                23882369                                      \n",
      "\n",
      "Exporting sample images...\n",
      "2022-06-24 11:32:21.301452: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 700 kimg...\n",
      "\n",
      "tick 0     kimg 0.1      time 1m 50s       sec/tick 20.8    sec/kimg 162.31  maintenance 89.3   gpumem 8.2   augment 0.001\n",
      "Evaluating metrics...\n",
      "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/metrics/inception_v3_features.pkl ... done\n",
      "Calculating real image statistics for fid50k_full...\n",
      "network-snapshot-000000        time 7m 22s       fid50k_full 14.9587\n",
      "tick 1     kimg 4.2      time 11m 25s      sec/tick 109.1   sec/kimg 26.64   maintenance 466.1  gpumem 8.8   augment 0.037\n",
      "tick 2     kimg 8.3      time 13m 15s      sec/tick 109.4   sec/kimg 26.70   maintenance 0.0    gpumem 8.8   augment 0.073\n",
      "tick 3     kimg 12.4     time 15m 04s      sec/tick 109.5   sec/kimg 26.73   maintenance 0.0    gpumem 8.8   augment 0.114\n",
      "tick 4     kimg 16.5     time 16m 54s      sec/tick 109.6   sec/kimg 26.75   maintenance 0.0    gpumem 8.9   augment 0.152\n",
      "tick 5     kimg 20.6     time 18m 43s      sec/tick 109.6   sec/kimg 26.76   maintenance 0.0    gpumem 8.9   augment 0.183\n",
      "tick 6     kimg 24.7     time 20m 33s      sec/tick 109.9   sec/kimg 26.82   maintenance 0.0    gpumem 8.9   augment 0.219\n",
      "tick 7     kimg 28.8     time 22m 23s      sec/tick 109.9   sec/kimg 26.84   maintenance 0.0    gpumem 8.9   augment 0.260\n",
      "tick 8     kimg 32.9     time 24m 13s      sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 8.9   augment 0.296\n",
      "tick 9     kimg 37.0     time 26m 03s      sec/tick 110.2   sec/kimg 26.91   maintenance 0.0    gpumem 8.9   augment 0.326\n",
      "tick 10    kimg 41.1     time 27m 54s      sec/tick 110.3   sec/kimg 26.93   maintenance 0.0    gpumem 8.9   augment 0.357\n",
      "tick 11    kimg 45.2     time 29m 44s      sec/tick 110.3   sec/kimg 26.93   maintenance 0.0    gpumem 8.9   augment 0.378\n",
      "tick 12    kimg 49.3     time 31m 34s      sec/tick 110.2   sec/kimg 26.90   maintenance 0.0    gpumem 8.9   augment 0.398\n",
      "tick 13    kimg 53.4     time 33m 24s      sec/tick 110.2   sec/kimg 26.91   maintenance 0.0    gpumem 8.9   augment 0.411\n",
      "tick 14    kimg 57.5     time 35m 15s      sec/tick 110.3   sec/kimg 26.92   maintenance 0.0    gpumem 8.9   augment 0.431\n",
      "tick 15    kimg 61.6     time 37m 05s      sec/tick 110.3   sec/kimg 26.93   maintenance 0.0    gpumem 8.9   augment 0.454\n",
      "tick 16    kimg 65.7     time 38m 56s      sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 8.9   augment 0.460\n",
      "tick 17    kimg 69.8     time 40m 46s      sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 8.9   augment 0.467\n",
      "tick 18    kimg 73.9     time 42m 36s      sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 8.9   augment 0.472\n",
      "tick 19    kimg 78.0     time 44m 27s      sec/tick 110.6   sec/kimg 26.99   maintenance 0.0    gpumem 9.0   augment 0.470\n",
      "tick 20    kimg 82.0     time 46m 18s      sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.0   augment 0.477\n",
      "tick 21    kimg 86.1     time 48m 08s      sec/tick 110.3   sec/kimg 26.94   maintenance 0.0    gpumem 9.0   augment 0.480\n",
      "tick 22    kimg 90.2     time 49m 58s      sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 9.0   augment 0.488\n",
      "tick 23    kimg 94.3     time 51m 49s      sec/tick 110.6   sec/kimg 27.01   maintenance 0.0    gpumem 9.0   augment 0.495\n",
      "tick 24    kimg 98.4     time 53m 39s      sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 9.0   augment 0.495\n",
      "tick 25    kimg 102.5    time 55m 30s      sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 9.0   augment 0.485\n",
      "tick 26    kimg 106.6    time 57m 21s      sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.0   augment 0.485\n",
      "tick 27    kimg 110.7    time 59m 11s      sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 9.0   augment 0.488\n",
      "tick 28    kimg 114.8    time 1h 01m 02s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 9.0   augment 0.488\n",
      "tick 29    kimg 118.9    time 1h 02m 52s   sec/tick 110.3   sec/kimg 26.94   maintenance 0.0    gpumem 9.0   augment 0.483\n",
      "tick 30    kimg 123.0    time 1h 04m 43s   sec/tick 110.4   sec/kimg 26.95   maintenance 0.0    gpumem 9.0   augment 0.485\n",
      "tick 31    kimg 127.1    time 1h 06m 33s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.0   augment 0.485\n",
      "tick 32    kimg 131.2    time 1h 08m 24s   sec/tick 110.7   sec/kimg 27.01   maintenance 0.0    gpumem 9.0   augment 0.490\n",
      "tick 33    kimg 135.3    time 1h 10m 14s   sec/tick 110.5   sec/kimg 26.99   maintenance 0.0    gpumem 9.1   augment 0.490\n",
      "tick 34    kimg 139.4    time 1h 12m 05s   sec/tick 110.6   sec/kimg 26.99   maintenance 0.0    gpumem 9.1   augment 0.485\n",
      "tick 35    kimg 143.5    time 1h 13m 55s   sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 9.1   augment 0.490\n",
      "tick 36    kimg 147.6    time 1h 15m 46s   sec/tick 110.6   sec/kimg 26.99   maintenance 0.0    gpumem 9.1   augment 0.490\n",
      "tick 37    kimg 151.7    time 1h 17m 36s   sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 9.1   augment 0.480\n",
      "tick 38    kimg 155.8    time 1h 19m 27s   sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 9.1   augment 0.483\n",
      "tick 39    kimg 159.9    time 1h 21m 17s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 9.1   augment 0.485\n",
      "tick 40    kimg 164.0    time 1h 23m 08s   sec/tick 110.5   sec/kimg 26.99   maintenance 0.0    gpumem 9.1   augment 0.488\n",
      "tick 41    kimg 168.1    time 1h 24m 58s   sec/tick 110.3   sec/kimg 26.93   maintenance 0.0    gpumem 9.1   augment 0.485\n",
      "tick 42    kimg 172.2    time 1h 26m 49s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 9.1   augment 0.495\n",
      "tick 43    kimg 176.3    time 1h 28m 39s   sec/tick 110.6   sec/kimg 27.01   maintenance 0.0    gpumem 9.1   augment 0.493\n",
      "tick 44    kimg 180.4    time 1h 30m 30s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 9.1   augment 0.495\n",
      "tick 45    kimg 184.4    time 1h 32m 20s   sec/tick 110.4   sec/kimg 26.95   maintenance 0.0    gpumem 9.1   augment 0.475\n",
      "tick 46    kimg 188.5    time 1h 34m 11s   sec/tick 110.3   sec/kimg 26.94   maintenance 0.0    gpumem 9.1   augment 0.470\n",
      "tick 47    kimg 192.6    time 1h 36m 01s   sec/tick 110.4   sec/kimg 26.95   maintenance 0.0    gpumem 9.1   augment 0.467\n",
      "tick 48    kimg 196.7    time 1h 37m 51s   sec/tick 110.4   sec/kimg 26.97   maintenance 0.0    gpumem 9.1   augment 0.467\n",
      "tick 49    kimg 200.8    time 1h 39m 42s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 9.1   augment 0.470\n",
      "tick 50    kimg 204.9    time 1h 41m 32s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.1   augment 0.477\n",
      "tick 51    kimg 209.0    time 1h 43m 23s   sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 9.1   augment 0.477\n",
      "tick 52    kimg 213.1    time 1h 45m 13s   sec/tick 110.5   sec/kimg 26.99   maintenance 0.0    gpumem 9.1   augment 0.472\n",
      "tick 53    kimg 217.2    time 1h 47m 04s   sec/tick 110.3   sec/kimg 26.94   maintenance 0.0    gpumem 9.1   augment 0.477\n",
      "tick 54    kimg 221.3    time 1h 48m 54s   sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 9.1   augment 0.477\n",
      "tick 55    kimg 225.4    time 1h 50m 45s   sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 9.1   augment 0.477\n",
      "tick 56    kimg 229.5    time 1h 52m 35s   sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 9.1   augment 0.485\n",
      "tick 57    kimg 233.6    time 1h 54m 26s   sec/tick 110.4   sec/kimg 26.95   maintenance 0.0    gpumem 9.1   augment 0.483\n",
      "tick 58    kimg 237.7    time 1h 56m 16s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 9.1   augment 0.485\n",
      "tick 59    kimg 241.8    time 1h 58m 07s   sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 9.1   augment 0.477\n",
      "tick 60    kimg 245.9    time 1h 59m 57s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 9.1   augment 0.488\n",
      "Evaluating metrics...\n",
      "network-snapshot-000245        time 5m 42s       fid50k_full 15.0985\n",
      "tick 61    kimg 250.0    time 2h 07m 38s   sec/tick 110.6   sec/kimg 27.01   maintenance 350.2  gpumem 9.1   augment 0.483\n",
      "tick 62    kimg 254.1    time 2h 09m 28s   sec/tick 110.4   sec/kimg 26.95   maintenance 0.0    gpumem 9.1   augment 0.493\n",
      "tick 63    kimg 258.2    time 2h 11m 19s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 9.1   augment 0.483\n",
      "tick 64    kimg 262.3    time 2h 13m 09s   sec/tick 110.4   sec/kimg 26.95   maintenance 0.0    gpumem 9.1   augment 0.480\n",
      "tick 65    kimg 266.4    time 2h 15m 00s   sec/tick 110.4   sec/kimg 26.95   maintenance 0.0    gpumem 9.1   augment 0.485\n",
      "tick 66    kimg 270.5    time 2h 16m 51s   sec/tick 110.8   sec/kimg 27.05   maintenance 0.0    gpumem 9.1   augment 0.490\n",
      "tick 67    kimg 274.6    time 2h 18m 41s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 9.1   augment 0.490\n",
      "tick 68    kimg 278.7    time 2h 20m 32s   sec/tick 110.4   sec/kimg 26.95   maintenance 0.0    gpumem 9.1   augment 0.490\n",
      "tick 69    kimg 282.8    time 2h 22m 22s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 9.1   augment 0.475\n",
      "tick 70    kimg 286.8    time 2h 24m 13s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.1   augment 0.477\n",
      "tick 71    kimg 290.9    time 2h 26m 03s   sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 9.1   augment 0.467\n",
      "tick 72    kimg 295.0    time 2h 27m 53s   sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 9.1   augment 0.472\n",
      "tick 73    kimg 299.1    time 2h 29m 44s   sec/tick 110.4   sec/kimg 26.95   maintenance 0.0    gpumem 9.1   augment 0.475\n",
      "tick 74    kimg 303.2    time 2h 31m 34s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 9.1   augment 0.472\n",
      "tick 75    kimg 307.3    time 2h 33m 25s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.1   augment 0.477\n",
      "tick 76    kimg 311.4    time 2h 35m 15s   sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 9.1   augment 0.472\n",
      "tick 77    kimg 315.5    time 2h 37m 06s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.1   augment 0.467\n",
      "tick 78    kimg 319.6    time 2h 38m 56s   sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 9.1   augment 0.465\n",
      "tick 79    kimg 323.7    time 2h 40m 46s   sec/tick 110.3   sec/kimg 26.93   maintenance 0.0    gpumem 9.1   augment 0.470\n",
      "tick 80    kimg 327.8    time 2h 42m 37s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.1   augment 0.472\n",
      "tick 81    kimg 331.9    time 2h 44m 27s   sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 9.1   augment 0.475\n",
      "tick 82    kimg 336.0    time 2h 46m 18s   sec/tick 110.6   sec/kimg 27.01   maintenance 0.0    gpumem 9.1   augment 0.483\n",
      "tick 83    kimg 340.1    time 2h 48m 09s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.1   augment 0.488\n",
      "tick 84    kimg 344.2    time 2h 49m 59s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 9.1   augment 0.485\n",
      "tick 85    kimg 348.3    time 2h 51m 50s   sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 9.1   augment 0.485\n",
      "tick 86    kimg 352.4    time 2h 53m 40s   sec/tick 110.4   sec/kimg 26.95   maintenance 0.0    gpumem 9.1   augment 0.488\n",
      "tick 87    kimg 356.5    time 2h 55m 30s   sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 9.1   augment 0.485\n",
      "tick 88    kimg 360.6    time 2h 57m 21s   sec/tick 110.5   sec/kimg 26.99   maintenance 0.0    gpumem 9.1   augment 0.483\n",
      "tick 89    kimg 364.7    time 2h 59m 11s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.1   augment 0.475\n",
      "tick 90    kimg 368.8    time 3h 01m 02s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.1   augment 0.475\n",
      "tick 91    kimg 372.9    time 3h 02m 52s   sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 9.1   augment 0.472\n",
      "tick 92    kimg 377.0    time 3h 04m 43s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 9.1   augment 0.477\n",
      "tick 93    kimg 381.1    time 3h 06m 33s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.1   augment 0.483\n",
      "tick 94    kimg 385.2    time 3h 08m 24s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 9.1   augment 0.488\n",
      "tick 95    kimg 389.2    time 3h 10m 14s   sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 9.1   augment 0.483\n",
      "tick 96    kimg 393.3    time 3h 12m 05s   sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 9.1   augment 0.493\n",
      "tick 97    kimg 397.4    time 3h 13m 55s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.1   augment 0.493\n",
      "tick 98    kimg 401.5    time 3h 15m 46s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.1   augment 0.480\n",
      "tick 99    kimg 405.6    time 3h 17m 36s   sec/tick 110.4   sec/kimg 26.95   maintenance 0.0    gpumem 9.1   augment 0.477\n",
      "tick 100   kimg 409.7    time 3h 19m 27s   sec/tick 110.6   sec/kimg 27.01   maintenance 0.0    gpumem 9.1   augment 0.480\n",
      "tick 101   kimg 413.8    time 3h 21m 17s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.1   augment 0.483\n",
      "tick 102   kimg 417.9    time 3h 23m 08s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.1   augment 0.477\n",
      "tick 103   kimg 422.0    time 3h 24m 58s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 9.1   augment 0.467\n",
      "tick 104   kimg 426.1    time 3h 26m 49s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.1   augment 0.472\n",
      "tick 105   kimg 430.2    time 3h 28m 39s   sec/tick 110.5   sec/kimg 26.99   maintenance 0.0    gpumem 9.1   augment 0.480\n",
      "tick 106   kimg 434.3    time 3h 30m 30s   sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 9.1   augment 0.485\n",
      "tick 107   kimg 438.4    time 3h 32m 20s   sec/tick 110.4   sec/kimg 26.95   maintenance 0.0    gpumem 9.1   augment 0.485\n",
      "tick 108   kimg 442.5    time 3h 34m 11s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.1   augment 0.490\n",
      "tick 109   kimg 446.6    time 3h 36m 01s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 9.1   augment 0.490\n",
      "tick 110   kimg 450.7    time 3h 37m 52s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 9.1   augment 0.495\n",
      "tick 111   kimg 454.8    time 3h 39m 42s   sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 9.1   augment 0.493\n",
      "tick 112   kimg 458.9    time 3h 41m 33s   sec/tick 110.6   sec/kimg 27.01   maintenance 0.0    gpumem 9.1   augment 0.483\n",
      "tick 113   kimg 463.0    time 3h 43m 23s   sec/tick 110.5   sec/kimg 26.99   maintenance 0.0    gpumem 9.1   augment 0.477\n",
      "tick 114   kimg 467.1    time 3h 45m 14s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.1   augment 0.467\n",
      "tick 115   kimg 471.2    time 3h 47m 04s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.1   augment 0.467\n",
      "tick 116   kimg 475.3    time 3h 48m 55s   sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 9.1   augment 0.467\n",
      "tick 117   kimg 479.4    time 3h 50m 46s   sec/tick 110.6   sec/kimg 26.99   maintenance 0.0    gpumem 9.2   augment 0.467\n",
      "tick 118   kimg 483.5    time 3h 52m 36s   sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 9.2   augment 0.470\n",
      "tick 119   kimg 487.6    time 3h 54m 27s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.2   augment 0.477\n",
      "tick 120   kimg 491.6    time 3h 56m 17s   sec/tick 110.4   sec/kimg 26.95   maintenance 0.0    gpumem 9.2   augment 0.483\n",
      "Evaluating metrics...\n",
      "network-snapshot-000491        time 5m 40s       fid50k_full 14.9382\n",
      "tick 121   kimg 495.7    time 4h 03m 56s   sec/tick 110.6   sec/kimg 27.00   maintenance 348.7  gpumem 9.2   augment 0.480\n",
      "tick 122   kimg 499.8    time 4h 05m 47s   sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 9.2   augment 0.477\n",
      "tick 123   kimg 503.9    time 4h 07m 38s   sec/tick 110.7   sec/kimg 27.03   maintenance 0.0    gpumem 9.2   augment 0.475\n",
      "tick 124   kimg 508.0    time 4h 09m 28s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 9.2   augment 0.480\n",
      "tick 125   kimg 512.1    time 4h 11m 19s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 9.2   augment 0.475\n",
      "tick 126   kimg 516.2    time 4h 13m 09s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 9.2   augment 0.472\n",
      "tick 127   kimg 520.3    time 4h 15m 00s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.2   augment 0.477\n",
      "tick 128   kimg 524.4    time 4h 16m 50s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 9.2   augment 0.483\n",
      "tick 129   kimg 528.5    time 4h 18m 41s   sec/tick 110.4   sec/kimg 26.95   maintenance 0.0    gpumem 9.2   augment 0.490\n",
      "tick 130   kimg 532.6    time 4h 20m 31s   sec/tick 110.5   sec/kimg 26.99   maintenance 0.0    gpumem 9.2   augment 0.493\n",
      "tick 131   kimg 536.7    time 4h 22m 22s   sec/tick 110.4   sec/kimg 26.97   maintenance 0.0    gpumem 9.2   augment 0.485\n",
      "tick 132   kimg 540.8    time 4h 24m 12s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.2   augment 0.483\n",
      "tick 133   kimg 544.9    time 4h 26m 03s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 9.2   augment 0.483\n",
      "tick 134   kimg 549.0    time 4h 27m 53s   sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 9.2   augment 0.493\n",
      "tick 135   kimg 553.1    time 4h 29m 44s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.2   augment 0.488\n",
      "tick 136   kimg 557.2    time 4h 31m 34s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 9.2   augment 0.493\n",
      "tick 137   kimg 561.3    time 4h 33m 25s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.2   augment 0.485\n",
      "tick 138   kimg 565.4    time 4h 35m 15s   sec/tick 110.4   sec/kimg 26.95   maintenance 0.0    gpumem 9.2   augment 0.483\n",
      "tick 139   kimg 569.5    time 4h 37m 06s   sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 9.2   augment 0.488\n",
      "tick 140   kimg 573.6    time 4h 38m 56s   sec/tick 110.6   sec/kimg 26.99   maintenance 0.0    gpumem 9.2   augment 0.477\n",
      "tick 141   kimg 577.7    time 4h 40m 47s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 9.2   augment 0.465\n",
      "tick 142   kimg 581.8    time 4h 42m 37s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.2   augment 0.475\n",
      "tick 143   kimg 585.9    time 4h 44m 28s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 9.2   augment 0.472\n",
      "tick 144   kimg 590.0    time 4h 46m 19s   sec/tick 110.7   sec/kimg 27.03   maintenance 0.0    gpumem 9.2   augment 0.485\n",
      "tick 145   kimg 594.0    time 4h 48m 09s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 9.2   augment 0.485\n",
      "tick 146   kimg 598.1    time 4h 50m 00s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 9.2   augment 0.488\n",
      "tick 147   kimg 602.2    time 4h 51m 50s   sec/tick 110.5   sec/kimg 26.99   maintenance 0.0    gpumem 9.2   augment 0.488\n",
      "tick 148   kimg 606.3    time 4h 53m 41s   sec/tick 110.6   sec/kimg 26.99   maintenance 0.0    gpumem 9.2   augment 0.483\n",
      "tick 149   kimg 610.4    time 4h 55m 31s   sec/tick 110.6   sec/kimg 26.99   maintenance 0.0    gpumem 9.2   augment 0.490\n",
      "tick 150   kimg 614.5    time 4h 57m 22s   sec/tick 110.4   sec/kimg 26.95   maintenance 0.0    gpumem 9.2   augment 0.480\n",
      "tick 151   kimg 618.6    time 4h 59m 12s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.2   augment 0.488\n",
      "tick 152   kimg 622.7    time 5h 01m 03s   sec/tick 110.5   sec/kimg 26.99   maintenance 0.0    gpumem 9.2   augment 0.490\n",
      "tick 153   kimg 626.8    time 5h 02m 53s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 9.2   augment 0.480\n",
      "tick 154   kimg 630.9    time 5h 04m 44s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.2   augment 0.475\n",
      "tick 155   kimg 635.0    time 5h 06m 34s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.2   augment 0.467\n",
      "tick 156   kimg 639.1    time 5h 08m 25s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.2   augment 0.472\n",
      "tick 157   kimg 643.2    time 5h 10m 15s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 9.2   augment 0.475\n"
     ]
    }
   ],
   "source": [
    "#!python stylegan2-ada/train.py --snap=60 --outdir=./training-runs-full --gpus=1 --data=./datasets/logo-full --res=128 --kimg=700 --mirror=False --gamma=6 --augpipe=bgcfnc --target=0.6 --resume=./training-runs-full/00014-logo-full-res128-auto1-gamma6-kimg650-target0.6-bgcfnc-resumecustom/network-snapshot-000650.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T15:32:07.100139Z",
     "iopub.status.busy": "2022-06-26T15:32:07.099858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 5.0\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.5,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1,\n",
      "      \"imgfilter\": 1,\n",
      "      \"noise\": 1,\n",
      "      \"cutout\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 60,\n",
      "  \"network_snapshot_ticks\": 60,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 700,\n",
      "  \"minibatch_size\": 32,\n",
      "  \"minibatch_gpu\": 32,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"./training-runs-full/00015-logo-full-res128-auto1-gamma6-kimg700-target0.6-bgcfnc-resumecustom/network-snapshot-000491.pkl\",\n",
      "  \"run_dir\": \"./training-runs-full/00016-logo-full-res128-auto1-gamma5-kimg700-target0.5-bgcfnc-resumecustom\"\n",
      "}\n",
      "\n",
      "Output directory:  ./training-runs-full/00016-logo-full-res128-auto1-gamma5-kimg700-target0.5-bgcfnc-resumecustom\n",
      "Training data:     ./datasets/logo-full\n",
      "Training length:   700 kimg\n",
      "Resolution:        128\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "Image shape: [3, 128, 128]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
      "Resuming from \"./training-runs-full/00015-logo-full-res128-auto1-gamma6-kimg700-target0.6-bgcfnc-resumecustom/network-snapshot-000491.pkl\"\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 12, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 12, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "---                           ---       ---                 ---             \n",
      "Total                         22949277                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 128, 128)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "128x128/FromRGB      512       (?, 128, 128, 128)  (1, 1, 3, 128)  \n",
      "128x128/Conv0        147584    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                23882369                                      \n",
      "\n",
      "Exporting sample images...\n",
      "2022-06-26 15:32:53.743938: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 700 kimg...\n",
      "\n",
      "tick 0     kimg 0.1      time 1m 51s       sec/tick 21.2    sec/kimg 165.48  maintenance 89.9   gpumem 8.9   augment 0.001\n",
      "Evaluating metrics...\n",
      "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/metrics/inception_v3_features.pkl ... done\n",
      "Calculating real image statistics for fid50k_full...\n",
      "network-snapshot-000000        time 7m 29s       fid50k_full 15.0247\n",
      "tick 1     kimg 4.2      time 11m 35s      sec/tick 109.3   sec/kimg 26.68   maintenance 474.6  gpumem 8.9   augment 0.035\n",
      "tick 2     kimg 8.3      time 13m 25s      sec/tick 109.6   sec/kimg 26.76   maintenance 0.0    gpumem 8.9   augment 0.076\n",
      "tick 3     kimg 12.4     time 15m 14s      sec/tick 109.8   sec/kimg 26.79   maintenance 0.0    gpumem 8.9   augment 0.109\n",
      "tick 4     kimg 16.5     time 17m 04s      sec/tick 109.8   sec/kimg 26.80   maintenance 0.0    gpumem 8.9   augment 0.147\n",
      "tick 5     kimg 20.6     time 18m 54s      sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.9   augment 0.183\n",
      "tick 6     kimg 24.7     time 20m 44s      sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 8.9   augment 0.224\n",
      "tick 7     kimg 28.8     time 22m 34s      sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 8.9   augment 0.262\n",
      "tick 8     kimg 32.9     time 24m 24s      sec/tick 110.1   sec/kimg 26.88   maintenance 0.0    gpumem 8.9   augment 0.303\n",
      "tick 9     kimg 37.0     time 26m 15s      sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 8.9   augment 0.339\n",
      "tick 10    kimg 41.1     time 28m 05s      sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 8.9   augment 0.380\n",
      "tick 11    kimg 45.2     time 29m 56s      sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 8.9   augment 0.411\n",
      "tick 12    kimg 49.3     time 31m 46s      sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.9   augment 0.443\n",
      "tick 13    kimg 53.4     time 33m 37s      sec/tick 110.7   sec/kimg 27.01   maintenance 0.0    gpumem 8.9   augment 0.468\n",
      "tick 14    kimg 57.5     time 35m 27s      sec/tick 110.6   sec/kimg 27.01   maintenance 0.0    gpumem 8.9   augment 0.490\n",
      "tick 15    kimg 61.6     time 37m 18s      sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 8.9   augment 0.508\n",
      "tick 16    kimg 65.7     time 39m 09s      sec/tick 110.8   sec/kimg 27.05   maintenance 0.0    gpumem 8.9   augment 0.520\n",
      "tick 17    kimg 69.8     time 41m 00s      sec/tick 110.7   sec/kimg 27.03   maintenance 0.0    gpumem 8.9   augment 0.529\n",
      "tick 18    kimg 73.9     time 42m 51s      sec/tick 110.8   sec/kimg 27.05   maintenance 0.0    gpumem 8.9   augment 0.545\n",
      "tick 19    kimg 78.0     time 44m 41s      sec/tick 110.9   sec/kimg 27.08   maintenance 0.0    gpumem 8.9   augment 0.553\n",
      "tick 20    kimg 82.0     time 46m 32s      sec/tick 110.9   sec/kimg 27.07   maintenance 0.0    gpumem 8.9   augment 0.552\n",
      "tick 21    kimg 86.1     time 48m 23s      sec/tick 110.6   sec/kimg 26.99   maintenance 0.0    gpumem 8.9   augment 0.557\n",
      "tick 22    kimg 90.2     time 50m 14s      sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 8.9   augment 0.559\n",
      "tick 23    kimg 94.3     time 52m 04s      sec/tick 110.6   sec/kimg 26.99   maintenance 0.0    gpumem 8.9   augment 0.564\n",
      "tick 24    kimg 98.4     time 53m 55s      sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 8.9   augment 0.570\n",
      "tick 25    kimg 102.5    time 55m 45s      sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 8.9   augment 0.573\n",
      "tick 26    kimg 106.6    time 57m 36s      sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 8.9   augment 0.572\n",
      "tick 27    kimg 110.7    time 59m 26s      sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.9   augment 0.567\n",
      "tick 28    kimg 114.8    time 1h 01m 17s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.9   augment 0.573\n",
      "tick 29    kimg 118.9    time 1h 03m 08s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.9   augment 0.572\n",
      "tick 30    kimg 123.0    time 1h 04m 58s   sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 8.9   augment 0.575\n",
      "tick 31    kimg 127.1    time 1h 06m 49s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.9   augment 0.564\n",
      "tick 32    kimg 131.2    time 1h 08m 39s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.9   augment 0.566\n",
      "tick 33    kimg 135.3    time 1h 10m 30s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 8.9   augment 0.564\n",
      "tick 34    kimg 139.4    time 1h 12m 20s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.9   augment 0.576\n",
      "tick 35    kimg 143.5    time 1h 14m 11s   sec/tick 110.5   sec/kimg 26.99   maintenance 0.0    gpumem 8.9   augment 0.577\n",
      "tick 36    kimg 147.6    time 1h 16m 01s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.9   augment 0.575\n",
      "tick 37    kimg 151.7    time 1h 17m 52s   sec/tick 110.5   sec/kimg 26.99   maintenance 0.0    gpumem 8.9   augment 0.573\n",
      "tick 38    kimg 155.8    time 1h 19m 43s   sec/tick 110.6   sec/kimg 27.01   maintenance 0.0    gpumem 8.9   augment 0.570\n",
      "tick 39    kimg 159.9    time 1h 21m 33s   sec/tick 110.5   sec/kimg 26.99   maintenance 0.0    gpumem 8.9   augment 0.570\n",
      "tick 40    kimg 164.0    time 1h 23m 24s   sec/tick 110.6   sec/kimg 27.01   maintenance 0.0    gpumem 8.9   augment 0.570\n",
      "tick 41    kimg 168.1    time 1h 25m 14s   sec/tick 110.6   sec/kimg 26.99   maintenance 0.0    gpumem 8.9   augment 0.572\n",
      "tick 42    kimg 172.2    time 1h 27m 05s   sec/tick 110.6   sec/kimg 26.99   maintenance 0.0    gpumem 8.9   augment 0.579\n",
      "tick 43    kimg 176.3    time 1h 28m 56s   sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 8.9   augment 0.575\n",
      "tick 44    kimg 180.4    time 1h 30m 46s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 8.9   augment 0.580\n",
      "tick 45    kimg 184.4    time 1h 32m 37s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.9   augment 0.577\n",
      "tick 46    kimg 188.5    time 1h 34m 27s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.9   augment 0.575\n",
      "tick 47    kimg 192.6    time 1h 36m 18s   sec/tick 110.6   sec/kimg 26.99   maintenance 0.0    gpumem 8.9   augment 0.581\n",
      "tick 48    kimg 196.7    time 1h 38m 08s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 8.9   augment 0.580\n",
      "tick 49    kimg 200.8    time 1h 39m 59s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.9   augment 0.585\n",
      "tick 50    kimg 204.9    time 1h 41m 49s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 8.9   augment 0.586\n",
      "tick 51    kimg 209.0    time 1h 43m 40s   sec/tick 110.5   sec/kimg 26.99   maintenance 0.0    gpumem 8.9   augment 0.576\n",
      "tick 52    kimg 213.1    time 1h 45m 30s   sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 8.9   augment 0.576\n",
      "tick 53    kimg 217.2    time 1h 47m 21s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.9   augment 0.582\n",
      "tick 54    kimg 221.3    time 1h 49m 11s   sec/tick 110.6   sec/kimg 26.99   maintenance 0.0    gpumem 8.9   augment 0.576\n",
      "tick 55    kimg 225.4    time 1h 51m 02s   sec/tick 110.7   sec/kimg 27.01   maintenance 0.0    gpumem 8.9   augment 0.582\n",
      "tick 56    kimg 229.5    time 1h 52m 53s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.9   augment 0.585\n",
      "tick 57    kimg 233.6    time 1h 54m 43s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.9   augment 0.577\n",
      "tick 58    kimg 237.7    time 1h 56m 34s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.9   augment 0.577\n",
      "tick 59    kimg 241.8    time 1h 58m 24s   sec/tick 110.6   sec/kimg 26.99   maintenance 0.0    gpumem 8.9   augment 0.581\n",
      "tick 60    kimg 245.9    time 2h 00m 15s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.9   augment 0.584\n",
      "Evaluating metrics...\n",
      "network-snapshot-000245        time 5m 45s       fid50k_full 14.8435\n",
      "tick 61    kimg 250.0    time 2h 07m 59s   sec/tick 110.5   sec/kimg 26.98   maintenance 354.0  gpumem 8.9   augment 0.586\n",
      "tick 62    kimg 254.1    time 2h 09m 50s   sec/tick 110.5   sec/kimg 26.99   maintenance 0.0    gpumem 8.9   augment 0.581\n",
      "tick 63    kimg 258.2    time 2h 11m 41s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.9   augment 0.581\n",
      "tick 64    kimg 262.3    time 2h 13m 31s   sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 8.9   augment 0.575\n",
      "tick 65    kimg 266.4    time 2h 15m 22s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.9   augment 0.571\n",
      "tick 66    kimg 270.5    time 2h 17m 12s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.9   augment 0.579\n",
      "tick 67    kimg 274.6    time 2h 19m 03s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.9   augment 0.576\n",
      "tick 68    kimg 278.7    time 2h 20m 54s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.9   augment 0.576\n",
      "tick 69    kimg 282.8    time 2h 22m 44s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.9   augment 0.572\n",
      "tick 70    kimg 286.8    time 2h 24m 35s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.9   augment 0.581\n",
      "tick 71    kimg 290.9    time 2h 26m 25s   sec/tick 110.6   sec/kimg 26.99   maintenance 0.0    gpumem 8.9   augment 0.586\n",
      "tick 72    kimg 295.0    time 2h 28m 16s   sec/tick 110.6   sec/kimg 26.99   maintenance 0.0    gpumem 8.9   augment 0.589\n",
      "tick 73    kimg 299.1    time 2h 30m 07s   sec/tick 110.9   sec/kimg 27.09   maintenance 0.0    gpumem 8.9   augment 0.591\n",
      "tick 74    kimg 303.2    time 2h 31m 58s   sec/tick 110.6   sec/kimg 27.01   maintenance 0.0    gpumem 8.9   augment 0.593\n",
      "tick 75    kimg 307.3    time 2h 33m 48s   sec/tick 110.8   sec/kimg 27.06   maintenance 0.0    gpumem 8.9   augment 0.593\n",
      "tick 76    kimg 311.4    time 2h 35m 39s   sec/tick 110.6   sec/kimg 27.01   maintenance 0.0    gpumem 8.9   augment 0.579\n",
      "tick 77    kimg 315.5    time 2h 37m 30s   sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 8.9   augment 0.579\n",
      "tick 78    kimg 319.6    time 2h 39m 20s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.9   augment 0.581\n",
      "tick 79    kimg 323.7    time 2h 41m 11s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.9   augment 0.582\n",
      "tick 80    kimg 327.8    time 2h 43m 02s   sec/tick 110.7   sec/kimg 27.03   maintenance 0.0    gpumem 8.9   augment 0.585\n",
      "tick 81    kimg 331.9    time 2h 44m 52s   sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 8.9   augment 0.582\n",
      "tick 82    kimg 336.0    time 2h 46m 43s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 8.9   augment 0.589\n",
      "tick 83    kimg 340.1    time 2h 48m 33s   sec/tick 110.6   sec/kimg 27.01   maintenance 0.0    gpumem 8.9   augment 0.589\n",
      "tick 84    kimg 344.2    time 2h 50m 24s   sec/tick 110.6   sec/kimg 26.99   maintenance 0.0    gpumem 8.9   augment 0.594\n",
      "tick 85    kimg 348.3    time 2h 52m 15s   sec/tick 110.6   sec/kimg 27.01   maintenance 0.0    gpumem 8.9   augment 0.586\n",
      "tick 86    kimg 352.4    time 2h 54m 05s   sec/tick 110.7   sec/kimg 27.03   maintenance 0.0    gpumem 8.9   augment 0.581\n",
      "tick 87    kimg 356.5    time 2h 55m 56s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 8.9   augment 0.582\n",
      "tick 88    kimg 360.6    time 2h 57m 47s   sec/tick 110.7   sec/kimg 27.03   maintenance 0.0    gpumem 8.9   augment 0.577\n",
      "tick 89    kimg 364.7    time 2h 59m 37s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.9   augment 0.573\n",
      "tick 90    kimg 368.8    time 3h 01m 28s   sec/tick 110.6   sec/kimg 27.01   maintenance 0.0    gpumem 8.9   augment 0.579\n",
      "tick 91    kimg 372.9    time 3h 03m 18s   sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 8.9   augment 0.575\n",
      "tick 92    kimg 377.0    time 3h 05m 09s   sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 8.9   augment 0.581\n",
      "tick 93    kimg 381.1    time 3h 07m 00s   sec/tick 110.6   sec/kimg 27.01   maintenance 0.0    gpumem 8.9   augment 0.577\n",
      "tick 94    kimg 385.2    time 3h 08m 50s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.9   augment 0.575\n",
      "tick 95    kimg 389.2    time 3h 10m 41s   sec/tick 110.5   sec/kimg 26.99   maintenance 0.0    gpumem 8.9   augment 0.577\n",
      "tick 96    kimg 393.3    time 3h 12m 31s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.9   augment 0.588\n",
      "tick 97    kimg 397.4    time 3h 14m 22s   sec/tick 110.5   sec/kimg 26.99   maintenance 0.0    gpumem 8.9   augment 0.588\n",
      "tick 98    kimg 401.5    time 3h 16m 13s   sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 8.9   augment 0.584\n",
      "tick 99    kimg 405.6    time 3h 18m 03s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 8.9   augment 0.584\n",
      "tick 100   kimg 409.7    time 3h 19m 54s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.9   augment 0.593\n",
      "tick 101   kimg 413.8    time 3h 21m 44s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.9   augment 0.594\n",
      "tick 102   kimg 417.9    time 3h 23m 35s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 8.9   augment 0.594\n",
      "tick 103   kimg 422.0    time 3h 25m 25s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.9   augment 0.596\n",
      "tick 104   kimg 426.1    time 3h 27m 16s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.9   augment 0.596\n",
      "tick 105   kimg 430.2    time 3h 29m 07s   sec/tick 110.5   sec/kimg 26.99   maintenance 0.0    gpumem 8.9   augment 0.595\n",
      "tick 106   kimg 434.3    time 3h 30m 57s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.9   augment 0.598\n",
      "tick 107   kimg 438.4    time 3h 32m 48s   sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 8.9   augment 0.593\n",
      "tick 108   kimg 442.5    time 3h 34m 38s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.9   augment 0.588\n",
      "tick 109   kimg 446.6    time 3h 36m 29s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.9   augment 0.581\n",
      "tick 110   kimg 450.7    time 3h 38m 20s   sec/tick 110.6   sec/kimg 27.01   maintenance 0.0    gpumem 8.9   augment 0.594\n",
      "tick 111   kimg 454.8    time 3h 40m 10s   sec/tick 110.6   sec/kimg 26.99   maintenance 0.0    gpumem 8.9   augment 0.599\n",
      "tick 112   kimg 458.9    time 3h 42m 01s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.9   augment 0.595\n",
      "tick 113   kimg 463.0    time 3h 43m 51s   sec/tick 110.7   sec/kimg 27.04   maintenance 0.0    gpumem 8.9   augment 0.590\n",
      "tick 114   kimg 467.1    time 3h 45m 42s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.9   augment 0.585\n",
      "tick 115   kimg 471.2    time 3h 47m 32s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.9   augment 0.585\n",
      "tick 116   kimg 475.3    time 3h 49m 23s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.9   augment 0.584\n",
      "tick 117   kimg 479.4    time 3h 51m 14s   sec/tick 110.5   sec/kimg 26.99   maintenance 0.0    gpumem 8.9   augment 0.579\n",
      "tick 118   kimg 483.5    time 3h 53m 04s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.9   augment 0.577\n",
      "tick 119   kimg 487.6    time 3h 54m 55s   sec/tick 110.4   sec/kimg 26.95   maintenance 0.0    gpumem 8.9   augment 0.575\n",
      "tick 120   kimg 491.6    time 3h 56m 45s   sec/tick 110.6   sec/kimg 27.01   maintenance 0.0    gpumem 8.9   augment 0.568\n",
      "Evaluating metrics...\n",
      "network-snapshot-000491        time 5m 44s       fid50k_full 14.1941\n",
      "tick 121   kimg 495.7    time 4h 04m 29s   sec/tick 110.6   sec/kimg 27.00   maintenance 352.9  gpumem 8.9   augment 0.572\n",
      "tick 122   kimg 499.8    time 4h 06m 19s   sec/tick 110.6   sec/kimg 27.01   maintenance 0.0    gpumem 8.9   augment 0.568\n",
      "tick 123   kimg 503.9    time 4h 08m 10s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.9   augment 0.563\n",
      "tick 124   kimg 508.0    time 4h 10m 00s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.9   augment 0.563\n",
      "tick 125   kimg 512.1    time 4h 11m 51s   sec/tick 110.5   sec/kimg 26.99   maintenance 0.0    gpumem 8.9   augment 0.567\n",
      "tick 126   kimg 516.2    time 4h 13m 42s   sec/tick 110.5   sec/kimg 26.99   maintenance 0.0    gpumem 8.9   augment 0.572\n",
      "tick 127   kimg 520.3    time 4h 15m 32s   sec/tick 110.6   sec/kimg 26.99   maintenance 0.0    gpumem 8.9   augment 0.566\n",
      "tick 128   kimg 524.4    time 4h 17m 23s   sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 8.9   augment 0.567\n",
      "tick 129   kimg 528.5    time 4h 19m 14s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.9   augment 0.570\n",
      "tick 130   kimg 532.6    time 4h 21m 04s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.9   augment 0.566\n",
      "tick 131   kimg 536.7    time 4h 22m 55s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.9   augment 0.562\n",
      "tick 132   kimg 540.8    time 4h 24m 45s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.9   augment 0.559\n",
      "tick 133   kimg 544.9    time 4h 26m 36s   sec/tick 110.5   sec/kimg 26.99   maintenance 0.0    gpumem 8.9   augment 0.564\n",
      "tick 134   kimg 549.0    time 4h 28m 26s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 8.9   augment 0.568\n",
      "tick 135   kimg 553.1    time 4h 30m 17s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.9   augment 0.564\n",
      "tick 136   kimg 557.2    time 4h 32m 07s   sec/tick 110.6   sec/kimg 26.99   maintenance 0.0    gpumem 8.9   augment 0.562\n",
      "tick 137   kimg 561.3    time 4h 33m 58s   sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 8.9   augment 0.570\n",
      "tick 138   kimg 565.4    time 4h 35m 48s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 8.9   augment 0.567\n",
      "tick 139   kimg 569.5    time 4h 37m 39s   sec/tick 110.6   sec/kimg 27.01   maintenance 0.0    gpumem 8.9   augment 0.575\n",
      "tick 140   kimg 573.6    time 4h 39m 30s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.9   augment 0.572\n",
      "tick 141   kimg 577.7    time 4h 41m 20s   sec/tick 110.8   sec/kimg 27.04   maintenance 0.0    gpumem 8.9   augment 0.577\n",
      "tick 142   kimg 581.8    time 4h 43m 11s   sec/tick 110.8   sec/kimg 27.05   maintenance 0.0    gpumem 8.9   augment 0.579\n",
      "tick 143   kimg 585.9    time 4h 45m 02s   sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 8.9   augment 0.572\n",
      "tick 144   kimg 590.0    time 4h 46m 53s   sec/tick 110.7   sec/kimg 27.03   maintenance 0.0    gpumem 8.9   augment 0.566\n",
      "tick 145   kimg 594.0    time 4h 48m 43s   sec/tick 110.6   sec/kimg 27.01   maintenance 0.0    gpumem 8.9   augment 0.564\n",
      "tick 146   kimg 598.1    time 4h 50m 34s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 8.9   augment 0.564\n",
      "tick 147   kimg 602.2    time 4h 52m 24s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.9   augment 0.568\n",
      "tick 148   kimg 606.3    time 4h 54m 15s   sec/tick 110.6   sec/kimg 26.99   maintenance 0.0    gpumem 8.9   augment 0.571\n",
      "tick 149   kimg 610.4    time 4h 56m 05s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.9   augment 0.572\n",
      "tick 150   kimg 614.5    time 4h 57m 56s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 8.9   augment 0.567\n",
      "tick 151   kimg 618.6    time 4h 59m 47s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.9   augment 0.573\n",
      "tick 152   kimg 622.7    time 5h 01m 37s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 8.9   augment 0.585\n",
      "tick 153   kimg 626.8    time 5h 03m 28s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.9   augment 0.576\n",
      "tick 154   kimg 630.9    time 5h 05m 18s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.9   augment 0.571\n",
      "tick 155   kimg 635.0    time 5h 07m 09s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.9   augment 0.570\n",
      "tick 156   kimg 639.1    time 5h 08m 59s   sec/tick 110.5   sec/kimg 26.99   maintenance 0.0    gpumem 8.9   augment 0.573\n",
      "tick 157   kimg 643.2    time 5h 10m 50s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.9   augment 0.572\n",
      "tick 158   kimg 647.3    time 5h 12m 40s   sec/tick 110.6   sec/kimg 27.01   maintenance 0.0    gpumem 8.9   augment 0.567\n",
      "tick 159   kimg 651.4    time 5h 14m 31s   sec/tick 110.5   sec/kimg 26.99   maintenance 0.0    gpumem 8.9   augment 0.564\n",
      "tick 160   kimg 655.5    time 5h 16m 21s   sec/tick 110.4   sec/kimg 26.95   maintenance 0.0    gpumem 8.9   augment 0.566\n",
      "tick 161   kimg 659.6    time 5h 18m 12s   sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 8.9   augment 0.573\n",
      "tick 162   kimg 663.7    time 5h 20m 02s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.9   augment 0.571\n",
      "tick 163   kimg 667.8    time 5h 21m 53s   sec/tick 110.6   sec/kimg 26.99   maintenance 0.0    gpumem 8.9   augment 0.567\n",
      "tick 164   kimg 671.9    time 5h 23m 44s   sec/tick 110.9   sec/kimg 27.07   maintenance 0.0    gpumem 8.9   augment 0.566\n",
      "tick 165   kimg 676.0    time 5h 25m 34s   sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 8.9   augment 0.558\n",
      "tick 166   kimg 680.1    time 5h 27m 25s   sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 8.9   augment 0.566\n",
      "tick 167   kimg 684.2    time 5h 29m 16s   sec/tick 110.8   sec/kimg 27.04   maintenance 0.0    gpumem 8.9   augment 0.563\n"
     ]
    }
   ],
   "source": [
    "#!python stylegan2-ada/train.py --snap=60 --outdir=./training-runs-full --gpus=1 --data=./datasets/logo-full --res=128 --kimg=700 --mirror=False --gamma=5 --augpipe=bgcfnc --target=0.5 --resume=./training-runs-full/00015-logo-full-res128-auto1-gamma6-kimg700-target0.6-bgcfnc-resumecustom/network-snapshot-000491.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T22:06:42.183727Z",
     "iopub.status.busy": "2022-06-26T22:06:42.183439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 5.0\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.5,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1,\n",
      "      \"imgfilter\": 1,\n",
      "      \"noise\": 1,\n",
      "      \"cutout\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 60,\n",
      "  \"network_snapshot_ticks\": 60,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 700,\n",
      "  \"minibatch_size\": 32,\n",
      "  \"minibatch_gpu\": 32,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"./training-runs-full/00016-logo-full-res128-auto1-gamma5-kimg700-target0.5-bgcfnc-resumecustom/network-snapshot-000700.pkl\",\n",
      "  \"run_dir\": \"./training-runs-full/00017-logo-full-res128-auto1-gamma5-kimg700-target0.5-bgcfnc-resumecustom\"\n",
      "}\n",
      "\n",
      "Output directory:  ./training-runs-full/00017-logo-full-res128-auto1-gamma5-kimg700-target0.5-bgcfnc-resumecustom\n",
      "Training data:     ./datasets/logo-full\n",
      "Training length:   700 kimg\n",
      "Resolution:        128\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "Image shape: [3, 128, 128]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
      "Resuming from \"./training-runs-full/00016-logo-full-res128-auto1-gamma5-kimg700-target0.5-bgcfnc-resumecustom/network-snapshot-000700.pkl\"\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 12, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 12, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "---                           ---       ---                 ---             \n",
      "Total                         22949277                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 128, 128)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "128x128/FromRGB      512       (?, 128, 128, 128)  (1, 1, 3, 128)  \n",
      "128x128/Conv0        147584    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                23882369                                      \n",
      "\n",
      "Exporting sample images...\n",
      "2022-06-26 22:07:27.642157: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n"
     ]
    }
   ],
   "source": [
    "#!python stylegan2-ada/train.py --snap=60 --outdir=./training-runs-full --gpus=1 --data=./datasets/logo-full --res=128 --kimg=700 --mirror=False --gamma=5 --augpipe=bgcfnc --target=0.5 --resume=./training-runs-full/00016-logo-full-res128-auto1-gamma5-kimg700-target0.5-bgcfnc-resumecustom/network-snapshot-000700.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T00:08:32.712814Z",
     "iopub.status.busy": "2022-06-30T00:08:32.712522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 5.0\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.5,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1,\n",
      "      \"imgfilter\": 1,\n",
      "      \"noise\": 1,\n",
      "      \"cutout\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 60,\n",
      "  \"network_snapshot_ticks\": 60,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 700,\n",
      "  \"minibatch_size\": 32,\n",
      "  \"minibatch_gpu\": 32,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"./training-runs-full/00017-logo-full-res128-auto1-gamma5-kimg700-target0.5-bgcfnc-resumecustom/network-snapshot-000700.pkl\",\n",
      "  \"run_dir\": \"./training-runs-full/00018-logo-full-res128-auto1-gamma5-kimg700-target0.5-bgcfnc-resumecustom\"\n",
      "}\n",
      "\n",
      "Output directory:  ./training-runs-full/00018-logo-full-res128-auto1-gamma5-kimg700-target0.5-bgcfnc-resumecustom\n",
      "Training data:     ./datasets/logo-full\n",
      "Training length:   700 kimg\n",
      "Resolution:        128\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "Image shape: [3, 128, 128]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
      "Resuming from \"./training-runs-full/00017-logo-full-res128-auto1-gamma5-kimg700-target0.5-bgcfnc-resumecustom/network-snapshot-000700.pkl\"\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 12, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 12, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "---                           ---       ---                 ---             \n",
      "Total                         22949277                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 128, 128)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "128x128/FromRGB      512       (?, 128, 128, 128)  (1, 1, 3, 128)  \n",
      "128x128/Conv0        147584    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                23882369                                      \n",
      "\n",
      "Exporting sample images...\n",
      "2022-06-30 00:09:19.134657: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 700 kimg...\n",
      "\n",
      "tick 0     kimg 0.1      time 1m 53s       sec/tick 21.1    sec/kimg 164.81  maintenance 91.6   gpumem 8.2   augment 0.001\n",
      "Evaluating metrics...\n",
      "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/metrics/inception_v3_features.pkl ... done\n",
      "Calculating real image statistics for fid50k_full...\n",
      "network-snapshot-000000        time 7m 30s       fid50k_full 14.2002\n",
      "tick 1     kimg 4.2      time 11m 38s      sec/tick 109.1   sec/kimg 26.64   maintenance 476.3  gpumem 8.6   augment 0.040\n",
      "tick 2     kimg 8.3      time 13m 28s      sec/tick 109.3   sec/kimg 26.70   maintenance 0.0    gpumem 8.6   augment 0.070\n",
      "tick 3     kimg 12.4     time 15m 17s      sec/tick 109.3   sec/kimg 26.69   maintenance 0.0    gpumem 8.6   augment 0.110\n",
      "tick 4     kimg 16.5     time 17m 06s      sec/tick 109.6   sec/kimg 26.77   maintenance 0.0    gpumem 8.7   augment 0.147\n",
      "tick 5     kimg 20.6     time 18m 56s      sec/tick 109.7   sec/kimg 26.77   maintenance 0.0    gpumem 8.7   augment 0.186\n",
      "tick 6     kimg 24.7     time 20m 46s      sec/tick 109.7   sec/kimg 26.78   maintenance 0.0    gpumem 8.8   augment 0.221\n",
      "tick 7     kimg 28.8     time 22m 36s      sec/tick 109.9   sec/kimg 26.83   maintenance 0.0    gpumem 8.8   augment 0.260\n",
      "tick 8     kimg 32.9     time 24m 26s      sec/tick 110.0   sec/kimg 26.86   maintenance 0.0    gpumem 8.8   augment 0.301\n",
      "tick 9     kimg 37.0     time 26m 16s      sec/tick 110.1   sec/kimg 26.87   maintenance 0.0    gpumem 8.8   augment 0.337\n",
      "tick 10    kimg 41.1     time 28m 06s      sec/tick 110.2   sec/kimg 26.91   maintenance 0.0    gpumem 8.8   augment 0.372\n",
      "tick 11    kimg 45.2     time 29m 56s      sec/tick 110.3   sec/kimg 26.94   maintenance 0.0    gpumem 8.8   augment 0.407\n",
      "tick 12    kimg 49.3     time 31m 47s      sec/tick 110.4   sec/kimg 26.95   maintenance 0.0    gpumem 8.8   augment 0.436\n",
      "tick 13    kimg 53.4     time 33m 37s      sec/tick 110.4   sec/kimg 26.94   maintenance 0.0    gpumem 8.8   augment 0.466\n",
      "tick 14    kimg 57.5     time 35m 27s      sec/tick 110.3   sec/kimg 26.93   maintenance 0.0    gpumem 8.8   augment 0.494\n",
      "tick 15    kimg 61.6     time 37m 18s      sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 8.8   augment 0.520\n",
      "tick 16    kimg 65.7     time 39m 08s      sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.8   augment 0.531\n",
      "tick 17    kimg 69.8     time 40m 59s      sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 8.8   augment 0.548\n",
      "tick 18    kimg 73.9     time 42m 50s      sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.8   augment 0.563\n",
      "tick 19    kimg 78.0     time 44m 40s      sec/tick 110.6   sec/kimg 27.01   maintenance 0.0    gpumem 8.8   augment 0.580\n",
      "tick 20    kimg 82.0     time 46m 31s      sec/tick 110.9   sec/kimg 27.08   maintenance 0.0    gpumem 8.9   augment 0.584\n"
     ]
    }
   ],
   "source": [
    "#!python stylegan2-ada/train.py --snap=60 --outdir=./training-runs-full --gpus=1 --data=./datasets/logo-full --res=128 --kimg=700 --mirror=False --gamma=5 --augpipe=bgcfnc --target=0.5 --resume=./training-runs-full/00017-logo-full-res128-auto1-gamma5-kimg700-target0.5-bgcfnc-resumecustom/network-snapshot-000700.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T17:32:35.647528Z",
     "iopub.status.busy": "2022-07-01T17:32:35.647199Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 16.0\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.8,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1,\n",
      "      \"imgfilter\": 1,\n",
      "      \"noise\": 1,\n",
      "      \"cutout\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 60,\n",
      "  \"network_snapshot_ticks\": 60,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"./datasets/logo-full\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 700,\n",
      "  \"minibatch_size\": 32,\n",
      "  \"minibatch_gpu\": 32,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"./training-runs-full/00018-logo-full-res128-auto1-gamma5-kimg700-target0.5-bgcfnc-resumecustom/network-snapshot-000700.pkl\",\n",
      "  \"run_dir\": \"./training-runs-full/00019-logo-full-res128-auto1-gamma16-kimg700-target0.8-bgcfnc-resumecustom\"\n",
      "}\n",
      "\n",
      "Output directory:  ./training-runs-full/00019-logo-full-res128-auto1-gamma16-kimg700-target0.8-bgcfnc-resumecustom\n",
      "Training data:     ./datasets/logo-full\n",
      "Training length:   700 kimg\n",
      "Resolution:        128\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "Image shape: [3, 128, 128]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
      "Resuming from \"./training-runs-full/00018-logo-full-res128-auto1-gamma5-kimg700-target0.5-bgcfnc-resumecustom/network-snapshot-000700.pkl\"\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 12, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 12, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "---                           ---       ---                 ---             \n",
      "Total                         22949277                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 128, 128)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "128x128/FromRGB      512       (?, 128, 128, 128)  (1, 1, 3, 128)  \n",
      "128x128/Conv0        147584    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                23882369                                      \n",
      "\n",
      "Exporting sample images...\n",
      "2022-07-01 17:33:24.878792: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 700 kimg...\n",
      "\n",
      "tick 0     kimg 0.1      time 1m 58s       sec/tick 21.7    sec/kimg 169.74  maintenance 96.1   gpumem 8.6   augment 0.001\n",
      "Evaluating metrics...\n",
      "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/metrics/inception_v3_features.pkl ... done\n",
      "Calculating real image statistics for fid50k_full...\n",
      "network-snapshot-000000        time 7m 43s       fid50k_full 14.0245\n",
      "tick 1     kimg 4.2      time 11m 57s      sec/tick 109.8   sec/kimg 26.80   maintenance 489.7  gpumem 8.7   augment 0.040\n",
      "tick 2     kimg 8.3      time 13m 48s      sec/tick 110.2   sec/kimg 26.90   maintenance 0.0    gpumem 8.7   augment 0.073\n",
      "tick 3     kimg 12.4     time 15m 38s      sec/tick 110.4   sec/kimg 26.94   maintenance 0.0    gpumem 8.7   augment 0.104\n",
      "tick 4     kimg 16.5     time 17m 28s      sec/tick 110.4   sec/kimg 26.96   maintenance 0.0    gpumem 8.7   augment 0.137\n",
      "tick 5     kimg 20.6     time 19m 19s      sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.7   augment 0.157\n",
      "tick 6     kimg 24.7     time 21m 09s      sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 8.7   augment 0.186\n",
      "tick 7     kimg 28.8     time 23m 00s      sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.7   augment 0.209\n",
      "tick 8     kimg 32.9     time 24m 51s      sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 8.7   augment 0.229\n",
      "tick 9     kimg 37.0     time 26m 41s      sec/tick 110.8   sec/kimg 27.04   maintenance 0.0    gpumem 8.7   augment 0.229\n",
      "tick 10    kimg 41.1     time 28m 32s      sec/tick 110.7   sec/kimg 27.01   maintenance 0.0    gpumem 8.7   augment 0.229\n",
      "tick 11    kimg 45.2     time 30m 23s      sec/tick 110.8   sec/kimg 27.06   maintenance 0.0    gpumem 9.4   augment 0.232\n",
      "tick 12    kimg 49.3     time 32m 14s      sec/tick 110.8   sec/kimg 27.06   maintenance 0.0    gpumem 9.4   augment 0.234\n",
      "tick 13    kimg 53.4     time 34m 04s      sec/tick 110.7   sec/kimg 27.03   maintenance 0.0    gpumem 9.4   augment 0.229\n",
      "tick 14    kimg 57.5     time 35m 55s      sec/tick 110.7   sec/kimg 27.03   maintenance 0.0    gpumem 9.4   augment 0.227\n",
      "tick 15    kimg 61.6     time 37m 46s      sec/tick 110.7   sec/kimg 27.03   maintenance 0.0    gpumem 9.4   augment 0.227\n",
      "tick 16    kimg 65.7     time 39m 37s      sec/tick 110.8   sec/kimg 27.04   maintenance 0.0    gpumem 9.4   augment 0.229\n",
      "tick 17    kimg 69.8     time 41m 27s      sec/tick 110.5   sec/kimg 26.99   maintenance 0.0    gpumem 9.4   augment 0.234\n",
      "tick 18    kimg 73.9     time 43m 18s      sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 9.4   augment 0.234\n",
      "tick 19    kimg 78.0     time 45m 09s      sec/tick 111.0   sec/kimg 27.11   maintenance 0.0    gpumem 9.4   augment 0.227\n",
      "tick 20    kimg 82.0     time 47m 00s      sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 9.4   augment 0.229\n",
      "tick 21    kimg 86.1     time 48m 50s      sec/tick 110.6   sec/kimg 27.01   maintenance 0.0    gpumem 9.4   augment 0.237\n",
      "tick 22    kimg 90.2     time 50m 41s      sec/tick 110.6   sec/kimg 27.01   maintenance 0.0    gpumem 9.4   augment 0.242\n",
      "tick 23    kimg 94.3     time 52m 32s      sec/tick 110.7   sec/kimg 27.03   maintenance 0.0    gpumem 9.4   augment 0.247\n",
      "tick 24    kimg 98.4     time 54m 22s      sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 9.4   augment 0.239\n",
      "tick 25    kimg 102.5    time 56m 13s      sec/tick 110.6   sec/kimg 27.01   maintenance 0.0    gpumem 9.4   augment 0.234\n",
      "tick 26    kimg 106.6    time 58m 04s      sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 9.4   augment 0.229\n",
      "tick 27    kimg 110.7    time 59m 54s      sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 9.4   augment 0.232\n",
      "tick 28    kimg 114.8    time 1h 01m 45s   sec/tick 110.8   sec/kimg 27.05   maintenance 0.0    gpumem 9.4   augment 0.229\n",
      "tick 29    kimg 118.9    time 1h 03m 36s   sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 9.4   augment 0.232\n",
      "tick 30    kimg 123.0    time 1h 05m 27s   sec/tick 110.8   sec/kimg 27.05   maintenance 0.0    gpumem 9.4   augment 0.227\n",
      "tick 31    kimg 127.1    time 1h 07m 17s   sec/tick 110.8   sec/kimg 27.05   maintenance 0.0    gpumem 9.4   augment 0.234\n",
      "tick 32    kimg 131.2    time 1h 09m 08s   sec/tick 110.5   sec/kimg 26.99   maintenance 0.0    gpumem 9.4   augment 0.237\n",
      "tick 33    kimg 135.3    time 1h 10m 59s   sec/tick 110.6   sec/kimg 27.01   maintenance 0.0    gpumem 9.4   augment 0.232\n",
      "tick 34    kimg 139.4    time 1h 12m 49s   sec/tick 110.7   sec/kimg 27.03   maintenance 0.0    gpumem 9.4   augment 0.232\n",
      "tick 35    kimg 143.5    time 1h 14m 40s   sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 9.4   augment 0.227\n",
      "tick 36    kimg 147.6    time 1h 16m 31s   sec/tick 110.7   sec/kimg 27.04   maintenance 0.0    gpumem 9.4   augment 0.224\n",
      "tick 37    kimg 151.7    time 1h 18m 21s   sec/tick 110.7   sec/kimg 27.01   maintenance 0.0    gpumem 9.4   augment 0.227\n",
      "tick 38    kimg 155.8    time 1h 20m 12s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 9.4   augment 0.227\n",
      "tick 39    kimg 159.9    time 1h 22m 03s   sec/tick 110.7   sec/kimg 27.04   maintenance 0.0    gpumem 9.4   augment 0.211\n",
      "tick 40    kimg 164.0    time 1h 23m 53s   sec/tick 110.5   sec/kimg 26.97   maintenance 0.0    gpumem 9.4   augment 0.219\n",
      "tick 41    kimg 168.1    time 1h 25m 44s   sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 9.4   augment 0.219\n",
      "tick 42    kimg 172.2    time 1h 27m 35s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 9.4   augment 0.227\n",
      "tick 43    kimg 176.3    time 1h 29m 25s   sec/tick 110.6   sec/kimg 27.01   maintenance 0.0    gpumem 9.4   augment 0.221\n",
      "tick 44    kimg 180.4    time 1h 31m 16s   sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 9.4   augment 0.229\n",
      "tick 45    kimg 184.4    time 1h 33m 07s   sec/tick 110.8   sec/kimg 27.04   maintenance 0.0    gpumem 9.4   augment 0.221\n",
      "tick 46    kimg 188.5    time 1h 34m 57s   sec/tick 110.6   sec/kimg 27.01   maintenance 0.0    gpumem 9.4   augment 0.224\n",
      "tick 47    kimg 192.6    time 1h 36m 48s   sec/tick 110.6   sec/kimg 27.01   maintenance 0.0    gpumem 9.4   augment 0.227\n",
      "tick 48    kimg 196.7    time 1h 38m 39s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 9.4   augment 0.216\n",
      "tick 49    kimg 200.8    time 1h 40m 29s   sec/tick 110.7   sec/kimg 27.03   maintenance 0.0    gpumem 9.4   augment 0.216\n",
      "tick 50    kimg 204.9    time 1h 42m 20s   sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 9.4   augment 0.216\n",
      "tick 51    kimg 209.0    time 1h 44m 11s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 9.4   augment 0.214\n",
      "tick 52    kimg 213.1    time 1h 46m 01s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 9.4   augment 0.219\n",
      "tick 53    kimg 217.2    time 1h 47m 52s   sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 9.4   augment 0.221\n",
      "tick 54    kimg 221.3    time 1h 49m 42s   sec/tick 110.5   sec/kimg 26.98   maintenance 0.0    gpumem 9.4   augment 0.214\n",
      "tick 55    kimg 225.4    time 1h 51m 33s   sec/tick 110.7   sec/kimg 27.03   maintenance 0.0    gpumem 9.4   augment 0.216\n",
      "tick 56    kimg 229.5    time 1h 53m 24s   sec/tick 110.6   sec/kimg 27.00   maintenance 0.0    gpumem 9.4   augment 0.227\n",
      "tick 57    kimg 233.6    time 1h 55m 14s   sec/tick 110.7   sec/kimg 27.02   maintenance 0.0    gpumem 9.4   augment 0.224\n"
     ]
    }
   ],
   "source": [
    "!python stylegan2-ada/train.py --snap=60 --outdir=./training-runs-full --gpus=1 --data=./datasets/logo-full --res=128 --kimg=700 --mirror=False --gamma=16 --augpipe=bgcfnc --target=0.8 --resume=./training-runs-full/00018-logo-full-res128-auto1-gamma5-kimg700-target0.5-bgcfnc-resumecustom/network-snapshot-000700.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LogoGan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
